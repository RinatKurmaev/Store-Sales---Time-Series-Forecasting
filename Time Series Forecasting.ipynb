{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e772922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the events data\n",
    "import csv\n",
    "\n",
    "csv_file_path = \"./holidays_events.csv\"\n",
    "data_dict = {}\n",
    "\n",
    "with open(csv_file_path, \"r\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file, delimiter=\",\")\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        date = row[\"date\"]\n",
    "        locale_name = row[\"locale_name\"]\n",
    "        \n",
    "        if date not in data_dict:\n",
    "            data_dict[date] = {}\n",
    "            \n",
    "        description = row[\"description\"]\n",
    "        change = None\n",
    "        if '+' in description:\n",
    "            if any(char.isdigit() for char in description):\n",
    "                phrases = description.split(\"+\")\n",
    "                description = phrases[0]\n",
    "                change = int(phrases[1])+1\n",
    "        if '-' in description:\n",
    "            if any(char.isdigit() for char in description):\n",
    "                phrases = description.split(\"-\")\n",
    "                description = phrases[0]\n",
    "                change = '-' + phrases[1]\n",
    "                #print(change)\n",
    "        else:\n",
    "            try:\n",
    "                description = description\n",
    "            except ValueError:\n",
    "                description = description\n",
    "            \n",
    "        data_dict[date][locale_name] = {\n",
    "            \"type\": row[\"type\"],\n",
    "            \"locale\": row[\"locale\"],\n",
    "            \"description\": description,\n",
    "            \"transferred\": row[\"transferred\"],\n",
    "            \"change\": change,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55db0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "train_df = pd.read_csv('train.csv')\n",
    "oil_df = pd.read_csv('oil.csv')\n",
    "stores_df = pd.read_csv('stores.csv')\n",
    "# fill missing values in dcoilwtico column with previous day's value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill')\n",
    "\n",
    "# merge the two dataframes based on the 'date' column using left join\n",
    "merged_df = pd.merge(train_df, oil_df[['date', 'dcoilwtico']], on='date', how='left')\n",
    "\n",
    "# fill remaining missing values in dcoilwtico column with previous day's value\n",
    "merged_df['dcoilwtico'] = merged_df['dcoilwtico'].fillna(method='ffill')\n",
    "merged_df = pd.merge(merged_df, stores_df, on='store_nbr').sort_values(by='id')\n",
    "\n",
    "df = merged_df#pd.read_csv('train.csv')\n",
    "\n",
    "# Extract the label column and convert to a PyTorch tensor\n",
    "ids = torch.tensor(df['id'].values, dtype=torch.float)\n",
    "#date = torch.tensor(df['date'].values)\n",
    "store_nbr = torch.tensor(df['store_nbr'].values)\n",
    "train_sales = torch.tensor(df['sales'].values, dtype=torch.float)\n",
    "onpromotion = torch.tensor(df['onpromotion'].values)\n",
    "dcoilwtico = torch.tensor(df['dcoilwtico'].values, dtype=torch.float)\n",
    "\n",
    "df['event_type'] = 'regular day'\n",
    "df['description'] = '0'\n",
    "for index, row in df.iterrows():\n",
    "    if (row['date'] in data_dict):\n",
    "        if (row['city'] in data_dict[row['date']]):\n",
    "            df.at[index, 'description'] = data_dict[row['date']][row['city']]['description']\n",
    "            df.at[index, 'event_type'] =  data_dict[row['date']][row['city']]['type']\n",
    "        if (row['state'] in data_dict[row['date']]):\n",
    "            df.at[index, 'description'] = data_dict[row['date']][row['state']]['description']\n",
    "            df.at[index, 'event_type']  = data_dict[row['date']][row['state']]['type']\n",
    "        if ('Ecuador' in data_dict[row['date']]):\n",
    "                df.at[index, 'description'] = data_dict[row['date']]['Ecuador']['description']\n",
    "                df.at[index, 'event_type'] = data_dict[row['date']]['Ecuador']['type']\n",
    "    else:\n",
    "        df.at[index, 'event_type'] = \"regular day\"\n",
    "#df.to_csv('merged.csv', index=False)\n",
    "# Convert string dates to datetime objects\n",
    "dates = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "month = []\n",
    "day_of_week = []\n",
    "day_of_month = []\n",
    "day_since_paycheck = []\n",
    "for i in dates:\n",
    "    month.append(i.month)\n",
    "    day_of_week.append(i.day_of_week + 1)\n",
    "    num_days_in_month = monthrange(i.year, i.month)[1]\n",
    "    day_of_month.append(i.day)\n",
    "    if(num_days_in_month == i.day):\n",
    "        day_since_paycheck.append(0)\n",
    "    else:\n",
    "        if (i.day>=15):\n",
    "            day_since_paycheck.append(i.day-15)\n",
    "        else:\n",
    "            day_since_paycheck.append(i.day)\n",
    "\n",
    "month = torch.FloatTensor(month)\n",
    "day_of_week = torch.FloatTensor(day_of_week)\n",
    "day_since_paycheck = torch.FloatTensor(day_since_paycheck)\n",
    "day_of_month = torch.FloatTensor(day_of_month)\n",
    "\n",
    "#family to tensor\n",
    "family = []\n",
    "family_raw = df['family'].values\n",
    "families = sorted(list(set(family_raw)))\n",
    "family_stoi = {s:i+1 for i,s in enumerate(families)}\n",
    "for i in family_raw:\n",
    "    family.append(family_stoi[i])\n",
    "family = torch.FloatTensor(family)\n",
    "\n",
    "#city to tensor\n",
    "city = []\n",
    "city_raw = df['city'].values\n",
    "cities = sorted(list(set(city_raw)))\n",
    "cities_stoi = {s:i+1 for i,s in enumerate(cities)}\n",
    "#cities_itos = {i:s for s,i in cities_stoi.items()}\n",
    "for i in city_raw:\n",
    "    city.append(cities_stoi[i])\n",
    "city = torch.FloatTensor(city)\n",
    "\n",
    "#state to tensor\n",
    "state_raw = df['state'].values\n",
    "state = []\n",
    "states = sorted(list(set(state_raw)))\n",
    "states_stoi = {s:i+1 for i,s in enumerate(states)}\n",
    "for i in state_raw:\n",
    "    state.append(states_stoi[i])\n",
    "state = torch.FloatTensor(state)\n",
    "\n",
    "#store type to tensor\n",
    "store_type_raw = df['type'].values\n",
    "store_type = []\n",
    "store_types = sorted(list(set(store_type_raw)))\n",
    "store_types_stoi = {s:i+1 for i,s in enumerate(store_types)}\n",
    "for i in store_type_raw:\n",
    "    store_type.append(store_types_stoi[i])\n",
    "store_type = torch.FloatTensor(store_type)\n",
    "\n",
    "train_event_description_raw = df['description']\n",
    "train_event_description = []\n",
    "event_descriptions = sorted(list(set(train_event_description_raw)))\n",
    "event_descriptions_stoi = {s:i+1 for i,s in enumerate(event_descriptions)}\n",
    "for i in train_event_description_raw:\n",
    "    train_event_description.append(event_descriptions_stoi[i])\n",
    "train_event_description = torch.FloatTensor(train_event_description)\n",
    "\n",
    "\n",
    "train_event_type_raw = df['event_type']\n",
    "train_event_type = []\n",
    "event_types = sorted(list(set(train_event_type_raw)))\n",
    "event_types_stoi = {s:i+1 for i,s in enumerate(event_types)}\n",
    "for i in train_event_type_raw:\n",
    "    train_event_type.append(event_types_stoi[i])\n",
    "train_event_type = torch.FloatTensor(train_event_type)\n",
    "\n",
    "\n",
    "cluster = torch.tensor(df['cluster'].values, dtype=torch.float)\n",
    "#merged_df.to_csv('merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b16b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.73381\n",
      "tensor(2.6951)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_sales_log = np.log(train_sales+1)\n",
    "data_range = train_sales_log.numpy().max() - train_sales_log.numpy().min()\n",
    "# choose the number of bins based on the range of the data\n",
    "#num_bins = min(50, int(data_range / 10))\n",
    "num_bins = 50\n",
    "hist_range = (0, int(train_sales_log.numpy().max())+1)\n",
    "plt.hist(train_sales_log.numpy(), range=hist_range, bins=num_bins)\n",
    "plt.show()\n",
    "print(data_range)\n",
    "print(train_sales_log.std())\n",
    "print(train_sales_log.numpy().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fefefde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.int64\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(ids.shape, ids.dtype)\n",
    "print(train_sales.shape, train_sales.dtype)\n",
    "print(train_sales_log.shape, train_sales_log.dtype)\n",
    "print(onpromotion.shape, onpromotion.dtype)\n",
    "print(family.shape, family.dtype)\n",
    "print(day_of_week.shape, day_of_week.dtype)\n",
    "print(month.shape, month.dtype)\n",
    "print(day_since_paycheck.shape, day_since_paycheck.dtype)\n",
    "print(dcoilwtico.shape, dcoilwtico.dtype)\n",
    "print(city.shape, city.dtype)\n",
    "print(state.shape, state.dtype)\n",
    "print(store_type.shape, store_type.dtype)\n",
    "print(cluster.shape, cluster.dtype)\n",
    "print(train_event_type.shape, train_event_type.dtype)\n",
    "print(train_event_description.shape, train_event_description.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7531da23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([3000888, 12]) torch.float32\n",
      "torch.Size([3000888]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.cat((month.unsqueeze(1), day_of_week.unsqueeze(1),day_since_paycheck.unsqueeze(1),\n",
    "                        #store_nbr.unsqueeze(1),\n",
    "                        family.unsqueeze(1),  onpromotion.unsqueeze(1),\n",
    "                        dcoilwtico.unsqueeze(1),\n",
    "                        city.unsqueeze(1), state.unsqueeze(1), store_type.unsqueeze(1), cluster.unsqueeze(1),\n",
    "                        train_event_type.unsqueeze(1), train_event_description.unsqueeze(1)\n",
    "                           ), dim=1)\n",
    "\n",
    "print(train_data.dtype)\n",
    "print(train_data.shape, train_data.dtype)\n",
    "print(train_sales.shape, train_sales.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa0c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600177, 12])\n",
      "torch.Size([600177])\n",
      "torch.Size([2400711, 12])\n",
      "torch.Size([2400711])\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data and labels\n",
    "indices = np.random.permutation(len(train_data))\n",
    "train_data = train_data[indices]\n",
    "train_sales = train_sales_log[indices]\n",
    "\n",
    "# Define the percentage of data to be used for validation\n",
    "val_percent = 0.2\n",
    "\n",
    "# Calculate the number of validation samples\n",
    "val_size = int(len(train_data) * val_percent)\n",
    "\n",
    "# Split the data and labels into training and validation sets\n",
    "val_data = train_data[:val_size]\n",
    "train_data = train_data[val_size:]\n",
    "\n",
    "val_sales = train_sales[:val_size]\n",
    "train_sales = train_sales[val_size:]\n",
    "\n",
    "print(val_data.shape)\n",
    "print(val_sales.shape)\n",
    "print(train_data.shape)\n",
    "print(train_sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5cfa0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.73381\n",
      "std 2.6952431201934814\n",
      "mean 2.9256398677825928\n",
      "min 0.0\n",
      "max 11.733810424804688\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data_range = train_sales.numpy().max() - train_sales.numpy().min()\n",
    "# choose the number of bins based on the range of the data\n",
    "#num_bins = min(50, int(data_range / 10))\n",
    "num_bins = 50\n",
    "hist_range = (0, int(train_sales.numpy().max())+1)\n",
    "plt.hist(train_sales.numpy(), range=hist_range, bins=num_bins)\n",
    "plt.show()\n",
    "print(data_range)\n",
    "print(f'std {train_sales.std()}')\n",
    "print(f'mean {train_sales.mean()}')\n",
    "print(f'min {train_sales.min()}')\n",
    "print(f'max {train_sales.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbddeb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3911fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        rmsle = self.mse(torch.log(pred + 1), torch.log(actual + 1)) \n",
    "        return rmsle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11fa6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalesPredictor(\n",
      "  (fc1): Linear(in_features=12, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (Leaky_ReLu): LeakyReLU(negative_slope=0.01)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SalesPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SalesPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 64) \n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1, bias=False)\n",
    "        self.Leaky_ReLu = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.Leaky_ReLu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.Leaky_ReLu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    # Instantiate the neural network\n",
    "model = SalesPredictor()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2ff093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Define the loss function and optimizer\n",
    "criterion = RMSLELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Convert the data and labels to PyTorch datasets\n",
    "train_dataset = TensorDataset(train_data, train_sales)\n",
    "val_dataset = TensorDataset(val_data, val_sales)\n",
    "# Define batch size for training and validation dataloaders\n",
    "batch_size = 1300\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=10)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=10)\n",
    "save_every = 1\n",
    "train_iterations = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a63dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss_es = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81e1789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0 iteration 1846 of 1847\n",
      "Epoch 0 loss: 4.26310038463322\n",
      "Saving model as weights/model_weights_0.pth\n",
      "Training epoch 1 iteration 1846 of 1847\n",
      "Epoch 1 loss: 3.5798740385672048\n",
      "Saving model as weights/model_weights_1.pth\n",
      "Training epoch 2 iteration 1846 of 1847\n",
      "Epoch 2 loss: 3.258708684716795\n",
      "Saving model as weights/model_weights_2.pth\n",
      "Training epoch 3 iteration 1846 of 1847\n",
      "Epoch 3 loss: 2.9242915432067194\n",
      "Saving model as weights/model_weights_3.pth\n",
      "Training epoch 4 iteration 1846 of 1847\n",
      "Epoch 4 loss: 2.6349953901593466\n",
      "Saving model as weights/model_weights_4.pth\n",
      "Training epoch 5 iteration 1846 of 1847\n",
      "Epoch 5 loss: 2.2921321408194855\n",
      "Saving model as weights/model_weights_5.pth\n",
      "Training epoch 6 iteration 1846 of 1847\n",
      "Epoch 6 loss: 1.9925863458197635\n",
      "Saving model as weights/model_weights_6.pth\n",
      "Training epoch 7 iteration 1846 of 1847\n",
      "Epoch 7 loss: 1.7875696503283465\n",
      "Saving model as weights/model_weights_7.pth\n",
      "Training epoch 8 iteration 1846 of 1847\n",
      "Epoch 8 loss: 1.6614060893727434\n",
      "Saving model as weights/model_weights_8.pth\n",
      "Training epoch 9 iteration 1846 of 1847\n",
      "Epoch 9 loss: 1.5768230472568827\n",
      "Saving model as weights/model_weights_9.pth\n",
      "Training epoch 10 iteration 1846 of 1847\n",
      "Epoch 10 loss: 1.508513964119639\n",
      "Saving model as weights/model_weights_10.pth\n",
      "Training epoch 11 iteration 1846 of 1847\n",
      "Epoch 11 loss: 1.418164116986455\n",
      "Saving model as weights/model_weights_11.pth\n",
      "Training epoch 12 iteration 1846 of 1847\n",
      "Epoch 12 loss: 1.3245060416770484\n",
      "Saving model as weights/model_weights_12.pth\n",
      "Training epoch 13 iteration 1846 of 1847\n",
      "Epoch 13 loss: 1.2778735960504464\n",
      "Saving model as weights/model_weights_13.pth\n",
      "Training epoch 14 iteration 1846 of 1847\n",
      "Epoch 14 loss: 1.2509280186636615\n",
      "Saving model as weights/model_weights_14.pth\n",
      "Training epoch 15 iteration 1846 of 1847\n",
      "Epoch 15 loss: 1.2240556999355248\n",
      "Saving model as weights/model_weights_15.pth\n",
      "Training epoch 16 iteration 1846 of 1847\n",
      "Epoch 16 loss: 1.2048922398636388\n",
      "Saving model as weights/model_weights_16.pth\n",
      "Training epoch 17 iteration 1846 of 1847\n",
      "Epoch 17 loss: 1.186226041431871\n",
      "Saving model as weights/model_weights_17.pth\n",
      "Training epoch 18 iteration 1846 of 1847\n",
      "Epoch 18 loss: 1.1715291538752282\n",
      "Saving model as weights/model_weights_18.pth\n",
      "Training epoch 19 iteration 1846 of 1847\n",
      "Epoch 19 loss: 1.1558749273007924\n",
      "Saving model as weights/model_weights_19.pth\n",
      "Training epoch 20 iteration 1846 of 1847\n",
      "Epoch 20 loss: 1.1397344274784207\n",
      "Saving model as weights/model_weights_20.pth\n",
      "Training epoch 21 iteration 1846 of 1847\n",
      "Epoch 21 loss: 1.1260294223644958\n",
      "Saving model as weights/model_weights_21.pth\n",
      "Training epoch 22 iteration 1846 of 1847\n",
      "Epoch 22 loss: 1.1104579466900828\n",
      "Saving model as weights/model_weights_22.pth\n",
      "Training epoch 23 iteration 1846 of 1847\n",
      "Epoch 23 loss: 1.0985185891857776\n",
      "Saving model as weights/model_weights_23.pth\n",
      "Training epoch 24 iteration 1846 of 1847\n",
      "Epoch 24 loss: 1.0805016538873518\n",
      "Saving model as weights/model_weights_24.pth\n",
      "Training epoch 25 iteration 1846 of 1847\n",
      "Epoch 25 loss: 1.0676272409828405\n",
      "Saving model as weights/model_weights_25.pth\n",
      "Training epoch 26 iteration 1846 of 1847\n",
      "Epoch 26 loss: 1.058400565279324\n",
      "Saving model as weights/model_weights_26.pth\n",
      "Training epoch 27 iteration 1846 of 1847\n",
      "Epoch 27 loss: 1.0454142527381471\n",
      "Saving model as weights/model_weights_27.pth\n",
      "Training epoch 28 iteration 1846 of 1847\n",
      "Epoch 28 loss: 1.0365779378572928\n",
      "Saving model as weights/model_weights_28.pth\n",
      "Training epoch 29 iteration 1846 of 1847\n",
      "Epoch 29 loss: 1.0235016608018777\n",
      "Saving model as weights/model_weights_29.pth\n",
      "Training epoch 30 iteration 1846 of 1847\n",
      "Epoch 30 loss: 1.0159337923342173\n",
      "Saving model as weights/model_weights_30.pth\n",
      "Training epoch 31 iteration 1846 of 1847\n",
      "Epoch 31 loss: 1.006499645157511\n",
      "Saving model as weights/model_weights_31.pth\n",
      "Training epoch 32 iteration 1846 of 1847\n",
      "Epoch 32 loss: 0.9965184021460797\n",
      "Saving model as weights/model_weights_32.pth\n",
      "Training epoch 33 iteration 1846 of 1847\n",
      "Epoch 33 loss: 0.9890004743029766\n",
      "Saving model as weights/model_weights_33.pth\n",
      "Training epoch 34 iteration 1846 of 1847\n",
      "Epoch 34 loss: 0.9833969527731473\n",
      "Saving model as weights/model_weights_34.pth\n",
      "Training epoch 35 iteration 1846 of 1847\n",
      "Epoch 35 loss: 0.9773559099155048\n",
      "Saving model as weights/model_weights_35.pth\n",
      "Training epoch 36 iteration 1846 of 1847\n",
      "Epoch 36 loss: 0.9675526551833719\n",
      "Saving model as weights/model_weights_36.pth\n",
      "Training epoch 37 iteration 1846 of 1847\n",
      "Epoch 37 loss: 0.9615386749320761\n",
      "Saving model as weights/model_weights_37.pth\n",
      "Training epoch 38 iteration 1846 of 1847\n",
      "Epoch 38 loss: 0.954578710912561\n",
      "Saving model as weights/model_weights_38.pth\n",
      "Training epoch 39 iteration 1846 of 1847\n",
      "Epoch 39 loss: 0.9487212591708255\n",
      "Saving model as weights/model_weights_39.pth\n",
      "Training epoch 40 iteration 1846 of 1847\n",
      "Epoch 40 loss: 0.9374112958642168\n",
      "Saving model as weights/model_weights_40.pth\n",
      "Training epoch 41 iteration 1846 of 1847\n",
      "Epoch 41 loss: 0.930112736284507\n",
      "Saving model as weights/model_weights_41.pth\n",
      "Training epoch 42 iteration 1846 of 1847\n",
      "Epoch 42 loss: 0.9221927869558721\n",
      "Saving model as weights/model_weights_42.pth\n",
      "Training epoch 43 iteration 1846 of 1847\n",
      "Epoch 43 loss: 0.9147383952114991\n",
      "Saving model as weights/model_weights_43.pth\n",
      "Training epoch 44 iteration 1846 of 1847\n",
      "Epoch 44 loss: 0.9126833547562215\n",
      "Saving model as weights/model_weights_44.pth\n",
      "Training epoch 45 iteration 1846 of 1847\n",
      "Epoch 45 loss: 0.9050306084353535\n",
      "Saving model as weights/model_weights_45.pth\n",
      "Training epoch 46 iteration 1846 of 1847\n",
      "Epoch 46 loss: 0.9015911734291329\n",
      "Saving model as weights/model_weights_46.pth\n",
      "Training epoch 47 iteration 1846 of 1847\n",
      "Epoch 47 loss: 0.8985869355891031\n",
      "Saving model as weights/model_weights_47.pth\n",
      "Training epoch 48 iteration 1846 of 1847\n",
      "Epoch 48 loss: 0.8924720254729229\n",
      "Saving model as weights/model_weights_48.pth\n",
      "Training epoch 49 iteration 1846 of 1847\n",
      "Epoch 49 loss: 0.888246277570079\n",
      "Saving model as weights/model_weights_49.pth\n",
      "Training epoch 50 iteration 1846 of 1847\n",
      "Epoch 50 loss: 0.883440477078711\n",
      "Saving model as weights/model_weights_50.pth\n",
      "Training epoch 51 iteration 1846 of 1847\n",
      "Epoch 51 loss: 0.8812788414774422\n",
      "Saving model as weights/model_weights_51.pth\n",
      "Training epoch 52 iteration 1846 of 1847\n",
      "Epoch 52 loss: 0.8768620387115024\n",
      "Saving model as weights/model_weights_52.pth\n",
      "Training epoch 53 iteration 1846 of 1847\n",
      "Epoch 53 loss: 0.8722221901369017\n",
      "Saving model as weights/model_weights_53.pth\n",
      "Training epoch 54 iteration 1846 of 1847\n",
      "Epoch 54 loss: 0.8699100538079778\n",
      "Saving model as weights/model_weights_54.pth\n",
      "Training epoch 55 iteration 1846 of 1847\n",
      "Epoch 55 loss: 0.8660097360352793\n",
      "Saving model as weights/model_weights_55.pth\n",
      "Training epoch 56 iteration 1846 of 1847\n",
      "Epoch 56 loss: 0.8646414375137367\n",
      "Saving model as weights/model_weights_56.pth\n",
      "Training epoch 57 iteration 1846 of 1847\n",
      "Epoch 57 loss: 0.8606566826136743\n",
      "Saving model as weights/model_weights_57.pth\n",
      "Training epoch 58 iteration 1846 of 1847\n",
      "Epoch 58 loss: 0.8561287742404597\n",
      "Saving model as weights/model_weights_58.pth\n",
      "Training epoch 59 iteration 1846 of 1847\n",
      "Epoch 59 loss: 0.852402527815081\n",
      "Saving model as weights/model_weights_59.pth\n",
      "Training epoch 60 iteration 1846 of 1847\n",
      "Epoch 60 loss: 0.8515380435397836\n",
      "Saving model as weights/model_weights_60.pth\n",
      "Training epoch 61 iteration 1846 of 1847\n",
      "Epoch 61 loss: 0.848604049725215\n",
      "Saving model as weights/model_weights_61.pth\n",
      "Training epoch 62 iteration 1846 of 1847\n",
      "Epoch 62 loss: 0.8432364114633301\n",
      "Saving model as weights/model_weights_62.pth\n",
      "Training epoch 63 iteration 1846 of 1847\n",
      "Epoch 63 loss: 0.8412881066299608\n",
      "Saving model as weights/model_weights_63.pth\n",
      "Training epoch 64 iteration 1846 of 1847\n",
      "Epoch 64 loss: 0.8359884164368196\n",
      "Saving model as weights/model_weights_64.pth\n",
      "Training epoch 65 iteration 1846 of 1847\n",
      "Epoch 65 loss: 0.8316879321512947\n",
      "Saving model as weights/model_weights_65.pth\n",
      "Training epoch 66 iteration 1846 of 1847\n",
      "Epoch 66 loss: 0.8334053889699542\n",
      "Saving model as weights/model_weights_66.pth\n",
      "Training epoch 67 iteration 1846 of 1847\n",
      "Epoch 67 loss: 0.8269740390855038\n",
      "Saving model as weights/model_weights_67.pth\n",
      "Training epoch 68 iteration 1846 of 1847\n",
      "Epoch 68 loss: 0.8255599576457487\n",
      "Saving model as weights/model_weights_68.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 69 iteration 1846 of 1847\n",
      "Epoch 69 loss: 0.8199445732103274\n",
      "Saving model as weights/model_weights_69.pth\n",
      "Training epoch 70 iteration 1846 of 1847\n",
      "Epoch 70 loss: 0.8169891774880286\n",
      "Saving model as weights/model_weights_70.pth\n",
      "Training epoch 71 iteration 1846 of 1847\n",
      "Epoch 71 loss: 0.8127608543224573\n",
      "Saving model as weights/model_weights_71.pth\n",
      "Training epoch 72 iteration 1846 of 1847\n",
      "Epoch 72 loss: 0.8110033355988098\n",
      "Saving model as weights/model_weights_72.pth\n",
      "Training epoch 73 iteration 1846 of 1847\n",
      "Epoch 73 loss: 0.8084036785005942\n",
      "Saving model as weights/model_weights_73.pth\n",
      "Training epoch 74 iteration 1846 of 1847\n",
      "Epoch 74 loss: 0.8056514612325928\n",
      "Saving model as weights/model_weights_74.pth\n",
      "Training epoch 75 iteration 1846 of 1847\n",
      "Epoch 75 loss: 0.8044524515197932\n",
      "Saving model as weights/model_weights_75.pth\n",
      "Training epoch 76 iteration 1846 of 1847\n",
      "Epoch 76 loss: 0.8004209550574591\n",
      "Saving model as weights/model_weights_76.pth\n",
      "Training epoch 77 iteration 1846 of 1847\n",
      "Epoch 77 loss: 0.7996298754996201\n",
      "Saving model as weights/model_weights_77.pth\n",
      "Training epoch 78 iteration 1846 of 1847\n",
      "Epoch 78 loss: 0.7957529918722804\n",
      "Saving model as weights/model_weights_78.pth\n",
      "Training epoch 79 iteration 1846 of 1847\n",
      "Epoch 79 loss: 0.7949841445887741\n",
      "Saving model as weights/model_weights_79.pth\n",
      "Training epoch 80 iteration 1846 of 1847\n",
      "Epoch 80 loss: 0.7903664178892156\n",
      "Saving model as weights/model_weights_80.pth\n",
      "Training epoch 81 iteration 1846 of 1847\n",
      "Epoch 81 loss: 0.7896806852328306\n",
      "Saving model as weights/model_weights_81.pth\n",
      "Training epoch 82 iteration 1846 of 1847\n",
      "Epoch 82 loss: 0.7879976809637961\n",
      "Saving model as weights/model_weights_82.pth\n",
      "Training epoch 83 iteration 1846 of 1847\n",
      "Epoch 83 loss: 0.7831470632010947\n",
      "Saving model as weights/model_weights_83.pth\n",
      "Training epoch 84 iteration 1846 of 1847\n",
      "Epoch 84 loss: 0.7843652588325897\n",
      "Saving model as weights/model_weights_84.pth\n",
      "Training epoch 85 iteration 1846 of 1847\n",
      "Epoch 85 loss: 0.7786815020930915\n",
      "Saving model as weights/model_weights_85.pth\n",
      "Training epoch 86 iteration 1846 of 1847\n",
      "Epoch 86 loss: 0.7776533887718069\n",
      "Saving model as weights/model_weights_86.pth\n",
      "Training epoch 87 iteration 1846 of 1847\n",
      "Epoch 87 loss: 0.7764307187903424\n",
      "Saving model as weights/model_weights_87.pth\n",
      "Training epoch 88 iteration 1846 of 1847\n",
      "Epoch 88 loss: 0.7725371010056946\n",
      "Saving model as weights/model_weights_88.pth\n",
      "Training epoch 89 iteration 1846 of 1847\n",
      "Epoch 89 loss: 0.7728794432034929\n",
      "Saving model as weights/model_weights_89.pth\n",
      "Training epoch 90 iteration 1846 of 1847\n",
      "Epoch 90 loss: 0.7688347055709356\n",
      "Saving model as weights/model_weights_90.pth\n",
      "Training epoch 91 iteration 1846 of 1847\n",
      "Epoch 91 loss: 0.7689740056273869\n",
      "Saving model as weights/model_weights_91.pth\n",
      "Training epoch 92 iteration 1846 of 1847\n",
      "Epoch 92 loss: 0.7671055196424917\n",
      "Saving model as weights/model_weights_92.pth\n",
      "Training epoch 93 iteration 1846 of 1847\n",
      "Epoch 93 loss: 0.7649641789548386\n",
      "Saving model as weights/model_weights_93.pth\n",
      "Training epoch 94 iteration 1846 of 1847\n",
      "Epoch 94 loss: 0.7635090311734045\n",
      "Saving model as weights/model_weights_94.pth\n",
      "Training epoch 95 iteration 1846 of 1847\n",
      "Epoch 95 loss: 0.7615884578931505\n",
      "Saving model as weights/model_weights_95.pth\n",
      "Training epoch 96 iteration 1846 of 1847\n",
      "Epoch 96 loss: 0.7592399511778748\n",
      "Saving model as weights/model_weights_96.pth\n",
      "Training epoch 97 iteration 1846 of 1847\n",
      "Epoch 97 loss: 0.7578212603337712\n",
      "Saving model as weights/model_weights_97.pth\n",
      "Training epoch 98 iteration 1846 of 1847\n",
      "Epoch 98 loss: 0.7564779428062274\n",
      "Saving model as weights/model_weights_98.pth\n",
      "Training epoch 99 iteration 1846 of 1847\n",
      "Epoch 99 loss: 0.7550731855724461\n",
      "Saving model as weights/model_weights_99.pth\n",
      "Training epoch 100 iteration 1846 of 1847\n",
      "Epoch 100 loss: 0.7550122638166952\n",
      "Saving model as weights/model_weights_100.pth\n",
      "Training epoch 101 iteration 1846 of 1847\n",
      "Epoch 101 loss: 0.7521023505045132\n",
      "Saving model as weights/model_weights_101.pth\n",
      "Training epoch 102 iteration 1846 of 1847\n",
      "Epoch 102 loss: 0.7499624281944167\n",
      "Saving model as weights/model_weights_102.pth\n",
      "Training epoch 103 iteration 1846 of 1847\n",
      "Epoch 103 loss: 0.7504103690079243\n",
      "Saving model as weights/model_weights_103.pth\n",
      "Training epoch 104 iteration 1846 of 1847\n",
      "Epoch 104 loss: 0.7478949754833207\n",
      "Saving model as weights/model_weights_104.pth\n",
      "Training epoch 105 iteration 1846 of 1847\n",
      "Epoch 105 loss: 0.74481714562461\n",
      "Saving model as weights/model_weights_105.pth\n",
      "Training epoch 106 iteration 1846 of 1847\n",
      "Epoch 106 loss: 0.7444582364335858\n",
      "Saving model as weights/model_weights_106.pth\n",
      "Training epoch 107 iteration 1846 of 1847\n",
      "Epoch 107 loss: 0.7460767629021364\n",
      "Saving model as weights/model_weights_107.pth\n",
      "Training epoch 108 iteration 1846 of 1847\n",
      "Epoch 108 loss: 0.7429660342484471\n",
      "Saving model as weights/model_weights_108.pth\n",
      "Training epoch 109 iteration 1846 of 1847\n",
      "Epoch 109 loss: 0.7430441913633135\n",
      "Saving model as weights/model_weights_109.pth\n",
      "Training epoch 110 iteration 1846 of 1847\n",
      "Epoch 110 loss: 0.7404029447127499\n",
      "Saving model as weights/model_weights_110.pth\n",
      "Training epoch 111 iteration 1846 of 1847\n",
      "Epoch 111 loss: 0.7415159078436925\n",
      "Saving model as weights/model_weights_111.pth\n",
      "Training epoch 112 iteration 1846 of 1847\n",
      "Epoch 112 loss: 0.7362256245027056\n",
      "Saving model as weights/model_weights_112.pth\n",
      "Training epoch 113 iteration 1846 of 1847\n",
      "Epoch 113 loss: 0.7369302695805664\n",
      "Saving model as weights/model_weights_113.pth\n",
      "Training epoch 114 iteration 1846 of 1847\n",
      "Epoch 114 loss: 0.7363227565480879\n",
      "Saving model as weights/model_weights_114.pth\n",
      "Training epoch 115 iteration 1846 of 1847\n",
      "Epoch 115 loss: 0.7351288257512648\n",
      "Saving model as weights/model_weights_115.pth\n",
      "Training epoch 116 iteration 1846 of 1847\n",
      "Epoch 116 loss: 0.7351276598624688\n",
      "Saving model as weights/model_weights_116.pth\n",
      "Training epoch 117 iteration 1846 of 1847\n",
      "Epoch 117 loss: 0.7322735910036142\n",
      "Saving model as weights/model_weights_117.pth\n",
      "Training epoch 118 iteration 1846 of 1847\n",
      "Epoch 118 loss: 0.7311935483215303\n",
      "Saving model as weights/model_weights_118.pth\n",
      "Training epoch 119 iteration 1846 of 1847\n",
      "Epoch 119 loss: 0.7309032626002301\n",
      "Saving model as weights/model_weights_119.pth\n",
      "Training epoch 120 iteration 1846 of 1847\n",
      "Epoch 120 loss: 0.7315136766879057\n",
      "Saving model as weights/model_weights_120.pth\n",
      "Training epoch 121 iteration 1846 of 1847\n",
      "Epoch 121 loss: 0.7286195330640466\n",
      "Saving model as weights/model_weights_121.pth\n",
      "Training epoch 122 iteration 1846 of 1847\n",
      "Epoch 122 loss: 0.728864514027406\n",
      "Saving model as weights/model_weights_122.pth\n",
      "Training epoch 123 iteration 1846 of 1847\n",
      "Epoch 123 loss: 0.7262940751776931\n",
      "Saving model as weights/model_weights_123.pth\n",
      "Training epoch 124 iteration 1846 of 1847\n",
      "Epoch 124 loss: 0.7269757853111966\n",
      "Saving model as weights/model_weights_124.pth\n",
      "Training epoch 125 iteration 1846 of 1847\n",
      "Epoch 125 loss: 0.7239533779617252\n",
      "Saving model as weights/model_weights_125.pth\n",
      "Training epoch 126 iteration 1846 of 1847\n",
      "Epoch 126 loss: 0.7237466240032466\n",
      "Saving model as weights/model_weights_126.pth\n",
      "Training epoch 127 iteration 1846 of 1847\n",
      "Epoch 127 loss: 0.7224725672342871\n",
      "Saving model as weights/model_weights_127.pth\n",
      "Training epoch 128 iteration 1846 of 1847\n",
      "Epoch 128 loss: 0.7245975702145839\n",
      "Saving model as weights/model_weights_128.pth\n",
      "Training epoch 129 iteration 1846 of 1847\n",
      "Epoch 129 loss: 0.7200841205986241\n",
      "Saving model as weights/model_weights_129.pth\n",
      "Training epoch 130 iteration 1846 of 1847\n",
      "Epoch 130 loss: 0.7206538106598722\n",
      "Saving model as weights/model_weights_130.pth\n",
      "Training epoch 131 iteration 1846 of 1847\n",
      "Epoch 131 loss: 0.7201877034349446\n",
      "Saving model as weights/model_weights_131.pth\n",
      "Training epoch 132 iteration 1846 of 1847\n",
      "Epoch 132 loss: 0.7184881658313981\n",
      "Saving model as weights/model_weights_132.pth\n",
      "Training epoch 133 iteration 1846 of 1847\n",
      "Epoch 133 loss: 0.7177685103870819\n",
      "Saving model as weights/model_weights_133.pth\n",
      "Training epoch 134 iteration 1846 of 1847\n",
      "Epoch 134 loss: 0.7178507542119649\n",
      "Saving model as weights/model_weights_134.pth\n",
      "Training epoch 135 iteration 1846 of 1847\n",
      "Epoch 135 loss: 0.7155612275351301\n",
      "Saving model as weights/model_weights_135.pth\n",
      "Training epoch 136 iteration 1846 of 1847\n",
      "Epoch 136 loss: 0.7161763494054756\n",
      "Saving model as weights/model_weights_136.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 137 iteration 1846 of 1847\n",
      "Epoch 137 loss: 0.7150528918877123\n",
      "Saving model as weights/model_weights_137.pth\n",
      "Training epoch 138 iteration 1846 of 1847\n",
      "Epoch 138 loss: 0.7126317798413647\n",
      "Saving model as weights/model_weights_138.pth\n",
      "Training epoch 139 iteration 1846 of 1847\n",
      "Epoch 139 loss: 0.7145424844060773\n",
      "Saving model as weights/model_weights_139.pth\n",
      "Training epoch 140 iteration 1846 of 1847\n",
      "Epoch 140 loss: 0.711994697548082\n",
      "Saving model as weights/model_weights_140.pth\n",
      "Training epoch 141 iteration 1846 of 1847\n",
      "Epoch 141 loss: 0.7109798571194709\n",
      "Saving model as weights/model_weights_141.pth\n",
      "Training epoch 142 iteration 1846 of 1847\n",
      "Epoch 142 loss: 0.7101856004436661\n",
      "Saving model as weights/model_weights_142.pth\n",
      "Training epoch 143 iteration 1846 of 1847\n",
      "Epoch 143 loss: 0.7088472046075025\n",
      "Saving model as weights/model_weights_143.pth\n",
      "Training epoch 144 iteration 1846 of 1847\n",
      "Epoch 144 loss: 0.7112428286169824\n",
      "Saving model as weights/model_weights_144.pth\n",
      "Training epoch 145 iteration 1846 of 1847\n",
      "Epoch 145 loss: 0.7080432292443065\n",
      "Saving model as weights/model_weights_145.pth\n",
      "Training epoch 146 iteration 1846 of 1847\n",
      "Epoch 146 loss: 0.7066913394587196\n",
      "Saving model as weights/model_weights_146.pth\n",
      "Training epoch 147 iteration 1846 of 1847\n",
      "Epoch 147 loss: 0.7077894010573512\n",
      "Saving model as weights/model_weights_147.pth\n",
      "Training epoch 148 iteration 1846 of 1847\n",
      "Epoch 148 loss: 0.708387856749373\n",
      "Saving model as weights/model_weights_148.pth\n",
      "Training epoch 149 iteration 1846 of 1847\n",
      "Epoch 149 loss: 0.7066803320911554\n",
      "Saving model as weights/model_weights_149.pth\n",
      "Training epoch 150 iteration 1846 of 1847\n",
      "Epoch 150 loss: 0.7045557637374725\n",
      "Saving model as weights/model_weights_150.pth\n",
      "Training epoch 151 iteration 1846 of 1847\n",
      "Epoch 151 loss: 0.704353993818059\n",
      "Saving model as weights/model_weights_151.pth\n",
      "Training epoch 152 iteration 1846 of 1847\n",
      "Epoch 152 loss: 0.7021212066323549\n",
      "Saving model as weights/model_weights_152.pth\n",
      "Training epoch 153 iteration 1846 of 1847\n",
      "Epoch 153 loss: 0.7021424343409123\n",
      "Saving model as weights/model_weights_153.pth\n",
      "Training epoch 154 iteration 1846 of 1847\n",
      "Epoch 154 loss: 0.7025271219599227\n",
      "Saving model as weights/model_weights_154.pth\n",
      "Training epoch 155 iteration 1846 of 1847\n",
      "Epoch 155 loss: 0.7009089304488223\n",
      "Saving model as weights/model_weights_155.pth\n",
      "Training epoch 156 iteration 1846 of 1847\n",
      "Epoch 156 loss: 0.7027560721943684\n",
      "Saving model as weights/model_weights_156.pth\n",
      "Training epoch 157 iteration 1846 of 1847\n",
      "Epoch 157 loss: 0.6995137864406133\n",
      "Saving model as weights/model_weights_157.pth\n",
      "Training epoch 158 iteration 1846 of 1847\n",
      "Epoch 158 loss: 0.7001373143246449\n",
      "Saving model as weights/model_weights_158.pth\n",
      "Training epoch 159 iteration 1846 of 1847\n",
      "Epoch 159 loss: 0.6987069780657468\n",
      "Saving model as weights/model_weights_159.pth\n",
      "Training epoch 160 iteration 1846 of 1847\n",
      "Epoch 160 loss: 0.69784879494049\n",
      "Saving model as weights/model_weights_160.pth\n",
      "Training epoch 161 iteration 1846 of 1847\n",
      "Epoch 161 loss: 0.6983623209035777\n",
      "Saving model as weights/model_weights_161.pth\n",
      "Training epoch 162 iteration 1846 of 1847\n",
      "Epoch 162 loss: 0.6978714633904474\n",
      "Saving model as weights/model_weights_162.pth\n",
      "Training epoch 163 iteration 1846 of 1847\n",
      "Epoch 163 loss: 0.6957866205805111\n",
      "Saving model as weights/model_weights_163.pth\n",
      "Training epoch 164 iteration 1846 of 1847\n",
      "Epoch 164 loss: 0.6975879225623756\n",
      "Saving model as weights/model_weights_164.pth\n",
      "Training epoch 165 iteration 1846 of 1847\n",
      "Epoch 165 loss: 0.6953779327656426\n",
      "Saving model as weights/model_weights_165.pth\n",
      "Training epoch 166 iteration 1846 of 1847\n",
      "Epoch 166 loss: 0.693637182793878\n",
      "Saving model as weights/model_weights_166.pth\n",
      "Training epoch 167 iteration 1846 of 1847\n",
      "Epoch 167 loss: 0.695603960226469\n",
      "Saving model as weights/model_weights_167.pth\n",
      "Training epoch 168 iteration 1846 of 1847\n",
      "Epoch 168 loss: 0.6948212744999913\n",
      "Saving model as weights/model_weights_168.pth\n",
      "Training epoch 169 iteration 1846 of 1847\n",
      "Epoch 169 loss: 0.6942810232599297\n",
      "Saving model as weights/model_weights_169.pth\n",
      "Training epoch 170 iteration 1846 of 1847\n",
      "Epoch 170 loss: 0.6916274925664624\n",
      "Saving model as weights/model_weights_170.pth\n",
      "Training epoch 171 iteration 1846 of 1847\n",
      "Epoch 171 loss: 0.6910910976856027\n",
      "Saving model as weights/model_weights_171.pth\n",
      "Training epoch 172 iteration 1846 of 1847\n",
      "Epoch 172 loss: 0.6928327158617857\n",
      "Saving model as weights/model_weights_172.pth\n",
      "Training epoch 173 iteration 1846 of 1847\n",
      "Epoch 173 loss: 0.6884133064495143\n",
      "Saving model as weights/model_weights_173.pth\n",
      "Training epoch 174 iteration 1846 of 1847\n",
      "Epoch 174 loss: 0.6888219034213534\n",
      "Saving model as weights/model_weights_174.pth\n",
      "Training epoch 175 iteration 1846 of 1847\n",
      "Epoch 175 loss: 0.6882294251199793\n",
      "Saving model as weights/model_weights_175.pth\n",
      "Training epoch 176 iteration 1846 of 1847\n",
      "Epoch 176 loss: 0.6881138411772593\n",
      "Saving model as weights/model_weights_176.pth\n",
      "Training epoch 177 iteration 1846 of 1847\n",
      "Epoch 177 loss: 0.6872347616219947\n",
      "Saving model as weights/model_weights_177.pth\n",
      "Training epoch 178 iteration 1846 of 1847\n",
      "Epoch 178 loss: 0.6873796525263567\n",
      "Saving model as weights/model_weights_178.pth\n",
      "Training epoch 179 iteration 1846 of 1847\n",
      "Epoch 179 loss: 0.6869879254116261\n",
      "Saving model as weights/model_weights_179.pth\n",
      "Training epoch 180 iteration 1846 of 1847\n",
      "Epoch 180 loss: 0.6870472312909432\n",
      "Saving model as weights/model_weights_180.pth\n",
      "Training epoch 181 iteration 1846 of 1847\n",
      "Epoch 181 loss: 0.6851816614963715\n",
      "Saving model as weights/model_weights_181.pth\n",
      "Training epoch 182 iteration 1846 of 1847\n",
      "Epoch 182 loss: 0.685470233495389\n",
      "Saving model as weights/model_weights_182.pth\n",
      "Training epoch 183 iteration 1846 of 1847\n",
      "Epoch 183 loss: 0.6829442292467994\n",
      "Saving model as weights/model_weights_183.pth\n",
      "Training epoch 184 iteration 1846 of 1847\n",
      "Epoch 184 loss: 0.6846936583099458\n",
      "Saving model as weights/model_weights_184.pth\n",
      "Training epoch 185 iteration 1846 of 1847\n",
      "Epoch 185 loss: 0.6843379779673939\n",
      "Saving model as weights/model_weights_185.pth\n",
      "Training epoch 186 iteration 1846 of 1847\n",
      "Epoch 186 loss: 0.6809607794721125\n",
      "Saving model as weights/model_weights_186.pth\n",
      "Training epoch 187 iteration 1846 of 1847\n",
      "Epoch 187 loss: 0.6818771536084337\n",
      "Saving model as weights/model_weights_187.pth\n",
      "Training epoch 188 iteration 1846 of 1847\n",
      "Epoch 188 loss: 0.6817138905001126\n",
      "Saving model as weights/model_weights_188.pth\n",
      "Training epoch 189 iteration 1846 of 1847\n",
      "Epoch 189 loss: 0.6812385495572588\n",
      "Saving model as weights/model_weights_189.pth\n",
      "Training epoch 190 iteration 1846 of 1847\n",
      "Epoch 190 loss: 0.680184975080898\n",
      "Saving model as weights/model_weights_190.pth\n",
      "Training epoch 191 iteration 1846 of 1847\n",
      "Epoch 191 loss: 0.6808249810836609\n",
      "Saving model as weights/model_weights_191.pth\n",
      "Training epoch 192 iteration 1846 of 1847\n",
      "Epoch 192 loss: 0.6772499992741594\n",
      "Saving model as weights/model_weights_192.pth\n",
      "Training epoch 193 iteration 1846 of 1847\n",
      "Epoch 193 loss: 0.6789264530830921\n",
      "Saving model as weights/model_weights_193.pth\n",
      "Training epoch 194 iteration 1846 of 1847\n",
      "Epoch 194 loss: 0.6767770986848737\n",
      "Saving model as weights/model_weights_194.pth\n",
      "Training epoch 195 iteration 1846 of 1847\n",
      "Epoch 195 loss: 0.676596217724718\n",
      "Saving model as weights/model_weights_195.pth\n",
      "Training epoch 196 iteration 1846 of 1847\n",
      "Epoch 196 loss: 0.6771808810084332\n",
      "Saving model as weights/model_weights_196.pth\n",
      "Training epoch 197 iteration 1846 of 1847\n",
      "Epoch 197 loss: 0.6766901043665751\n",
      "Saving model as weights/model_weights_197.pth\n",
      "Training epoch 198 iteration 1846 of 1847\n",
      "Epoch 198 loss: 0.6749308624652249\n",
      "Saving model as weights/model_weights_198.pth\n",
      "Training epoch 199 iteration 1846 of 1847\n",
      "Epoch 199 loss: 0.675210268338048\n",
      "Saving model as weights/model_weights_199.pth\n",
      "Training epoch 200 iteration 1846 of 1847\n",
      "Epoch 200 loss: 0.6737122565879006\n",
      "Saving model as weights/model_weights_200.pth\n",
      "Training epoch 201 iteration 1846 of 1847\n",
      "Epoch 201 loss: 0.6757160795173841\n",
      "Saving model as weights/model_weights_201.pth\n",
      "Training epoch 202 iteration 1846 of 1847\n",
      "Epoch 202 loss: 0.6729532211421952\n",
      "Saving model as weights/model_weights_202.pth\n",
      "Training epoch 203 iteration 1846 of 1847\n",
      "Epoch 203 loss: 0.6733650550464069\n",
      "Saving model as weights/model_weights_203.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 204 iteration 1846 of 1847\n",
      "Epoch 204 loss: 0.673791617122804\n",
      "Saving model as weights/model_weights_204.pth\n",
      "Training epoch 205 iteration 1846 of 1847\n",
      "Epoch 205 loss: 0.6725990043566817\n",
      "Saving model as weights/model_weights_205.pth\n",
      "Training epoch 206 iteration 1846 of 1847\n",
      "Epoch 206 loss: 0.6716507012029564\n",
      "Saving model as weights/model_weights_206.pth\n",
      "Training epoch 207 iteration 1846 of 1847\n",
      "Epoch 207 loss: 0.6709099870213445\n",
      "Saving model as weights/model_weights_207.pth\n",
      "Training epoch 208 iteration 1846 of 1847\n",
      "Epoch 208 loss: 0.6704173698803509\n",
      "Saving model as weights/model_weights_208.pth\n",
      "Training epoch 209 iteration 1846 of 1847\n",
      "Epoch 209 loss: 0.6713912394896158\n",
      "Saving model as weights/model_weights_209.pth\n",
      "Training epoch 210 iteration 1846 of 1847\n",
      "Epoch 210 loss: 0.669941562556162\n",
      "Saving model as weights/model_weights_210.pth\n",
      "Training epoch 211 iteration 1846 of 1847\n",
      "Epoch 211 loss: 0.6689587097976036\n",
      "Saving model as weights/model_weights_211.pth\n",
      "Training epoch 212 iteration 1846 of 1847\n",
      "Epoch 212 loss: 0.6683439125095629\n",
      "Saving model as weights/model_weights_212.pth\n",
      "Training epoch 213 iteration 1846 of 1847\n",
      "Epoch 213 loss: 0.6682542982492565\n",
      "Saving model as weights/model_weights_213.pth\n",
      "Training epoch 214 iteration 1846 of 1847\n",
      "Epoch 214 loss: 0.6684006458691926\n",
      "Saving model as weights/model_weights_214.pth\n",
      "Training epoch 215 iteration 1846 of 1847\n",
      "Epoch 215 loss: 0.6676540689882744\n",
      "Saving model as weights/model_weights_215.pth\n",
      "Training epoch 216 iteration 1846 of 1847\n",
      "Epoch 216 loss: 0.666119362688994\n",
      "Saving model as weights/model_weights_216.pth\n",
      "Training epoch 217 iteration 1846 of 1847\n",
      "Epoch 217 loss: 0.6658019293755147\n",
      "Saving model as weights/model_weights_217.pth\n",
      "Training epoch 218 iteration 1846 of 1847\n",
      "Epoch 218 loss: 0.6679008721853503\n",
      "Saving model as weights/model_weights_218.pth\n",
      "Training epoch 219 iteration 1846 of 1847\n",
      "Epoch 219 loss: 0.666830222704763\n",
      "Saving model as weights/model_weights_219.pth\n",
      "Training epoch 220 iteration 1846 of 1847\n",
      "Epoch 220 loss: 0.66563676285563\n",
      "Saving model as weights/model_weights_220.pth\n",
      "Training epoch 221 iteration 1846 of 1847\n",
      "Epoch 221 loss: 0.6662879901023961\n",
      "Saving model as weights/model_weights_221.pth\n",
      "Training epoch 222 iteration 1846 of 1847\n",
      "Epoch 222 loss: 0.6641668779790627\n",
      "Saving model as weights/model_weights_222.pth\n",
      "Training epoch 223 iteration 1846 of 1847\n",
      "Epoch 223 loss: 0.6654483105404414\n",
      "Saving model as weights/model_weights_223.pth\n",
      "Training epoch 224 iteration 1846 of 1847\n",
      "Epoch 224 loss: 0.6638213387843268\n",
      "Saving model as weights/model_weights_224.pth\n",
      "Training epoch 225 iteration 1846 of 1847\n",
      "Epoch 225 loss: 0.662073909332769\n",
      "Saving model as weights/model_weights_225.pth\n",
      "Training epoch 226 iteration 1846 of 1847\n",
      "Epoch 226 loss: 0.6633819658561338\n",
      "Saving model as weights/model_weights_226.pth\n",
      "Training epoch 227 iteration 1846 of 1847\n",
      "Epoch 227 loss: 0.6627403254856209\n",
      "Saving model as weights/model_weights_227.pth\n",
      "Training epoch 228 iteration 1846 of 1847\n",
      "Epoch 228 loss: 0.6626300489056994\n",
      "Saving model as weights/model_weights_228.pth\n",
      "Training epoch 229 iteration 1846 of 1847\n",
      "Epoch 229 loss: 0.6619847024461677\n",
      "Saving model as weights/model_weights_229.pth\n",
      "Training epoch 230 iteration 1846 of 1847\n",
      "Epoch 230 loss: 0.6614891838627244\n",
      "Saving model as weights/model_weights_230.pth\n",
      "Training epoch 231 iteration 1846 of 1847\n",
      "Epoch 231 loss: 0.6622154981172207\n",
      "Saving model as weights/model_weights_231.pth\n",
      "Training epoch 232 iteration 1846 of 1847\n",
      "Epoch 232 loss: 0.6596888839778993\n",
      "Saving model as weights/model_weights_232.pth\n",
      "Training epoch 233 iteration 1846 of 1847\n",
      "Epoch 233 loss: 0.660058891105213\n",
      "Saving model as weights/model_weights_233.pth\n",
      "Training epoch 234 iteration 1846 of 1847\n",
      "Epoch 234 loss: 0.6586878077688253\n",
      "Saving model as weights/model_weights_234.pth\n",
      "Training epoch 235 iteration 1846 of 1847\n",
      "Epoch 235 loss: 0.6598558664063731\n",
      "Saving model as weights/model_weights_235.pth\n",
      "Training epoch 236 iteration 1846 of 1847\n",
      "Epoch 236 loss: 0.6579730560570455\n",
      "Saving model as weights/model_weights_236.pth\n",
      "Training epoch 237 iteration 1846 of 1847\n",
      "Epoch 237 loss: 0.6594565792476156\n",
      "Saving model as weights/model_weights_237.pth\n",
      "Training epoch 238 iteration 1846 of 1847\n",
      "Epoch 238 loss: 0.6561780039949164\n",
      "Saving model as weights/model_weights_238.pth\n",
      "Training epoch 239 iteration 1846 of 1847\n",
      "Epoch 239 loss: 0.6576962361770768\n",
      "Saving model as weights/model_weights_239.pth\n",
      "Training epoch 240 iteration 1846 of 1847\n",
      "Epoch 240 loss: 0.6570227537273909\n",
      "Saving model as weights/model_weights_240.pth\n",
      "Training epoch 241 iteration 1846 of 1847\n",
      "Epoch 241 loss: 0.6568554138808104\n",
      "Saving model as weights/model_weights_241.pth\n",
      "Training epoch 242 iteration 1846 of 1847\n",
      "Epoch 242 loss: 0.6562746002439169\n",
      "Saving model as weights/model_weights_242.pth\n",
      "Training epoch 243 iteration 1846 of 1847\n",
      "Epoch 243 loss: 0.6549974683819426\n",
      "Saving model as weights/model_weights_243.pth\n",
      "Training epoch 244 iteration 1846 of 1847\n",
      "Epoch 244 loss: 0.6553333083003291\n",
      "Saving model as weights/model_weights_244.pth\n",
      "Training epoch 245 iteration 1846 of 1847\n",
      "Epoch 245 loss: 0.6552624750053424\n",
      "Saving model as weights/model_weights_245.pth\n",
      "Training epoch 246 iteration 1846 of 1847\n",
      "Epoch 246 loss: 0.6550676300355274\n",
      "Saving model as weights/model_weights_246.pth\n",
      "Training epoch 247 iteration 1846 of 1847\n",
      "Epoch 247 loss: 0.6537789098623965\n",
      "Saving model as weights/model_weights_247.pth\n",
      "Training epoch 248 iteration 1846 of 1847\n",
      "Epoch 248 loss: 0.6548185405953226\n",
      "Saving model as weights/model_weights_248.pth\n",
      "Training epoch 249 iteration 1846 of 1847\n",
      "Epoch 249 loss: 0.6527613726866587\n",
      "Saving model as weights/model_weights_249.pth\n",
      "Training epoch 250 iteration 1846 of 1847\n",
      "Epoch 250 loss: 0.6529522753271724\n",
      "Saving model as weights/model_weights_250.pth\n",
      "Training epoch 251 iteration 1846 of 1847\n",
      "Epoch 251 loss: 0.6543884236036795\n",
      "Saving model as weights/model_weights_251.pth\n",
      "Training epoch 252 iteration 1846 of 1847\n",
      "Epoch 252 loss: 0.6530779649356797\n",
      "Saving model as weights/model_weights_252.pth\n",
      "Training epoch 253 iteration 1846 of 1847\n",
      "Epoch 253 loss: 0.6515038743268237\n",
      "Saving model as weights/model_weights_253.pth\n",
      "Training epoch 254 iteration 1846 of 1847\n",
      "Epoch 254 loss: 0.6517774276657239\n",
      "Saving model as weights/model_weights_254.pth\n",
      "Training epoch 255 iteration 1846 of 1847\n",
      "Epoch 255 loss: 0.6530261650140955\n",
      "Saving model as weights/model_weights_255.pth\n",
      "Training epoch 256 iteration 1846 of 1847\n",
      "Epoch 256 loss: 0.6493569711575201\n",
      "Saving model as weights/model_weights_256.pth\n",
      "Training epoch 257 iteration 1846 of 1847\n",
      "Epoch 257 loss: 0.6524985452310162\n",
      "Saving model as weights/model_weights_257.pth\n",
      "Training epoch 258 iteration 1846 of 1847\n",
      "Epoch 258 loss: 0.6503507662413246\n",
      "Saving model as weights/model_weights_258.pth\n",
      "Training epoch 259 iteration 1846 of 1847\n",
      "Epoch 259 loss: 0.650102845255465\n",
      "Saving model as weights/model_weights_259.pth\n",
      "Training epoch 260 iteration 1846 of 1847\n",
      "Epoch 260 loss: 0.6503978386787576\n",
      "Saving model as weights/model_weights_260.pth\n",
      "Training epoch 261 iteration 1846 of 1847\n",
      "Epoch 261 loss: 0.6515881954235971\n",
      "Saving model as weights/model_weights_261.pth\n",
      "Training epoch 262 iteration 1846 of 1847\n",
      "Epoch 262 loss: 0.6501059048261008\n",
      "Saving model as weights/model_weights_262.pth\n",
      "Training epoch 263 iteration 1846 of 1847\n",
      "Epoch 263 loss: 0.6481640226755777\n",
      "Saving model as weights/model_weights_263.pth\n",
      "Training epoch 264 iteration 1846 of 1847\n",
      "Epoch 264 loss: 0.6496671224744112\n",
      "Saving model as weights/model_weights_264.pth\n",
      "Training epoch 265 iteration 1846 of 1847\n",
      "Epoch 265 loss: 0.6499293449606584\n",
      "Saving model as weights/model_weights_265.pth\n",
      "Training epoch 266 iteration 1846 of 1847\n",
      "Epoch 266 loss: 0.6471428273010719\n",
      "Saving model as weights/model_weights_266.pth\n",
      "Training epoch 267 iteration 1846 of 1847\n",
      "Epoch 267 loss: 0.6471047062743466\n",
      "Saving model as weights/model_weights_267.pth\n",
      "Training epoch 268 iteration 1846 of 1847\n",
      "Epoch 268 loss: 0.6471025357229618\n",
      "Saving model as weights/model_weights_268.pth\n",
      "Training epoch 269 iteration 1846 of 1847\n",
      "Epoch 269 loss: 0.6471691769106555\n",
      "Saving model as weights/model_weights_269.pth\n",
      "Training epoch 270 iteration 1846 of 1847\n",
      "Epoch 270 loss: 0.6464343024836273\n",
      "Saving model as weights/model_weights_270.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 271 iteration 1846 of 1847\n",
      "Epoch 271 loss: 0.6462280028532438\n",
      "Saving model as weights/model_weights_271.pth\n",
      "Training epoch 272 iteration 1846 of 1847\n",
      "Epoch 272 loss: 0.6470608931492648\n",
      "Saving model as weights/model_weights_272.pth\n",
      "Training epoch 273 iteration 1846 of 1847\n",
      "Epoch 273 loss: 0.6455381909253214\n",
      "Saving model as weights/model_weights_273.pth\n",
      "Training epoch 274 iteration 1846 of 1847\n",
      "Epoch 274 loss: 0.6458076070661344\n",
      "Saving model as weights/model_weights_274.pth\n",
      "Training epoch 275 iteration 1846 of 1847\n",
      "Epoch 275 loss: 0.6453125358079663\n",
      "Saving model as weights/model_weights_275.pth\n",
      "Training epoch 276 iteration 1846 of 1847\n",
      "Epoch 276 loss: 0.6454359839978447\n",
      "Saving model as weights/model_weights_276.pth\n",
      "Training epoch 277 iteration 1846 of 1847\n",
      "Epoch 277 loss: 0.6447961124201755\n",
      "Saving model as weights/model_weights_277.pth\n",
      "Training epoch 278 iteration 1846 of 1847\n",
      "Epoch 278 loss: 0.6441536752772319\n",
      "Saving model as weights/model_weights_278.pth\n",
      "Training epoch 279 iteration 1846 of 1847\n",
      "Epoch 279 loss: 0.6438462816352256\n",
      "Saving model as weights/model_weights_279.pth\n",
      "Training epoch 280 iteration 1846 of 1847\n",
      "Epoch 280 loss: 0.6454799574939509\n",
      "Saving model as weights/model_weights_280.pth\n",
      "Training epoch 281 iteration 1846 of 1847\n",
      "Epoch 281 loss: 0.6445169017549844\n",
      "Saving model as weights/model_weights_281.pth\n",
      "Training epoch 282 iteration 1846 of 1847\n",
      "Epoch 282 loss: 0.6440892843020304\n",
      "Saving model as weights/model_weights_282.pth\n",
      "Training epoch 283 iteration 1846 of 1847\n",
      "Epoch 283 loss: 0.6426222354544777\n",
      "Saving model as weights/model_weights_283.pth\n",
      "Training epoch 284 iteration 1846 of 1847\n",
      "Epoch 284 loss: 0.6431778375367958\n",
      "Saving model as weights/model_weights_284.pth\n",
      "Training epoch 285 iteration 1846 of 1847\n",
      "Epoch 285 loss: 0.6431483980217817\n",
      "Saving model as weights/model_weights_285.pth\n",
      "Training epoch 286 iteration 1846 of 1847\n",
      "Epoch 286 loss: 0.6418237747472237\n",
      "Saving model as weights/model_weights_286.pth\n",
      "Training epoch 287 iteration 1846 of 1847\n",
      "Epoch 287 loss: 0.6422217420842368\n",
      "Saving model as weights/model_weights_287.pth\n",
      "Training epoch 288 iteration 1846 of 1847\n",
      "Epoch 288 loss: 0.6424696896130417\n",
      "Saving model as weights/model_weights_288.pth\n",
      "Training epoch 289 iteration 1846 of 1847\n",
      "Epoch 289 loss: 0.6402709257073447\n",
      "Saving model as weights/model_weights_289.pth\n",
      "Training epoch 290 iteration 1846 of 1847\n",
      "Epoch 290 loss: 0.6427273093911849\n",
      "Saving model as weights/model_weights_290.pth\n",
      "Training epoch 291 iteration 1846 of 1847\n",
      "Epoch 291 loss: 0.6401333618822392\n",
      "Saving model as weights/model_weights_291.pth\n",
      "Training epoch 292 iteration 1846 of 1847\n",
      "Epoch 292 loss: 0.639481450247003\n",
      "Saving model as weights/model_weights_292.pth\n",
      "Training epoch 293 iteration 1846 of 1847\n",
      "Epoch 293 loss: 0.6411532478424169\n",
      "Saving model as weights/model_weights_293.pth\n",
      "Training epoch 294 iteration 1846 of 1847\n",
      "Epoch 294 loss: 0.6396547745354575\n",
      "Saving model as weights/model_weights_294.pth\n",
      "Training epoch 295 iteration 1846 of 1847\n",
      "Epoch 295 loss: 0.6409364056767937\n",
      "Saving model as weights/model_weights_295.pth\n",
      "Training epoch 296 iteration 1846 of 1847\n",
      "Epoch 296 loss: 0.6394750232882415\n",
      "Saving model as weights/model_weights_296.pth\n",
      "Training epoch 297 iteration 1846 of 1847\n",
      "Epoch 297 loss: 0.6388773890076035\n",
      "Saving model as weights/model_weights_297.pth\n",
      "Training epoch 298 iteration 1846 of 1847\n",
      "Epoch 298 loss: 0.6393037785145161\n",
      "Saving model as weights/model_weights_298.pth\n",
      "Training epoch 299 iteration 1846 of 1847\n",
      "Epoch 299 loss: 0.6385028922177032\n",
      "Saving model as weights/model_weights_299.pth\n",
      "Training epoch 300 iteration 1846 of 1847\n",
      "Epoch 300 loss: 0.6390421750839814\n",
      "Saving model as weights/model_weights_300.pth\n",
      "Training epoch 301 iteration 1846 of 1847\n",
      "Epoch 301 loss: 0.638381963542299\n",
      "Saving model as weights/model_weights_301.pth\n",
      "Training epoch 302 iteration 1846 of 1847\n",
      "Epoch 302 loss: 0.6365902404818718\n",
      "Saving model as weights/model_weights_302.pth\n",
      "Training epoch 303 iteration 1846 of 1847\n",
      "Epoch 303 loss: 0.6385266935270286\n",
      "Saving model as weights/model_weights_303.pth\n",
      "Training epoch 304 iteration 1846 of 1847\n",
      "Epoch 304 loss: 0.6361401892218257\n",
      "Saving model as weights/model_weights_304.pth\n",
      "Training epoch 305 iteration 1846 of 1847\n",
      "Epoch 305 loss: 0.6371676910065546\n",
      "Saving model as weights/model_weights_305.pth\n",
      "Training epoch 306 iteration 1846 of 1847\n",
      "Epoch 306 loss: 0.6381185123677763\n",
      "Saving model as weights/model_weights_306.pth\n",
      "Training epoch 307 iteration 1846 of 1847\n",
      "Epoch 307 loss: 0.6361069115000798\n",
      "Saving model as weights/model_weights_307.pth\n",
      "Training epoch 308 iteration 1846 of 1847\n",
      "Epoch 308 loss: 0.6356331265869822\n",
      "Saving model as weights/model_weights_308.pth\n",
      "Training epoch 309 iteration 1846 of 1847\n",
      "Epoch 309 loss: 0.6358603418163822\n",
      "Saving model as weights/model_weights_309.pth\n",
      "Training epoch 310 iteration 1846 of 1847\n",
      "Epoch 310 loss: 0.6370482532217752\n",
      "Saving model as weights/model_weights_310.pth\n",
      "Training epoch 311 iteration 1846 of 1847\n",
      "Epoch 311 loss: 0.6351633988881538\n",
      "Saving model as weights/model_weights_311.pth\n",
      "Training epoch 312 iteration 1846 of 1847\n",
      "Epoch 312 loss: 0.6353033575323639\n",
      "Saving model as weights/model_weights_312.pth\n",
      "Training epoch 313 iteration 1846 of 1847\n",
      "Epoch 313 loss: 0.6347549197702196\n",
      "Saving model as weights/model_weights_313.pth\n",
      "Training epoch 314 iteration 1846 of 1847\n",
      "Epoch 314 loss: 0.6355043726962647\n",
      "Saving model as weights/model_weights_314.pth\n",
      "Training epoch 315 iteration 1846 of 1847\n",
      "Epoch 315 loss: 0.634990264401929\n",
      "Saving model as weights/model_weights_315.pth\n",
      "Training epoch 316 iteration 1846 of 1847\n",
      "Epoch 316 loss: 0.6343988812189201\n",
      "Saving model as weights/model_weights_316.pth\n",
      "Training epoch 317 iteration 1846 of 1847\n",
      "Epoch 317 loss: 0.632500983052597\n",
      "Saving model as weights/model_weights_317.pth\n",
      "Training epoch 318 iteration 1846 of 1847\n",
      "Epoch 318 loss: 0.6342958371801898\n",
      "Saving model as weights/model_weights_318.pth\n",
      "Training epoch 319 iteration 1846 of 1847\n",
      "Epoch 319 loss: 0.6325523245637973\n",
      "Saving model as weights/model_weights_319.pth\n",
      "Training epoch 320 iteration 1846 of 1847\n",
      "Epoch 320 loss: 0.6334978439837581\n",
      "Saving model as weights/model_weights_320.pth\n",
      "Training epoch 321 iteration 1846 of 1847\n",
      "Epoch 321 loss: 0.6321737422740453\n",
      "Saving model as weights/model_weights_321.pth\n",
      "Training epoch 322 iteration 1846 of 1847\n",
      "Epoch 322 loss: 0.6321713682213667\n",
      "Saving model as weights/model_weights_322.pth\n",
      "Training epoch 323 iteration 1846 of 1847\n",
      "Epoch 323 loss: 0.6343124885138267\n",
      "Saving model as weights/model_weights_323.pth\n",
      "Training epoch 324 iteration 1846 of 1847\n",
      "Epoch 324 loss: 0.6340420292110526\n",
      "Saving model as weights/model_weights_324.pth\n",
      "Training epoch 325 iteration 1846 of 1847\n",
      "Epoch 325 loss: 0.632074235740325\n",
      "Saving model as weights/model_weights_325.pth\n",
      "Training epoch 326 iteration 1846 of 1847\n",
      "Epoch 326 loss: 0.6322095040766432\n",
      "Saving model as weights/model_weights_326.pth\n",
      "Training epoch 327 iteration 1846 of 1847\n",
      "Epoch 327 loss: 0.6320069725763882\n",
      "Saving model as weights/model_weights_327.pth\n",
      "Training epoch 328 iteration 1846 of 1847\n",
      "Epoch 328 loss: 0.6320186636708657\n",
      "Saving model as weights/model_weights_328.pth\n",
      "Training epoch 329 iteration 1846 of 1847\n",
      "Epoch 329 loss: 0.6318518650422047\n",
      "Saving model as weights/model_weights_329.pth\n",
      "Training epoch 330 iteration 1846 of 1847\n",
      "Epoch 330 loss: 0.6317700506160242\n",
      "Saving model as weights/model_weights_330.pth\n",
      "Training epoch 331 iteration 1846 of 1847\n",
      "Epoch 331 loss: 0.630322174456033\n",
      "Saving model as weights/model_weights_331.pth\n",
      "Training epoch 332 iteration 1846 of 1847\n",
      "Epoch 332 loss: 0.6295673186609921\n",
      "Saving model as weights/model_weights_332.pth\n",
      "Training epoch 333 iteration 1846 of 1847\n",
      "Epoch 333 loss: 0.6304165871645478\n",
      "Saving model as weights/model_weights_333.pth\n",
      "Training epoch 334 iteration 1846 of 1847\n",
      "Epoch 334 loss: 0.6302879763475675\n",
      "Saving model as weights/model_weights_334.pth\n",
      "Training epoch 335 iteration 1846 of 1847\n",
      "Epoch 335 loss: 0.6307970141164019\n",
      "Saving model as weights/model_weights_335.pth\n",
      "Training epoch 336 iteration 1846 of 1847\n",
      "Epoch 336 loss: 0.6303051845667229\n",
      "Saving model as weights/model_weights_336.pth\n",
      "Training epoch 337 iteration 1846 of 1847\n",
      "Epoch 337 loss: 0.6291131631516094\n",
      "Saving model as weights/model_weights_337.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 338 iteration 1846 of 1847\n",
      "Epoch 338 loss: 0.6309259399795893\n",
      "Saving model as weights/model_weights_338.pth\n",
      "Training epoch 339 iteration 1846 of 1847\n",
      "Epoch 339 loss: 0.6290485738223478\n",
      "Saving model as weights/model_weights_339.pth\n",
      "Training epoch 340 iteration 1846 of 1847\n",
      "Epoch 340 loss: 0.628078159362352\n",
      "Saving model as weights/model_weights_340.pth\n",
      "Training epoch 341 iteration 1846 of 1847\n",
      "Epoch 341 loss: 0.6279764653994835\n",
      "Saving model as weights/model_weights_341.pth\n",
      "Training epoch 342 iteration 1846 of 1847\n",
      "Epoch 342 loss: 0.6287878179911607\n",
      "Saving model as weights/model_weights_342.pth\n",
      "Training epoch 343 iteration 1846 of 1847\n",
      "Epoch 343 loss: 0.6282233183101247\n",
      "Saving model as weights/model_weights_343.pth\n",
      "Training epoch 344 iteration 1846 of 1847\n",
      "Epoch 344 loss: 0.6287164303923402\n",
      "Saving model as weights/model_weights_344.pth\n",
      "Training epoch 345 iteration 1846 of 1847\n",
      "Epoch 345 loss: 0.6278632626574815\n",
      "Saving model as weights/model_weights_345.pth\n",
      "Training epoch 346 iteration 1846 of 1847\n",
      "Epoch 346 loss: 0.6282496217398238\n",
      "Saving model as weights/model_weights_346.pth\n",
      "Training epoch 347 iteration 1846 of 1847\n",
      "Epoch 347 loss: 0.6291954312281927\n",
      "Saving model as weights/model_weights_347.pth\n",
      "Training epoch 348 iteration 1846 of 1847\n",
      "Epoch 348 loss: 0.626577205588899\n",
      "Saving model as weights/model_weights_348.pth\n",
      "Training epoch 349 iteration 1846 of 1847\n",
      "Epoch 349 loss: 0.6277242343717481\n",
      "Saving model as weights/model_weights_349.pth\n",
      "Training epoch 350 iteration 1846 of 1847\n",
      "Epoch 350 loss: 0.6270819876603198\n",
      "Saving model as weights/model_weights_350.pth\n",
      "Training epoch 351 iteration 1846 of 1847\n",
      "Epoch 351 loss: 0.6265191801767706\n",
      "Saving model as weights/model_weights_351.pth\n",
      "Training epoch 352 iteration 1846 of 1847\n",
      "Epoch 352 loss: 0.626055460461553\n",
      "Saving model as weights/model_weights_352.pth\n",
      "Training epoch 353 iteration 1846 of 1847\n",
      "Epoch 353 loss: 0.6264544687983663\n",
      "Saving model as weights/model_weights_353.pth\n",
      "Training epoch 354 iteration 1846 of 1847\n",
      "Epoch 354 loss: 0.6266444161994172\n",
      "Saving model as weights/model_weights_354.pth\n",
      "Training epoch 355 iteration 1846 of 1847\n",
      "Epoch 355 loss: 0.6235804793540374\n",
      "Saving model as weights/model_weights_355.pth\n",
      "Training epoch 356 iteration 1846 of 1847\n",
      "Epoch 356 loss: 0.6275187656727106\n",
      "Saving model as weights/model_weights_356.pth\n",
      "Training epoch 357 iteration 1846 of 1847\n",
      "Epoch 357 loss: 0.6252867656910684\n",
      "Saving model as weights/model_weights_357.pth\n",
      "Training epoch 358 iteration 1846 of 1847\n",
      "Epoch 358 loss: 0.6237942271285529\n",
      "Saving model as weights/model_weights_358.pth\n",
      "Training epoch 359 iteration 1846 of 1847\n",
      "Epoch 359 loss: 0.6253596327081524\n",
      "Saving model as weights/model_weights_359.pth\n",
      "Training epoch 360 iteration 1846 of 1847\n",
      "Epoch 360 loss: 0.6250093286109732\n",
      "Saving model as weights/model_weights_360.pth\n",
      "Training epoch 361 iteration 1846 of 1847\n",
      "Epoch 361 loss: 0.6243497585211177\n",
      "Saving model as weights/model_weights_361.pth\n",
      "Training epoch 362 iteration 1846 of 1847\n",
      "Epoch 362 loss: 0.6230781481726853\n",
      "Saving model as weights/model_weights_362.pth\n",
      "Training epoch 363 iteration 1846 of 1847\n",
      "Epoch 363 loss: 0.6257922338613253\n",
      "Saving model as weights/model_weights_363.pth\n",
      "Training epoch 364 iteration 1846 of 1847\n",
      "Epoch 364 loss: 0.6249409168071209\n",
      "Saving model as weights/model_weights_364.pth\n",
      "Training epoch 365 iteration 1846 of 1847\n",
      "Epoch 365 loss: 0.6246989447165646\n",
      "Saving model as weights/model_weights_365.pth\n",
      "Training epoch 366 iteration 1846 of 1847\n",
      "Epoch 366 loss: 0.6244898101059759\n",
      "Saving model as weights/model_weights_366.pth\n",
      "Training epoch 367 iteration 1846 of 1847\n",
      "Epoch 367 loss: 0.6223885609804132\n",
      "Saving model as weights/model_weights_367.pth\n",
      "Training epoch 368 iteration 1846 of 1847\n",
      "Epoch 368 loss: 0.6229398707376665\n",
      "Saving model as weights/model_weights_368.pth\n",
      "Training epoch 369 iteration 1846 of 1847\n",
      "Epoch 369 loss: 0.62361868902936\n",
      "Saving model as weights/model_weights_369.pth\n",
      "Training epoch 370 iteration 1846 of 1847\n",
      "Epoch 370 loss: 0.6232651544056135\n",
      "Saving model as weights/model_weights_370.pth\n",
      "Training epoch 371 iteration 1846 of 1847\n",
      "Epoch 371 loss: 0.624021062979391\n",
      "Saving model as weights/model_weights_371.pth\n",
      "Training epoch 372 iteration 1846 of 1847\n",
      "Epoch 372 loss: 0.6224188727498635\n",
      "Saving model as weights/model_weights_372.pth\n",
      "Training epoch 373 iteration 1846 of 1847\n",
      "Epoch 373 loss: 0.6221684478041799\n",
      "Saving model as weights/model_weights_373.pth\n",
      "Training epoch 374 iteration 1846 of 1847\n",
      "Epoch 374 loss: 0.6217297231370071\n",
      "Saving model as weights/model_weights_374.pth\n",
      "Training epoch 375 iteration 1846 of 1847\n",
      "Epoch 375 loss: 0.6228875686784144\n",
      "Saving model as weights/model_weights_375.pth\n",
      "Training epoch 376 iteration 1846 of 1847\n",
      "Epoch 376 loss: 0.6220809856200773\n",
      "Saving model as weights/model_weights_376.pth\n",
      "Training epoch 377 iteration 1846 of 1847\n",
      "Epoch 377 loss: 0.6219529201033055\n",
      "Saving model as weights/model_weights_377.pth\n",
      "Training epoch 378 iteration 1846 of 1847\n",
      "Epoch 378 loss: 0.621577182103959\n",
      "Saving model as weights/model_weights_378.pth\n",
      "Training epoch 379 iteration 1846 of 1847\n",
      "Epoch 379 loss: 0.6214272253211279\n",
      "Saving model as weights/model_weights_379.pth\n",
      "Training epoch 380 iteration 1846 of 1847\n",
      "Epoch 380 loss: 0.6215263509756821\n",
      "Saving model as weights/model_weights_380.pth\n",
      "Training epoch 381 iteration 1846 of 1847\n",
      "Epoch 381 loss: 0.6217745605132098\n",
      "Saving model as weights/model_weights_381.pth\n",
      "Training epoch 382 iteration 1846 of 1847\n",
      "Epoch 382 loss: 0.6211661866986564\n",
      "Saving model as weights/model_weights_382.pth\n",
      "Training epoch 383 iteration 1846 of 1847\n",
      "Epoch 383 loss: 0.6214666081139637\n",
      "Saving model as weights/model_weights_383.pth\n",
      "Training epoch 384 iteration 1846 of 1847\n",
      "Epoch 384 loss: 0.6218865543652303\n",
      "Saving model as weights/model_weights_384.pth\n",
      "Training epoch 385 iteration 1846 of 1847\n",
      "Epoch 385 loss: 0.6201612670872104\n",
      "Saving model as weights/model_weights_385.pth\n",
      "Training epoch 386 iteration 1846 of 1847\n",
      "Epoch 386 loss: 0.6198373889206679\n",
      "Saving model as weights/model_weights_386.pth\n",
      "Training epoch 387 iteration 1846 of 1847\n",
      "Epoch 387 loss: 0.620244816437759\n",
      "Saving model as weights/model_weights_387.pth\n",
      "Training epoch 388 iteration 1846 of 1847\n",
      "Epoch 388 loss: 0.6198251453456713\n",
      "Saving model as weights/model_weights_388.pth\n",
      "Training epoch 389 iteration 1846 of 1847\n",
      "Epoch 389 loss: 0.6204793092264765\n",
      "Saving model as weights/model_weights_389.pth\n",
      "Training epoch 390 iteration 1846 of 1847\n",
      "Epoch 390 loss: 0.6202045806240377\n",
      "Saving model as weights/model_weights_390.pth\n",
      "Training epoch 391 iteration 1846 of 1847\n",
      "Epoch 391 loss: 0.6202856992539291\n",
      "Saving model as weights/model_weights_391.pth\n",
      "Training epoch 392 iteration 1846 of 1847\n",
      "Epoch 392 loss: 0.6194537859641995\n",
      "Saving model as weights/model_weights_392.pth\n",
      "Training epoch 393 iteration 1846 of 1847\n",
      "Epoch 393 loss: 0.6180926641387815\n",
      "Saving model as weights/model_weights_393.pth\n",
      "Training epoch 394 iteration 1846 of 1847\n",
      "Epoch 394 loss: 0.6198758526821684\n",
      "Saving model as weights/model_weights_394.pth\n",
      "Training epoch 395 iteration 1846 of 1847\n",
      "Epoch 395 loss: 0.6190698100672455\n",
      "Saving model as weights/model_weights_395.pth\n",
      "Training epoch 396 iteration 1846 of 1847\n",
      "Epoch 396 loss: 0.6186762343694793\n",
      "Saving model as weights/model_weights_396.pth\n",
      "Training epoch 397 iteration 1846 of 1847\n",
      "Epoch 397 loss: 0.6188150437283528\n",
      "Saving model as weights/model_weights_397.pth\n",
      "Training epoch 398 iteration 1846 of 1847\n",
      "Epoch 398 loss: 0.6182298492307462\n",
      "Saving model as weights/model_weights_398.pth\n",
      "Training epoch 399 iteration 1846 of 1847\n",
      "Epoch 399 loss: 0.619523300631471\n",
      "Saving model as weights/model_weights_399.pth\n",
      "Training epoch 400 iteration 1846 of 1847\n",
      "Epoch 400 loss: 0.6181117278147079\n",
      "Saving model as weights/model_weights_400.pth\n",
      "Training epoch 401 iteration 1846 of 1847\n",
      "Epoch 401 loss: 0.6195774061104125\n",
      "Saving model as weights/model_weights_401.pth\n",
      "Training epoch 402 iteration 1846 of 1847\n",
      "Epoch 402 loss: 0.6175959335189286\n",
      "Saving model as weights/model_weights_402.pth\n",
      "Training epoch 403 iteration 1846 of 1847\n",
      "Epoch 403 loss: 0.6170357935771984\n",
      "Saving model as weights/model_weights_403.pth\n",
      "Training epoch 404 iteration 1846 of 1847\n",
      "Epoch 404 loss: 0.6183558253094384\n",
      "Saving model as weights/model_weights_404.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 405 iteration 1846 of 1847\n",
      "Epoch 405 loss: 0.6189076108711761\n",
      "Saving model as weights/model_weights_405.pth\n",
      "Training epoch 406 iteration 1846 of 1847\n",
      "Epoch 406 loss: 0.6174956577722615\n",
      "Saving model as weights/model_weights_406.pth\n",
      "Training epoch 407 iteration 1846 of 1847\n",
      "Epoch 407 loss: 0.6166196826444036\n",
      "Saving model as weights/model_weights_407.pth\n",
      "Training epoch 408 iteration 1846 of 1847\n",
      "Epoch 408 loss: 0.617199722001794\n",
      "Saving model as weights/model_weights_408.pth\n",
      "Training epoch 409 iteration 1846 of 1847\n",
      "Epoch 409 loss: 0.6170817318321501\n",
      "Saving model as weights/model_weights_409.pth\n",
      "Training epoch 410 iteration 1846 of 1847\n",
      "Epoch 410 loss: 0.6160850015503687\n",
      "Saving model as weights/model_weights_410.pth\n",
      "Training epoch 411 iteration 1846 of 1847\n",
      "Epoch 411 loss: 0.6172780267244813\n",
      "Saving model as weights/model_weights_411.pth\n",
      "Training epoch 412 iteration 1846 of 1847\n",
      "Epoch 412 loss: 0.6158067606466167\n",
      "Saving model as weights/model_weights_412.pth\n",
      "Training epoch 413 iteration 1846 of 1847\n",
      "Epoch 413 loss: 0.6151194307180631\n",
      "Saving model as weights/model_weights_413.pth\n",
      "Training epoch 414 iteration 1846 of 1847\n",
      "Epoch 414 loss: 0.6160281748305674\n",
      "Saving model as weights/model_weights_414.pth\n",
      "Training epoch 415 iteration 1846 of 1847\n",
      "Epoch 415 loss: 0.6161725250494822\n",
      "Saving model as weights/model_weights_415.pth\n",
      "Training epoch 416 iteration 1846 of 1847\n",
      "Epoch 416 loss: 0.6151014259685099\n",
      "Saving model as weights/model_weights_416.pth\n",
      "Training epoch 417 iteration 1846 of 1847\n",
      "Epoch 417 loss: 0.6171589602989058\n",
      "Saving model as weights/model_weights_417.pth\n",
      "Training epoch 418 iteration 1846 of 1847\n",
      "Epoch 418 loss: 0.6151961362645894\n",
      "Saving model as weights/model_weights_418.pth\n",
      "Training epoch 419 iteration 1846 of 1847\n",
      "Epoch 419 loss: 0.6164252701713127\n",
      "Saving model as weights/model_weights_419.pth\n",
      "Training epoch 420 iteration 1846 of 1847\n",
      "Epoch 420 loss: 0.6152230065515639\n",
      "Saving model as weights/model_weights_420.pth\n",
      "Training epoch 421 iteration 1846 of 1847\n",
      "Epoch 421 loss: 0.6151109291497733\n",
      "Saving model as weights/model_weights_421.pth\n",
      "Training epoch 422 iteration 1846 of 1847\n",
      "Epoch 422 loss: 0.6149484397400762\n",
      "Saving model as weights/model_weights_422.pth\n",
      "Training epoch 423 iteration 1846 of 1847\n",
      "Epoch 423 loss: 0.6158515838396891\n",
      "Saving model as weights/model_weights_423.pth\n",
      "Training epoch 424 iteration 1846 of 1847\n",
      "Epoch 424 loss: 0.6149817475545839\n",
      "Saving model as weights/model_weights_424.pth\n",
      "Training epoch 425 iteration 1846 of 1847\n",
      "Epoch 425 loss: 0.6157439444506562\n",
      "Saving model as weights/model_weights_425.pth\n",
      "Training epoch 426 iteration 1846 of 1847\n",
      "Epoch 426 loss: 0.6130286844182027\n",
      "Saving model as weights/model_weights_426.pth\n",
      "Training epoch 427 iteration 1846 of 1847\n",
      "Epoch 427 loss: 0.6140706914466462\n",
      "Saving model as weights/model_weights_427.pth\n",
      "Training epoch 428 iteration 1846 of 1847\n",
      "Epoch 428 loss: 0.6157640112078894\n",
      "Saving model as weights/model_weights_428.pth\n",
      "Training epoch 429 iteration 1846 of 1847\n",
      "Epoch 429 loss: 0.6134398936838089\n",
      "Saving model as weights/model_weights_429.pth\n",
      "Training epoch 430 iteration 1846 of 1847\n",
      "Epoch 430 loss: 0.6142554184231296\n",
      "Saving model as weights/model_weights_430.pth\n",
      "Training epoch 431 iteration 1846 of 1847\n",
      "Epoch 431 loss: 0.61327984386931\n",
      "Saving model as weights/model_weights_431.pth\n",
      "Training epoch 432 iteration 1846 of 1847\n",
      "Epoch 432 loss: 0.6150112092398151\n",
      "Saving model as weights/model_weights_432.pth\n",
      "Training epoch 433 iteration 1846 of 1847\n",
      "Epoch 433 loss: 0.6128831433649636\n",
      "Saving model as weights/model_weights_433.pth\n",
      "Training epoch 434 iteration 1846 of 1847\n",
      "Epoch 434 loss: 0.6134346603024116\n",
      "Saving model as weights/model_weights_434.pth\n",
      "Training epoch 435 iteration 1846 of 1847\n",
      "Epoch 435 loss: 0.6130923676084168\n",
      "Saving model as weights/model_weights_435.pth\n",
      "Training epoch 436 iteration 1846 of 1847\n",
      "Epoch 436 loss: 0.6127145723291003\n",
      "Saving model as weights/model_weights_436.pth\n",
      "Training epoch 437 iteration 1846 of 1847\n",
      "Epoch 437 loss: 0.6130204958146368\n",
      "Saving model as weights/model_weights_437.pth\n",
      "Training epoch 438 iteration 1846 of 1847\n",
      "Epoch 438 loss: 0.6120561807137538\n",
      "Saving model as weights/model_weights_438.pth\n",
      "Training epoch 439 iteration 1846 of 1847\n",
      "Epoch 439 loss: 0.6120246137937598\n",
      "Saving model as weights/model_weights_439.pth\n",
      "Training epoch 440 iteration 1846 of 1847\n",
      "Epoch 440 loss: 0.6131334930545391\n",
      "Saving model as weights/model_weights_440.pth\n",
      "Training epoch 441 iteration 1846 of 1847\n",
      "Epoch 441 loss: 0.6139193990131165\n",
      "Saving model as weights/model_weights_441.pth\n",
      "Training epoch 442 iteration 1846 of 1847\n",
      "Epoch 442 loss: 0.6117185951731433\n",
      "Saving model as weights/model_weights_442.pth\n",
      "Training epoch 443 iteration 1846 of 1847\n",
      "Epoch 443 loss: 0.613761317152298\n",
      "Saving model as weights/model_weights_443.pth\n",
      "Training epoch 444 iteration 1846 of 1847\n",
      "Epoch 444 loss: 0.6119051733950247\n",
      "Saving model as weights/model_weights_444.pth\n",
      "Training epoch 445 iteration 1846 of 1847\n",
      "Epoch 445 loss: 0.6124184250541165\n",
      "Saving model as weights/model_weights_445.pth\n",
      "Training epoch 446 iteration 1846 of 1847\n",
      "Epoch 446 loss: 0.6122820835114816\n",
      "Saving model as weights/model_weights_446.pth\n",
      "Training epoch 447 iteration 1846 of 1847\n",
      "Epoch 447 loss: 0.6112549097459253\n",
      "Saving model as weights/model_weights_447.pth\n",
      "Training epoch 448 iteration 1846 of 1847\n",
      "Epoch 448 loss: 0.6113159299284042\n",
      "Saving model as weights/model_weights_448.pth\n",
      "Training epoch 449 iteration 1846 of 1847\n",
      "Epoch 449 loss: 0.6128670131282414\n",
      "Saving model as weights/model_weights_449.pth\n",
      "Training epoch 450 iteration 1846 of 1847\n",
      "Epoch 450 loss: 0.6108294704925968\n",
      "Saving model as weights/model_weights_450.pth\n",
      "Training epoch 451 iteration 1846 of 1847\n",
      "Epoch 451 loss: 0.611543773281684\n",
      "Saving model as weights/model_weights_451.pth\n",
      "Training epoch 452 iteration 1846 of 1847\n",
      "Epoch 452 loss: 0.610495158996076\n",
      "Saving model as weights/model_weights_452.pth\n",
      "Training epoch 453 iteration 1846 of 1847\n",
      "Epoch 453 loss: 0.6111500824891882\n",
      "Saving model as weights/model_weights_453.pth\n",
      "Training epoch 454 iteration 1846 of 1847\n",
      "Epoch 454 loss: 0.610208975313545\n",
      "Saving model as weights/model_weights_454.pth\n",
      "Training epoch 455 iteration 1846 of 1847\n",
      "Epoch 455 loss: 0.6096727337202125\n",
      "Saving model as weights/model_weights_455.pth\n",
      "Training epoch 456 iteration 1846 of 1847\n",
      "Epoch 456 loss: 0.610869275148843\n",
      "Saving model as weights/model_weights_456.pth\n",
      "Training epoch 457 iteration 1846 of 1847\n",
      "Epoch 457 loss: 0.610341231630632\n",
      "Saving model as weights/model_weights_457.pth\n",
      "Training epoch 458 iteration 1846 of 1847\n",
      "Epoch 458 loss: 0.6100441863650429\n",
      "Saving model as weights/model_weights_458.pth\n",
      "Training epoch 459 iteration 1846 of 1847\n",
      "Epoch 459 loss: 0.6107228909012558\n",
      "Saving model as weights/model_weights_459.pth\n",
      "Training epoch 460 iteration 1846 of 1847\n",
      "Epoch 460 loss: 0.6092052094731127\n",
      "Saving model as weights/model_weights_460.pth\n",
      "Training epoch 461 iteration 1846 of 1847\n",
      "Epoch 461 loss: 0.6097397695184077\n",
      "Saving model as weights/model_weights_461.pth\n",
      "Training epoch 462 iteration 1846 of 1847\n",
      "Epoch 462 loss: 0.6099409361303854\n",
      "Saving model as weights/model_weights_462.pth\n",
      "Training epoch 463 iteration 1846 of 1847\n",
      "Epoch 463 loss: 0.6081645248319629\n",
      "Saving model as weights/model_weights_463.pth\n",
      "Training epoch 464 iteration 1846 of 1847\n",
      "Epoch 464 loss: 0.60994676646182\n",
      "Saving model as weights/model_weights_464.pth\n",
      "Training epoch 465 iteration 1846 of 1847\n",
      "Epoch 465 loss: 0.6102758341856628\n",
      "Saving model as weights/model_weights_465.pth\n",
      "Training epoch 466 iteration 1846 of 1847\n",
      "Epoch 466 loss: 0.6091026144377528\n",
      "Saving model as weights/model_weights_466.pth\n",
      "Training epoch 467 iteration 1846 of 1847\n",
      "Epoch 467 loss: 0.6094453024522124\n",
      "Saving model as weights/model_weights_467.pth\n",
      "Training epoch 468 iteration 1846 of 1847\n",
      "Epoch 468 loss: 0.6092019823350064\n",
      "Saving model as weights/model_weights_468.pth\n",
      "Training epoch 469 iteration 1846 of 1847\n",
      "Epoch 469 loss: 0.6098923487119824\n",
      "Saving model as weights/model_weights_469.pth\n",
      "Training epoch 470 iteration 1846 of 1847\n",
      "Epoch 470 loss: 0.6084286798705394\n",
      "Saving model as weights/model_weights_470.pth\n",
      "Training epoch 471 iteration 1846 of 1847\n",
      "Epoch 471 loss: 0.6085887103062678\n",
      "Saving model as weights/model_weights_471.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 472 iteration 1846 of 1847\n",
      "Epoch 472 loss: 0.608409178179538\n",
      "Saving model as weights/model_weights_472.pth\n",
      "Training epoch 473 iteration 1846 of 1847\n",
      "Epoch 473 loss: 0.6079812643330486\n",
      "Saving model as weights/model_weights_473.pth\n",
      "Training epoch 474 iteration 1846 of 1847\n",
      "Epoch 474 loss: 0.6067037866382774\n",
      "Saving model as weights/model_weights_474.pth\n",
      "Training epoch 475 iteration 1846 of 1847\n",
      "Epoch 475 loss: 0.6082931013609437\n",
      "Saving model as weights/model_weights_475.pth\n",
      "Training epoch 476 iteration 1846 of 1847\n",
      "Epoch 476 loss: 0.609149926697556\n",
      "Saving model as weights/model_weights_476.pth\n",
      "Training epoch 477 iteration 1846 of 1847\n",
      "Epoch 477 loss: 0.6077567236966938\n",
      "Saving model as weights/model_weights_477.pth\n",
      "Training epoch 478 iteration 1846 of 1847\n",
      "Epoch 478 loss: 0.607109231227917\n",
      "Saving model as weights/model_weights_478.pth\n",
      "Training epoch 479 iteration 1846 of 1847\n",
      "Epoch 479 loss: 0.6082166628090188\n",
      "Saving model as weights/model_weights_479.pth\n",
      "Training epoch 480 iteration 1846 of 1847\n",
      "Epoch 480 loss: 0.6079003816530003\n",
      "Saving model as weights/model_weights_480.pth\n",
      "Training epoch 481 iteration 1846 of 1847\n",
      "Epoch 481 loss: 0.6083886143350575\n",
      "Saving model as weights/model_weights_481.pth\n",
      "Training epoch 482 iteration 1846 of 1847\n",
      "Epoch 482 loss: 0.6076134404719167\n",
      "Saving model as weights/model_weights_482.pth\n",
      "Training epoch 483 iteration 1846 of 1847\n",
      "Epoch 483 loss: 0.6071976631734587\n",
      "Saving model as weights/model_weights_483.pth\n",
      "Training epoch 484 iteration 1846 of 1847\n",
      "Epoch 484 loss: 0.6068863740597277\n",
      "Saving model as weights/model_weights_484.pth\n",
      "Training epoch 485 iteration 1846 of 1847\n",
      "Epoch 485 loss: 0.6074529900122283\n",
      "Saving model as weights/model_weights_485.pth\n",
      "Training epoch 486 iteration 1846 of 1847\n",
      "Epoch 486 loss: 0.6072219458701614\n",
      "Saving model as weights/model_weights_486.pth\n",
      "Training epoch 487 iteration 1846 of 1847\n",
      "Epoch 487 loss: 0.6062269257608465\n",
      "Saving model as weights/model_weights_487.pth\n",
      "Training epoch 488 iteration 1846 of 1847\n",
      "Epoch 488 loss: 0.6070659141251379\n",
      "Saving model as weights/model_weights_488.pth\n",
      "Training epoch 489 iteration 1846 of 1847\n",
      "Epoch 489 loss: 0.6062724729873841\n",
      "Saving model as weights/model_weights_489.pth\n",
      "Training epoch 490 iteration 1846 of 1847\n",
      "Epoch 490 loss: 0.6065751952162032\n",
      "Saving model as weights/model_weights_490.pth\n",
      "Training epoch 491 iteration 1846 of 1847\n",
      "Epoch 491 loss: 0.6081171417049156\n",
      "Saving model as weights/model_weights_491.pth\n",
      "Training epoch 492 iteration 1846 of 1847\n",
      "Epoch 492 loss: 0.6065810695169549\n",
      "Saving model as weights/model_weights_492.pth\n",
      "Training epoch 493 iteration 1846 of 1847\n",
      "Epoch 493 loss: 0.6074615085228237\n",
      "Saving model as weights/model_weights_493.pth\n",
      "Training epoch 494 iteration 1846 of 1847\n",
      "Epoch 494 loss: 0.6058468601318973\n",
      "Saving model as weights/model_weights_494.pth\n",
      "Training epoch 495 iteration 1846 of 1847\n",
      "Epoch 495 loss: 0.6048953223854513\n",
      "Saving model as weights/model_weights_495.pth\n",
      "Training epoch 496 iteration 1846 of 1847\n",
      "Epoch 496 loss: 0.6063043697498655\n",
      "Saving model as weights/model_weights_496.pth\n",
      "Training epoch 497 iteration 1846 of 1847\n",
      "Epoch 497 loss: 0.6062959812916351\n",
      "Saving model as weights/model_weights_497.pth\n",
      "Training epoch 498 iteration 1846 of 1847\n",
      "Epoch 498 loss: 0.606063099490286\n",
      "Saving model as weights/model_weights_498.pth\n",
      "Training epoch 499 iteration 1846 of 1847\n",
      "Epoch 499 loss: 0.6052629694334546\n",
      "Saving model as weights/model_weights_499.pth\n",
      "Training epoch 500 iteration 1846 of 1847\n",
      "Epoch 500 loss: 0.6044688010028587\n",
      "Saving model as weights/model_weights_500.pth\n",
      "Training epoch 501 iteration 1846 of 1847\n",
      "Epoch 501 loss: 0.6053736275702344\n",
      "Saving model as weights/model_weights_501.pth\n",
      "Training epoch 502 iteration 1846 of 1847\n",
      "Epoch 502 loss: 0.604532549267662\n",
      "Saving model as weights/model_weights_502.pth\n",
      "Training epoch 503 iteration 1846 of 1847\n",
      "Epoch 503 loss: 0.6054499077519405\n",
      "Saving model as weights/model_weights_503.pth\n",
      "Training epoch 504 iteration 1846 of 1847\n",
      "Epoch 504 loss: 0.6049849498123495\n",
      "Saving model as weights/model_weights_504.pth\n",
      "Training epoch 505 iteration 1846 of 1847\n",
      "Epoch 505 loss: 0.604425251629137\n",
      "Saving model as weights/model_weights_505.pth\n",
      "Training epoch 506 iteration 1846 of 1847\n",
      "Epoch 506 loss: 0.6047164452159863\n",
      "Saving model as weights/model_weights_506.pth\n",
      "Training epoch 507 iteration 1846 of 1847\n",
      "Epoch 507 loss: 0.6033622465652586\n",
      "Saving model as weights/model_weights_507.pth\n",
      "Training epoch 508 iteration 1846 of 1847\n",
      "Epoch 508 loss: 0.6048998099342836\n",
      "Saving model as weights/model_weights_508.pth\n",
      "Training epoch 509 iteration 1846 of 1847\n",
      "Epoch 509 loss: 0.6043225338508067\n",
      "Saving model as weights/model_weights_509.pth\n",
      "Training epoch 510 iteration 1846 of 1847\n",
      "Epoch 510 loss: 0.603923941439529\n",
      "Saving model as weights/model_weights_510.pth\n",
      "Training epoch 511 iteration 1846 of 1847\n",
      "Epoch 511 loss: 0.6038368862741498\n",
      "Saving model as weights/model_weights_511.pth\n",
      "Training epoch 512 iteration 1846 of 1847\n",
      "Epoch 512 loss: 0.6035239927886173\n",
      "Saving model as weights/model_weights_512.pth\n",
      "Training epoch 513 iteration 1846 of 1847\n",
      "Epoch 513 loss: 0.6033553943707611\n",
      "Saving model as weights/model_weights_513.pth\n",
      "Training epoch 514 iteration 1846 of 1847\n",
      "Epoch 514 loss: 0.6033280128134091\n",
      "Saving model as weights/model_weights_514.pth\n",
      "Training epoch 515 iteration 1846 of 1847\n",
      "Epoch 515 loss: 0.603320751002368\n",
      "Saving model as weights/model_weights_515.pth\n",
      "Training epoch 516 iteration 1846 of 1847\n",
      "Epoch 516 loss: 0.6031673313090784\n",
      "Saving model as weights/model_weights_516.pth\n",
      "Training epoch 517 iteration 1846 of 1847\n",
      "Epoch 517 loss: 0.6043686945501636\n",
      "Saving model as weights/model_weights_517.pth\n",
      "Training epoch 518 iteration 1846 of 1847\n",
      "Epoch 518 loss: 0.6040586116317807\n",
      "Saving model as weights/model_weights_518.pth\n",
      "Training epoch 519 iteration 1846 of 1847\n",
      "Epoch 519 loss: 0.6031207542323911\n",
      "Saving model as weights/model_weights_519.pth\n",
      "Training epoch 520 iteration 1846 of 1847\n",
      "Epoch 520 loss: 0.6032630959813119\n",
      "Saving model as weights/model_weights_520.pth\n",
      "Training epoch 521 iteration 1846 of 1847\n",
      "Epoch 521 loss: 0.6030923154751675\n",
      "Saving model as weights/model_weights_521.pth\n",
      "Training epoch 522 iteration 1846 of 1847\n",
      "Epoch 522 loss: 0.6027436002274107\n",
      "Saving model as weights/model_weights_522.pth\n",
      "Training epoch 523 iteration 1846 of 1847\n",
      "Epoch 523 loss: 0.6026750766366124\n",
      "Saving model as weights/model_weights_523.pth\n",
      "Training epoch 524 iteration 1846 of 1847\n",
      "Epoch 524 loss: 0.6022332757630733\n",
      "Saving model as weights/model_weights_524.pth\n",
      "Training epoch 525 iteration 1846 of 1847\n",
      "Epoch 525 loss: 0.6028029988537495\n",
      "Saving model as weights/model_weights_525.pth\n",
      "Training epoch 526 iteration 1846 of 1847\n",
      "Epoch 526 loss: 0.602145741872679\n",
      "Saving model as weights/model_weights_526.pth\n",
      "Training epoch 527 iteration 1846 of 1847\n",
      "Epoch 527 loss: 0.6025122233223257\n",
      "Saving model as weights/model_weights_527.pth\n",
      "Training epoch 528 iteration 1846 of 1847\n",
      "Epoch 528 loss: 0.6037511304867997\n",
      "Saving model as weights/model_weights_528.pth\n",
      "Training epoch 529 iteration 1846 of 1847\n",
      "Epoch 529 loss: 0.6022827453753983\n",
      "Saving model as weights/model_weights_529.pth\n",
      "Training epoch 530 iteration 1846 of 1847\n",
      "Epoch 530 loss: 0.602922752136531\n",
      "Saving model as weights/model_weights_530.pth\n",
      "Training epoch 531 iteration 1846 of 1847\n",
      "Epoch 531 loss: 0.6025696025387817\n",
      "Saving model as weights/model_weights_531.pth\n",
      "Training epoch 532 iteration 1846 of 1847\n",
      "Epoch 532 loss: 0.6021678079510613\n",
      "Saving model as weights/model_weights_532.pth\n",
      "Training epoch 533 iteration 1846 of 1847\n",
      "Epoch 533 loss: 0.6015269564788407\n",
      "Saving model as weights/model_weights_533.pth\n",
      "Training epoch 534 iteration 1846 of 1847\n",
      "Epoch 534 loss: 0.6014343974199177\n",
      "Saving model as weights/model_weights_534.pth\n",
      "Training epoch 535 iteration 1846 of 1847\n",
      "Epoch 535 loss: 0.60174750023167\n",
      "Saving model as weights/model_weights_535.pth\n",
      "Training epoch 536 iteration 1846 of 1847\n",
      "Epoch 536 loss: 0.6019442393996616\n",
      "Saving model as weights/model_weights_536.pth\n",
      "Training epoch 537 iteration 1846 of 1847\n",
      "Epoch 537 loss: 0.6022880818950982\n",
      "Saving model as weights/model_weights_537.pth\n",
      "Training epoch 538 iteration 1846 of 1847\n",
      "Epoch 538 loss: 0.6016037482697705\n",
      "Saving model as weights/model_weights_538.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 539 iteration 1846 of 1847\n",
      "Epoch 539 loss: 0.6021715985902529\n",
      "Saving model as weights/model_weights_539.pth\n",
      "Training epoch 540 iteration 1846 of 1847\n",
      "Epoch 540 loss: 0.6014630985408457\n",
      "Saving model as weights/model_weights_540.pth\n",
      "Training epoch 541 iteration 1846 of 1847\n",
      "Epoch 541 loss: 0.6016779795297107\n",
      "Saving model as weights/model_weights_541.pth\n",
      "Training epoch 542 iteration 1846 of 1847\n",
      "Epoch 542 loss: 0.6004082068566962\n",
      "Saving model as weights/model_weights_542.pth\n",
      "Training epoch 543 iteration 1846 of 1847\n",
      "Epoch 543 loss: 0.6015773580954665\n",
      "Saving model as weights/model_weights_543.pth\n",
      "Training epoch 544 iteration 1846 of 1847\n",
      "Epoch 544 loss: 0.6012565281240115\n",
      "Saving model as weights/model_weights_544.pth\n",
      "Training epoch 545 iteration 1846 of 1847\n",
      "Epoch 545 loss: 0.5994108379952121\n",
      "Saving model as weights/model_weights_545.pth\n",
      "Training epoch 546 iteration 1846 of 1847\n",
      "Epoch 546 loss: 0.601164959367056\n",
      "Saving model as weights/model_weights_546.pth\n",
      "Training epoch 547 iteration 1846 of 1847\n",
      "Epoch 547 loss: 0.6009512435570238\n",
      "Saving model as weights/model_weights_547.pth\n",
      "Training epoch 548 iteration 1846 of 1847\n",
      "Epoch 548 loss: 0.6017512089830511\n",
      "Saving model as weights/model_weights_548.pth\n",
      "Training epoch 549 iteration 1846 of 1847\n",
      "Epoch 549 loss: 0.6012905355266577\n",
      "Saving model as weights/model_weights_549.pth\n",
      "Training epoch 550 iteration 1846 of 1847\n",
      "Epoch 550 loss: 0.6015681368018978\n",
      "Saving model as weights/model_weights_550.pth\n",
      "Training epoch 551 iteration 1846 of 1847\n",
      "Epoch 551 loss: 0.6003785302300807\n",
      "Saving model as weights/model_weights_551.pth\n",
      "Training epoch 552 iteration 1846 of 1847\n",
      "Epoch 552 loss: 0.6009780412825237\n",
      "Saving model as weights/model_weights_552.pth\n",
      "Training epoch 553 iteration 1846 of 1847\n",
      "Epoch 553 loss: 0.6006988214200809\n",
      "Saving model as weights/model_weights_553.pth\n",
      "Training epoch 554 iteration 1846 of 1847\n",
      "Epoch 554 loss: 0.6009304929276577\n",
      "Saving model as weights/model_weights_554.pth\n",
      "Training epoch 555 iteration 1846 of 1847\n",
      "Epoch 555 loss: 0.5995268247130114\n",
      "Saving model as weights/model_weights_555.pth\n",
      "Training epoch 556 iteration 1846 of 1847\n",
      "Epoch 556 loss: 0.5994043776036342\n",
      "Saving model as weights/model_weights_556.pth\n",
      "Training epoch 557 iteration 1846 of 1847\n",
      "Epoch 557 loss: 0.5988918353753536\n",
      "Saving model as weights/model_weights_557.pth\n",
      "Training epoch 558 iteration 1846 of 1847\n",
      "Epoch 558 loss: 0.60112933026305\n",
      "Saving model as weights/model_weights_558.pth\n",
      "Training epoch 559 iteration 1846 of 1847\n",
      "Epoch 559 loss: 0.5992933888821326\n",
      "Saving model as weights/model_weights_559.pth\n",
      "Training epoch 560 iteration 1846 of 1847\n",
      "Epoch 560 loss: 0.5996545169181803\n",
      "Saving model as weights/model_weights_560.pth\n",
      "Training epoch 561 iteration 1846 of 1847\n",
      "Epoch 561 loss: 0.6003412295982008\n",
      "Saving model as weights/model_weights_561.pth\n",
      "Training epoch 562 iteration 1846 of 1847\n",
      "Epoch 562 loss: 0.599666648657824\n",
      "Saving model as weights/model_weights_562.pth\n",
      "Training epoch 563 iteration 1846 of 1847\n",
      "Epoch 563 loss: 0.5988125555665027\n",
      "Saving model as weights/model_weights_563.pth\n",
      "Training epoch 564 iteration 1846 of 1847\n",
      "Epoch 564 loss: 0.5997380706737283\n",
      "Saving model as weights/model_weights_564.pth\n",
      "Training epoch 565 iteration 1846 of 1847\n",
      "Epoch 565 loss: 0.6000184688815957\n",
      "Saving model as weights/model_weights_565.pth\n",
      "Training epoch 566 iteration 1846 of 1847\n",
      "Epoch 566 loss: 0.599439401350992\n",
      "Saving model as weights/model_weights_566.pth\n",
      "Training epoch 567 iteration 1846 of 1847\n",
      "Epoch 567 loss: 0.5995526041091295\n",
      "Saving model as weights/model_weights_567.pth\n",
      "Training epoch 568 iteration 1846 of 1847\n",
      "Epoch 568 loss: 0.5984041735521832\n",
      "Saving model as weights/model_weights_568.pth\n",
      "Training epoch 569 iteration 1846 of 1847\n",
      "Epoch 569 loss: 0.5992464940968758\n",
      "Saving model as weights/model_weights_569.pth\n",
      "Training epoch 570 iteration 1846 of 1847\n",
      "Epoch 570 loss: 0.5982782582237582\n",
      "Saving model as weights/model_weights_570.pth\n",
      "Training epoch 571 iteration 1846 of 1847\n",
      "Epoch 571 loss: 0.5978654998344025\n",
      "Saving model as weights/model_weights_571.pth\n",
      "Training epoch 572 iteration 1846 of 1847\n",
      "Epoch 572 loss: 0.5993071282529547\n",
      "Saving model as weights/model_weights_572.pth\n",
      "Training epoch 573 iteration 1846 of 1847\n",
      "Epoch 573 loss: 0.5975740422057537\n",
      "Saving model as weights/model_weights_573.pth\n",
      "Training epoch 574 iteration 1846 of 1847\n",
      "Epoch 574 loss: 0.5990863244760727\n",
      "Saving model as weights/model_weights_574.pth\n",
      "Training epoch 575 iteration 1846 of 1847\n",
      "Epoch 575 loss: 0.5977785215548199\n",
      "Saving model as weights/model_weights_575.pth\n",
      "Training epoch 576 iteration 1846 of 1847\n",
      "Epoch 576 loss: 0.5984378819634738\n",
      "Saving model as weights/model_weights_576.pth\n",
      "Training epoch 577 iteration 1846 of 1847\n",
      "Epoch 577 loss: 0.5990762623923498\n",
      "Saving model as weights/model_weights_577.pth\n",
      "Training epoch 578 iteration 1846 of 1847\n",
      "Epoch 578 loss: 0.5970630850995884\n",
      "Saving model as weights/model_weights_578.pth\n",
      "Training epoch 579 iteration 1846 of 1847\n",
      "Epoch 579 loss: 0.5976054031395822\n",
      "Saving model as weights/model_weights_579.pth\n",
      "Training epoch 580 iteration 1846 of 1847\n",
      "Epoch 580 loss: 0.5975945139970402\n",
      "Saving model as weights/model_weights_580.pth\n",
      "Training epoch 581 iteration 1846 of 1847\n",
      "Epoch 581 loss: 0.5982560083778342\n",
      "Saving model as weights/model_weights_581.pth\n",
      "Training epoch 582 iteration 1846 of 1847\n",
      "Epoch 582 loss: 0.5977578805018323\n",
      "Saving model as weights/model_weights_582.pth\n",
      "Training epoch 583 iteration 1846 of 1847\n",
      "Epoch 583 loss: 0.5966608626137699\n",
      "Saving model as weights/model_weights_583.pth\n",
      "Training epoch 584 iteration 1846 of 1847\n",
      "Epoch 584 loss: 0.5991311807792511\n",
      "Saving model as weights/model_weights_584.pth\n",
      "Training epoch 585 iteration 1846 of 1847\n",
      "Epoch 585 loss: 0.5961970571866214\n",
      "Saving model as weights/model_weights_585.pth\n",
      "Training epoch 586 iteration 1846 of 1847\n",
      "Epoch 586 loss: 0.5976757978224793\n",
      "Saving model as weights/model_weights_586.pth\n",
      "Training epoch 587 iteration 1846 of 1847\n",
      "Epoch 587 loss: 0.5971995977272391\n",
      "Saving model as weights/model_weights_587.pth\n",
      "Training epoch 588 iteration 1846 of 1847\n",
      "Epoch 588 loss: 0.5977077058959666\n",
      "Saving model as weights/model_weights_588.pth\n",
      "Training epoch 589 iteration 1846 of 1847\n",
      "Epoch 589 loss: 0.5973148726423043\n",
      "Saving model as weights/model_weights_589.pth\n",
      "Training epoch 590 iteration 1846 of 1847\n",
      "Epoch 590 loss: 0.5956450739807868\n",
      "Saving model as weights/model_weights_590.pth\n",
      "Training epoch 591 iteration 1846 of 1847\n",
      "Epoch 591 loss: 0.5970700376409418\n",
      "Saving model as weights/model_weights_591.pth\n",
      "Training epoch 592 iteration 1846 of 1847\n",
      "Epoch 592 loss: 0.5961041875348971\n",
      "Saving model as weights/model_weights_592.pth\n",
      "Training epoch 593 iteration 1846 of 1847\n",
      "Epoch 593 loss: 0.5968040981903293\n",
      "Saving model as weights/model_weights_593.pth\n",
      "Training epoch 594 iteration 1846 of 1847\n",
      "Epoch 594 loss: 0.597111884393625\n",
      "Saving model as weights/model_weights_594.pth\n",
      "Training epoch 595 iteration 1846 of 1847\n",
      "Epoch 595 loss: 0.5977003628264005\n",
      "Saving model as weights/model_weights_595.pth\n",
      "Training epoch 596 iteration 1846 of 1847\n",
      "Epoch 596 loss: 0.5975130540845713\n",
      "Saving model as weights/model_weights_596.pth\n",
      "Training epoch 597 iteration 1846 of 1847\n",
      "Epoch 597 loss: 0.595707240447394\n",
      "Saving model as weights/model_weights_597.pth\n",
      "Training epoch 598 iteration 1846 of 1847\n",
      "Epoch 598 loss: 0.5970588646098995\n",
      "Saving model as weights/model_weights_598.pth\n",
      "Training epoch 599 iteration 1846 of 1847\n",
      "Epoch 599 loss: 0.5956465548996546\n",
      "Saving model as weights/model_weights_599.pth\n",
      "Training epoch 600 iteration 1846 of 1847\n",
      "Epoch 600 loss: 0.5964680242422277\n",
      "Saving model as weights/model_weights_600.pth\n",
      "Training epoch 601 iteration 1846 of 1847\n",
      "Epoch 601 loss: 0.5968177409093317\n",
      "Saving model as weights/model_weights_601.pth\n",
      "Training epoch 602 iteration 1846 of 1847\n",
      "Epoch 602 loss: 0.596868818943476\n",
      "Saving model as weights/model_weights_602.pth\n",
      "Training epoch 603 iteration 1846 of 1847\n",
      "Epoch 603 loss: 0.5949145674253711\n",
      "Saving model as weights/model_weights_603.pth\n",
      "Training epoch 604 iteration 1846 of 1847\n",
      "Epoch 604 loss: 0.5949353479216017\n",
      "Saving model as weights/model_weights_604.pth\n",
      "Training epoch 605 iteration 1846 of 1847\n",
      "Epoch 605 loss: 0.597212190539629\n",
      "Saving model as weights/model_weights_605.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 606 iteration 1846 of 1847\n",
      "Epoch 606 loss: 0.5963137113989916\n",
      "Saving model as weights/model_weights_606.pth\n",
      "Training epoch 607 iteration 1846 of 1847\n",
      "Epoch 607 loss: 0.5950228624009544\n",
      "Saving model as weights/model_weights_607.pth\n",
      "Training epoch 608 iteration 1846 of 1847\n",
      "Epoch 608 loss: 0.5967044254283874\n",
      "Saving model as weights/model_weights_608.pth\n",
      "Training epoch 609 iteration 1846 of 1847\n",
      "Epoch 609 loss: 0.5946342640782797\n",
      "Saving model as weights/model_weights_609.pth\n",
      "Training epoch 610 iteration 1846 of 1847\n",
      "Epoch 610 loss: 0.596432385150329\n",
      "Saving model as weights/model_weights_610.pth\n",
      "Training epoch 611 iteration 1846 of 1847\n",
      "Epoch 611 loss: 0.5964085311262299\n",
      "Saving model as weights/model_weights_611.pth\n",
      "Training epoch 612 iteration 1846 of 1847\n",
      "Epoch 612 loss: 0.5946714201035471\n",
      "Saving model as weights/model_weights_612.pth\n",
      "Training epoch 613 iteration 1846 of 1847\n",
      "Epoch 613 loss: 0.5948257707361925\n",
      "Saving model as weights/model_weights_613.pth\n",
      "Training epoch 614 iteration 1846 of 1847\n",
      "Epoch 614 loss: 0.595714802847208\n",
      "Saving model as weights/model_weights_614.pth\n",
      "Training epoch 615 iteration 1846 of 1847\n",
      "Epoch 615 loss: 0.5963065770909021\n",
      "Saving model as weights/model_weights_615.pth\n",
      "Training epoch 616 iteration 1846 of 1847\n",
      "Epoch 616 loss: 0.596387418964197\n",
      "Saving model as weights/model_weights_616.pth\n",
      "Training epoch 617 iteration 1846 of 1847\n",
      "Epoch 617 loss: 0.5954451709582345\n",
      "Saving model as weights/model_weights_617.pth\n",
      "Training epoch 618 iteration 1846 of 1847\n",
      "Epoch 618 loss: 0.5945601974652791\n",
      "Saving model as weights/model_weights_618.pth\n",
      "Training epoch 619 iteration 1846 of 1847\n",
      "Epoch 619 loss: 0.5938139477806216\n",
      "Saving model as weights/model_weights_619.pth\n",
      "Training epoch 620 iteration 1846 of 1847\n",
      "Epoch 620 loss: 0.5956817517651051\n",
      "Saving model as weights/model_weights_620.pth\n",
      "Training epoch 621 iteration 1846 of 1847\n",
      "Epoch 621 loss: 0.5948634620899114\n",
      "Saving model as weights/model_weights_621.pth\n",
      "Training epoch 622 iteration 1846 of 1847\n",
      "Epoch 622 loss: 0.5945082210855479\n",
      "Saving model as weights/model_weights_622.pth\n",
      "Training epoch 623 iteration 1846 of 1847\n",
      "Epoch 623 loss: 0.5942261413780495\n",
      "Saving model as weights/model_weights_623.pth\n",
      "Training epoch 624 iteration 1846 of 1847\n",
      "Epoch 624 loss: 0.5949091850162262\n",
      "Saving model as weights/model_weights_624.pth\n",
      "Training epoch 625 iteration 1846 of 1847\n",
      "Epoch 625 loss: 0.5950300041313874\n",
      "Saving model as weights/model_weights_625.pth\n",
      "Training epoch 626 iteration 1846 of 1847\n",
      "Epoch 626 loss: 0.5938069505277168\n",
      "Saving model as weights/model_weights_626.pth\n",
      "Training epoch 627 iteration 1846 of 1847\n",
      "Epoch 627 loss: 0.5951642218672655\n",
      "Saving model as weights/model_weights_627.pth\n",
      "Training epoch 628 iteration 1846 of 1847\n",
      "Epoch 628 loss: 0.5928727758530997\n",
      "Saving model as weights/model_weights_628.pth\n",
      "Training epoch 629 iteration 1846 of 1847\n",
      "Epoch 629 loss: 0.5945393705955375\n",
      "Saving model as weights/model_weights_629.pth\n",
      "Training epoch 630 iteration 1846 of 1847\n",
      "Epoch 630 loss: 0.594754252939787\n",
      "Saving model as weights/model_weights_630.pth\n",
      "Training epoch 631 iteration 1846 of 1847\n",
      "Epoch 631 loss: 0.5962786417621887\n",
      "Saving model as weights/model_weights_631.pth\n",
      "Training epoch 632 iteration 1846 of 1847\n",
      "Epoch 632 loss: 0.594782269882007\n",
      "Saving model as weights/model_weights_632.pth\n",
      "Training epoch 633 iteration 1846 of 1847\n",
      "Epoch 633 loss: 0.5949164004860276\n",
      "Saving model as weights/model_weights_633.pth\n",
      "Training epoch 634 iteration 1846 of 1847\n",
      "Epoch 634 loss: 0.5944702304823049\n",
      "Saving model as weights/model_weights_634.pth\n",
      "Training epoch 635 iteration 1846 of 1847\n",
      "Epoch 635 loss: 0.5938924130518242\n",
      "Saving model as weights/model_weights_635.pth\n",
      "Training epoch 636 iteration 1846 of 1847\n",
      "Epoch 636 loss: 0.5932244113411979\n",
      "Saving model as weights/model_weights_636.pth\n",
      "Training epoch 637 iteration 1846 of 1847\n",
      "Epoch 637 loss: 0.5935888141635695\n",
      "Saving model as weights/model_weights_637.pth\n",
      "Training epoch 638 iteration 1846 of 1847\n",
      "Epoch 638 loss: 0.593436771879728\n",
      "Saving model as weights/model_weights_638.pth\n",
      "Training epoch 639 iteration 1846 of 1847\n",
      "Epoch 639 loss: 0.5929274774268956\n",
      "Saving model as weights/model_weights_639.pth\n",
      "Training epoch 640 iteration 1846 of 1847\n",
      "Epoch 640 loss: 0.594609188142827\n",
      "Saving model as weights/model_weights_640.pth\n",
      "Training epoch 641 iteration 1846 of 1847\n",
      "Epoch 641 loss: 0.5936854654831311\n",
      "Saving model as weights/model_weights_641.pth\n",
      "Training epoch 642 iteration 1846 of 1847\n",
      "Epoch 642 loss: 0.592431698496689\n",
      "Saving model as weights/model_weights_642.pth\n",
      "Training epoch 643 iteration 1846 of 1847\n",
      "Epoch 643 loss: 0.5932625364824831\n",
      "Saving model as weights/model_weights_643.pth\n",
      "Training epoch 644 iteration 1846 of 1847\n",
      "Epoch 644 loss: 0.5937841556397527\n",
      "Saving model as weights/model_weights_644.pth\n",
      "Training epoch 645 iteration 1846 of 1847\n",
      "Epoch 645 loss: 0.5928573125623404\n",
      "Saving model as weights/model_weights_645.pth\n",
      "Training epoch 646 iteration 1846 of 1847\n",
      "Epoch 646 loss: 0.5927814244094513\n",
      "Saving model as weights/model_weights_646.pth\n",
      "Training epoch 647 iteration 1846 of 1847\n",
      "Epoch 647 loss: 0.5930510435997634\n",
      "Saving model as weights/model_weights_647.pth\n",
      "Training epoch 648 iteration 1846 of 1847\n",
      "Epoch 648 loss: 0.5921784474776123\n",
      "Saving model as weights/model_weights_648.pth\n",
      "Training epoch 649 iteration 1846 of 1847\n",
      "Epoch 649 loss: 0.5927348524799977\n",
      "Saving model as weights/model_weights_649.pth\n",
      "Training epoch 650 iteration 1846 of 1847\n",
      "Epoch 650 loss: 0.5923704171606703\n",
      "Saving model as weights/model_weights_650.pth\n",
      "Training epoch 651 iteration 1846 of 1847\n",
      "Epoch 651 loss: 0.593177932158766\n",
      "Saving model as weights/model_weights_651.pth\n",
      "Training epoch 652 iteration 1846 of 1847\n",
      "Epoch 652 loss: 0.5910043230751236\n",
      "Saving model as weights/model_weights_652.pth\n",
      "Training epoch 653 iteration 1846 of 1847\n",
      "Epoch 653 loss: 0.5921046219294176\n",
      "Saving model as weights/model_weights_653.pth\n",
      "Training epoch 654 iteration 1846 of 1847\n",
      "Epoch 654 loss: 0.5923876875822907\n",
      "Saving model as weights/model_weights_654.pth\n",
      "Training epoch 655 iteration 1846 of 1847\n",
      "Epoch 655 loss: 0.5910310128862043\n",
      "Saving model as weights/model_weights_655.pth\n",
      "Training epoch 656 iteration 1846 of 1847\n",
      "Epoch 656 loss: 0.5916632517454233\n",
      "Saving model as weights/model_weights_656.pth\n",
      "Training epoch 657 iteration 1846 of 1847\n",
      "Epoch 657 loss: 0.5909592488454881\n",
      "Saving model as weights/model_weights_657.pth\n",
      "Training epoch 658 iteration 1846 of 1847\n",
      "Epoch 658 loss: 0.5909264965127079\n",
      "Saving model as weights/model_weights_658.pth\n",
      "Training epoch 659 iteration 1846 of 1847\n",
      "Epoch 659 loss: 0.5906202322609307\n",
      "Saving model as weights/model_weights_659.pth\n",
      "Training epoch 660 iteration 1846 of 1847\n",
      "Epoch 660 loss: 0.5925015373267415\n",
      "Saving model as weights/model_weights_660.pth\n",
      "Training epoch 661 iteration 1846 of 1847\n",
      "Epoch 661 loss: 0.5935761532431109\n",
      "Saving model as weights/model_weights_661.pth\n",
      "Training epoch 662 iteration 1846 of 1847\n",
      "Epoch 662 loss: 0.5923048684289794\n",
      "Saving model as weights/model_weights_662.pth\n",
      "Training epoch 663 iteration 1846 of 1847\n",
      "Epoch 663 loss: 0.5915774536991223\n",
      "Saving model as weights/model_weights_663.pth\n",
      "Training epoch 664 iteration 1846 of 1847\n",
      "Epoch 664 loss: 0.5915767243247969\n",
      "Saving model as weights/model_weights_664.pth\n",
      "Training epoch 665 iteration 1846 of 1847\n",
      "Epoch 665 loss: 0.591293569426312\n",
      "Saving model as weights/model_weights_665.pth\n",
      "Training epoch 666 iteration 1846 of 1847\n",
      "Epoch 666 loss: 0.5912185077513626\n",
      "Saving model as weights/model_weights_666.pth\n",
      "Training epoch 667 iteration 1846 of 1847\n",
      "Epoch 667 loss: 0.5918124001543781\n",
      "Saving model as weights/model_weights_667.pth\n",
      "Training epoch 668 iteration 1846 of 1847\n",
      "Epoch 668 loss: 0.5905925251370064\n",
      "Saving model as weights/model_weights_668.pth\n",
      "Training epoch 669 iteration 1846 of 1847\n",
      "Epoch 669 loss: 0.590686712286959\n",
      "Saving model as weights/model_weights_669.pth\n",
      "Training epoch 670 iteration 1846 of 1847\n",
      "Epoch 670 loss: 0.5904847695398925\n",
      "Saving model as weights/model_weights_670.pth\n",
      "Training epoch 671 iteration 1846 of 1847\n",
      "Epoch 671 loss: 0.5918126438492752\n",
      "Saving model as weights/model_weights_671.pth\n",
      "Training epoch 672 iteration 1846 of 1847\n",
      "Epoch 672 loss: 0.5903368174190707\n",
      "Saving model as weights/model_weights_672.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 673 iteration 1846 of 1847\n",
      "Epoch 673 loss: 0.5892830231122604\n",
      "Saving model as weights/model_weights_673.pth\n",
      "Training epoch 674 iteration 1846 of 1847\n",
      "Epoch 674 loss: 0.5920276507759455\n",
      "Saving model as weights/model_weights_674.pth\n",
      "Training epoch 675 iteration 1846 of 1847\n",
      "Epoch 675 loss: 0.5917265474247687\n",
      "Saving model as weights/model_weights_675.pth\n",
      "Training epoch 676 iteration 1846 of 1847\n",
      "Epoch 676 loss: 0.59066977808136\n",
      "Saving model as weights/model_weights_676.pth\n",
      "Training epoch 677 iteration 1846 of 1847\n",
      "Epoch 677 loss: 0.5921436228265489\n",
      "Saving model as weights/model_weights_677.pth\n",
      "Training epoch 678 iteration 1846 of 1847\n",
      "Epoch 678 loss: 0.5909091567889897\n",
      "Saving model as weights/model_weights_678.pth\n",
      "Training epoch 679 iteration 1846 of 1847\n",
      "Epoch 679 loss: 0.5908032389318356\n",
      "Saving model as weights/model_weights_679.pth\n",
      "Training epoch 680 iteration 1846 of 1847\n",
      "Epoch 680 loss: 0.5927583589770694\n",
      "Saving model as weights/model_weights_680.pth\n",
      "Training epoch 681 iteration 1846 of 1847\n",
      "Epoch 681 loss: 0.5897739244333524\n",
      "Saving model as weights/model_weights_681.pth\n",
      "Training epoch 682 iteration 1846 of 1847\n",
      "Epoch 682 loss: 0.5918200695972928\n",
      "Saving model as weights/model_weights_682.pth\n",
      "Training epoch 683 iteration 1846 of 1847\n",
      "Epoch 683 loss: 0.5900286818331619\n",
      "Saving model as weights/model_weights_683.pth\n",
      "Training epoch 684 iteration 1846 of 1847\n",
      "Epoch 684 loss: 0.5891475808833442\n",
      "Saving model as weights/model_weights_684.pth\n",
      "Training epoch 685 iteration 1846 of 1847\n",
      "Epoch 685 loss: 0.5905559347588498\n",
      "Saving model as weights/model_weights_685.pth\n",
      "Training epoch 686 iteration 1846 of 1847\n",
      "Epoch 686 loss: 0.5901111459241536\n",
      "Saving model as weights/model_weights_686.pth\n",
      "Training epoch 687 iteration 1846 of 1847\n",
      "Epoch 687 loss: 0.5894252241109601\n",
      "Saving model as weights/model_weights_687.pth\n",
      "Training epoch 688 iteration 1846 of 1847\n",
      "Epoch 688 loss: 0.5896756568501044\n",
      "Saving model as weights/model_weights_688.pth\n",
      "Training epoch 689 iteration 1846 of 1847\n",
      "Epoch 689 loss: 0.5909274737610324\n",
      "Saving model as weights/model_weights_689.pth\n",
      "Training epoch 690 iteration 1846 of 1847\n",
      "Epoch 690 loss: 0.5906707826148644\n",
      "Saving model as weights/model_weights_690.pth\n",
      "Training epoch 691 iteration 1846 of 1847\n",
      "Epoch 691 loss: 0.589540840582907\n",
      "Saving model as weights/model_weights_691.pth\n",
      "Training epoch 692 iteration 1846 of 1847\n",
      "Epoch 692 loss: 0.589837260822638\n",
      "Saving model as weights/model_weights_692.pth\n",
      "Training epoch 693 iteration 1846 of 1847\n",
      "Epoch 693 loss: 0.5889383813111151\n",
      "Saving model as weights/model_weights_693.pth\n",
      "Training epoch 694 iteration 1846 of 1847\n",
      "Epoch 694 loss: 0.5907607707192463\n",
      "Saving model as weights/model_weights_694.pth\n",
      "Training epoch 695 iteration 1846 of 1847\n",
      "Epoch 695 loss: 0.5888393038856576\n",
      "Saving model as weights/model_weights_695.pth\n",
      "Training epoch 696 iteration 1846 of 1847\n",
      "Epoch 696 loss: 0.5910916127865549\n",
      "Saving model as weights/model_weights_696.pth\n",
      "Training epoch 697 iteration 1846 of 1847\n",
      "Epoch 697 loss: 0.5896757575680774\n",
      "Saving model as weights/model_weights_697.pth\n",
      "Training epoch 698 iteration 1846 of 1847\n",
      "Epoch 698 loss: 0.5894257945825941\n",
      "Saving model as weights/model_weights_698.pth\n",
      "Training epoch 699 iteration 1846 of 1847\n",
      "Epoch 699 loss: 0.5897226438499104\n",
      "Saving model as weights/model_weights_699.pth\n",
      "Training epoch 700 iteration 1846 of 1847\n",
      "Epoch 700 loss: 0.5888572232459904\n",
      "Saving model as weights/model_weights_700.pth\n",
      "Training epoch 701 iteration 1846 of 1847\n",
      "Epoch 701 loss: 0.589693714701684\n",
      "Saving model as weights/model_weights_701.pth\n",
      "Training epoch 702 iteration 1846 of 1847\n",
      "Epoch 702 loss: 0.5885289014353905\n",
      "Saving model as weights/model_weights_702.pth\n",
      "Training epoch 703 iteration 1846 of 1847\n",
      "Epoch 703 loss: 0.5893805317608937\n",
      "Saving model as weights/model_weights_703.pth\n",
      "Training epoch 704 iteration 1846 of 1847\n",
      "Epoch 704 loss: 0.5888881754830003\n",
      "Saving model as weights/model_weights_704.pth\n",
      "Training epoch 705 iteration 1846 of 1847\n",
      "Epoch 705 loss: 0.5885824697141591\n",
      "Saving model as weights/model_weights_705.pth\n",
      "Training epoch 706 iteration 1846 of 1847\n",
      "Epoch 706 loss: 0.5888438420677805\n",
      "Saving model as weights/model_weights_706.pth\n",
      "Training epoch 707 iteration 1846 of 1847\n",
      "Epoch 707 loss: 0.5885890549624618\n",
      "Saving model as weights/model_weights_707.pth\n",
      "Training epoch 708 iteration 1846 of 1847\n",
      "Epoch 708 loss: 0.5878147184526075\n",
      "Saving model as weights/model_weights_708.pth\n",
      "Training epoch 709 iteration 1846 of 1847\n",
      "Epoch 709 loss: 0.5896322390132165\n",
      "Saving model as weights/model_weights_709.pth\n",
      "Training epoch 710 iteration 1846 of 1847\n",
      "Epoch 710 loss: 0.589500347149327\n",
      "Saving model as weights/model_weights_710.pth\n",
      "Training epoch 711 iteration 1846 of 1847\n",
      "Epoch 711 loss: 0.589067748497161\n",
      "Saving model as weights/model_weights_711.pth\n",
      "Training epoch 712 iteration 1846 of 1847\n",
      "Epoch 712 loss: 0.5886820402091171\n",
      "Saving model as weights/model_weights_712.pth\n",
      "Training epoch 713 iteration 1846 of 1847\n",
      "Epoch 713 loss: 0.5886602463209765\n",
      "Saving model as weights/model_weights_713.pth\n",
      "Training epoch 714 iteration 1846 of 1847\n",
      "Epoch 714 loss: 0.5898031656749841\n",
      "Saving model as weights/model_weights_714.pth\n",
      "Training epoch 715 iteration 1846 of 1847\n",
      "Epoch 715 loss: 0.588819284986404\n",
      "Saving model as weights/model_weights_715.pth\n",
      "Training epoch 716 iteration 1846 of 1847\n",
      "Epoch 716 loss: 0.588194693900084\n",
      "Saving model as weights/model_weights_716.pth\n",
      "Training epoch 717 iteration 1846 of 1847\n",
      "Epoch 717 loss: 0.5877683920413659\n",
      "Saving model as weights/model_weights_717.pth\n",
      "Training epoch 718 iteration 1846 of 1847\n",
      "Epoch 718 loss: 0.5879856221051105\n",
      "Saving model as weights/model_weights_718.pth\n",
      "Training epoch 719 iteration 1846 of 1847\n",
      "Epoch 719 loss: 0.5894040510373045\n",
      "Saving model as weights/model_weights_719.pth\n",
      "Training epoch 720 iteration 1846 of 1847\n",
      "Epoch 720 loss: 0.5878831516844425\n",
      "Saving model as weights/model_weights_720.pth\n",
      "Training epoch 721 iteration 1846 of 1847\n",
      "Epoch 721 loss: 0.5886600520976117\n",
      "Saving model as weights/model_weights_721.pth\n",
      "Training epoch 722 iteration 1846 of 1847\n",
      "Epoch 722 loss: 0.5873989789435589\n",
      "Saving model as weights/model_weights_722.pth\n",
      "Training epoch 723 iteration 1846 of 1847\n",
      "Epoch 723 loss: 0.5876947605551806\n",
      "Saving model as weights/model_weights_723.pth\n",
      "Training epoch 724 iteration 1846 of 1847\n",
      "Epoch 724 loss: 0.5881122304061069\n",
      "Saving model as weights/model_weights_724.pth\n",
      "Training epoch 725 iteration 1846 of 1847\n",
      "Epoch 725 loss: 0.5874444940119868\n",
      "Saving model as weights/model_weights_725.pth\n",
      "Training epoch 726 iteration 1846 of 1847\n",
      "Epoch 726 loss: 0.5887715831826555\n",
      "Saving model as weights/model_weights_726.pth\n",
      "Training epoch 727 iteration 1846 of 1847\n",
      "Epoch 727 loss: 0.5868963422359618\n",
      "Saving model as weights/model_weights_727.pth\n",
      "Training epoch 728 iteration 1846 of 1847\n",
      "Epoch 728 loss: 0.5879199010782391\n",
      "Saving model as weights/model_weights_728.pth\n",
      "Training epoch 729 iteration 1846 of 1847\n",
      "Epoch 729 loss: 0.5884190069286643\n",
      "Saving model as weights/model_weights_729.pth\n",
      "Training epoch 730 iteration 1846 of 1847\n",
      "Epoch 730 loss: 0.5876606732171229\n",
      "Saving model as weights/model_weights_730.pth\n",
      "Training epoch 731 iteration 1846 of 1847\n",
      "Epoch 731 loss: 0.5885379891267776\n",
      "Saving model as weights/model_weights_731.pth\n",
      "Training epoch 732 iteration 1846 of 1847\n",
      "Epoch 732 loss: 0.5873578823800337\n",
      "Saving model as weights/model_weights_732.pth\n",
      "Training epoch 733 iteration 1846 of 1847\n",
      "Epoch 733 loss: 0.5866102032165754\n",
      "Saving model as weights/model_weights_733.pth\n",
      "Training epoch 734 iteration 1846 of 1847\n",
      "Epoch 734 loss: 0.5879661793249261\n",
      "Saving model as weights/model_weights_734.pth\n",
      "Training epoch 735 iteration 1846 of 1847\n",
      "Epoch 735 loss: 0.5877702015441498\n",
      "Saving model as weights/model_weights_735.pth\n",
      "Training epoch 736 iteration 1846 of 1847\n",
      "Epoch 736 loss: 0.5876608370572861\n",
      "Saving model as weights/model_weights_736.pth\n",
      "Training epoch 737 iteration 1846 of 1847\n",
      "Epoch 737 loss: 0.5881695877105143\n",
      "Saving model as weights/model_weights_737.pth\n",
      "Training epoch 738 iteration 1846 of 1847\n",
      "Epoch 738 loss: 0.5858199965747292\n",
      "Saving model as weights/model_weights_738.pth\n",
      "Training epoch 739 iteration 1846 of 1847\n",
      "Epoch 739 loss: 0.5881126504784735\n",
      "Saving model as weights/model_weights_739.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 740 iteration 1846 of 1847\n",
      "Epoch 740 loss: 0.5881182112981644\n",
      "Saving model as weights/model_weights_740.pth\n",
      "Training epoch 741 iteration 1846 of 1847\n",
      "Epoch 741 loss: 0.5887427196737619\n",
      "Saving model as weights/model_weights_741.pth\n",
      "Training epoch 742 iteration 1846 of 1847\n",
      "Epoch 742 loss: 0.5870650414847398\n",
      "Saving model as weights/model_weights_742.pth\n",
      "Training epoch 743 iteration 1846 of 1847\n",
      "Epoch 743 loss: 0.58750651201559\n",
      "Saving model as weights/model_weights_743.pth\n",
      "Training epoch 744 iteration 1846 of 1847\n",
      "Epoch 744 loss: 0.5867165314325076\n",
      "Saving model as weights/model_weights_744.pth\n",
      "Training epoch 745 iteration 1846 of 1847\n",
      "Epoch 745 loss: 0.586486383635222\n",
      "Saving model as weights/model_weights_745.pth\n",
      "Training epoch 746 iteration 1846 of 1847\n",
      "Epoch 746 loss: 0.5866124455710651\n",
      "Saving model as weights/model_weights_746.pth\n",
      "Training epoch 747 iteration 1846 of 1847\n",
      "Epoch 747 loss: 0.5868718475345411\n",
      "Saving model as weights/model_weights_747.pth\n",
      "Training epoch 748 iteration 1846 of 1847\n",
      "Epoch 748 loss: 0.5861993805905193\n",
      "Saving model as weights/model_weights_748.pth\n",
      "Training epoch 749 iteration 1846 of 1847\n",
      "Epoch 749 loss: 0.5875027899846684\n",
      "Saving model as weights/model_weights_749.pth\n",
      "Training epoch 750 iteration 1846 of 1847\n",
      "Epoch 750 loss: 0.5854098453319067\n",
      "Saving model as weights/model_weights_750.pth\n",
      "Training epoch 751 iteration 1846 of 1847\n",
      "Epoch 751 loss: 0.5866108028935173\n",
      "Saving model as weights/model_weights_751.pth\n",
      "Training epoch 752 iteration 1846 of 1847\n",
      "Epoch 752 loss: 0.5851653247474656\n",
      "Saving model as weights/model_weights_752.pth\n",
      "Training epoch 753 iteration 1846 of 1847\n",
      "Epoch 753 loss: 0.5852997086792943\n",
      "Saving model as weights/model_weights_753.pth\n",
      "Training epoch 754 iteration 1846 of 1847\n",
      "Epoch 754 loss: 0.5858467351635147\n",
      "Saving model as weights/model_weights_754.pth\n",
      "Training epoch 755 iteration 1846 of 1847\n",
      "Epoch 755 loss: 0.5861235700333899\n",
      "Saving model as weights/model_weights_755.pth\n",
      "Training epoch 756 iteration 1846 of 1847\n",
      "Epoch 756 loss: 0.5858850850243148\n",
      "Saving model as weights/model_weights_756.pth\n",
      "Training epoch 757 iteration 1846 of 1847\n",
      "Epoch 757 loss: 0.585873495035063\n",
      "Saving model as weights/model_weights_757.pth\n",
      "Training epoch 758 iteration 1846 of 1847\n",
      "Epoch 758 loss: 0.5853761839234125\n",
      "Saving model as weights/model_weights_758.pth\n",
      "Training epoch 759 iteration 1846 of 1847\n",
      "Epoch 759 loss: 0.5853506242447952\n",
      "Saving model as weights/model_weights_759.pth\n",
      "Training epoch 760 iteration 1846 of 1847\n",
      "Epoch 760 loss: 0.5856917222480743\n",
      "Saving model as weights/model_weights_760.pth\n",
      "Training epoch 761 iteration 1846 of 1847\n",
      "Epoch 761 loss: 0.5868447174171403\n",
      "Saving model as weights/model_weights_761.pth\n",
      "Training epoch 762 iteration 1846 of 1847\n",
      "Epoch 762 loss: 0.585610441343166\n",
      "Saving model as weights/model_weights_762.pth\n",
      "Training epoch 763 iteration 1846 of 1847\n",
      "Epoch 763 loss: 0.5855554085553628\n",
      "Saving model as weights/model_weights_763.pth\n",
      "Training epoch 764 iteration 1846 of 1847\n",
      "Epoch 764 loss: 0.5861790020141849\n",
      "Saving model as weights/model_weights_764.pth\n",
      "Training epoch 765 iteration 1846 of 1847\n",
      "Epoch 765 loss: 0.5844147706199608\n",
      "Saving model as weights/model_weights_765.pth\n",
      "Training epoch 766 iteration 1846 of 1847\n",
      "Epoch 766 loss: 0.5854233630166934\n",
      "Saving model as weights/model_weights_766.pth\n",
      "Training epoch 767 iteration 1846 of 1847\n",
      "Epoch 767 loss: 0.5850436380410362\n",
      "Saving model as weights/model_weights_767.pth\n",
      "Training epoch 768 iteration 1846 of 1847\n",
      "Epoch 768 loss: 0.5857940770092692\n",
      "Saving model as weights/model_weights_768.pth\n",
      "Training epoch 769 iteration 1846 of 1847\n",
      "Epoch 769 loss: 0.5855328633324417\n",
      "Saving model as weights/model_weights_769.pth\n",
      "Training epoch 770 iteration 1846 of 1847\n",
      "Epoch 770 loss: 0.584984182504686\n",
      "Saving model as weights/model_weights_770.pth\n",
      "Training epoch 771 iteration 1846 of 1847\n",
      "Epoch 771 loss: 0.5861722115058156\n",
      "Saving model as weights/model_weights_771.pth\n",
      "Training epoch 772 iteration 1846 of 1847\n",
      "Epoch 772 loss: 0.586004307286831\n",
      "Saving model as weights/model_weights_772.pth\n",
      "Training epoch 773 iteration 1846 of 1847\n",
      "Epoch 773 loss: 0.585666326764602\n",
      "Saving model as weights/model_weights_773.pth\n",
      "Training epoch 774 iteration 1846 of 1847\n",
      "Epoch 774 loss: 0.5851494787864964\n",
      "Saving model as weights/model_weights_774.pth\n",
      "Training epoch 775 iteration 1846 of 1847\n",
      "Epoch 775 loss: 0.5838843975992672\n",
      "Saving model as weights/model_weights_775.pth\n",
      "Training epoch 776 iteration 1846 of 1847\n",
      "Epoch 776 loss: 0.5849468609127536\n",
      "Saving model as weights/model_weights_776.pth\n",
      "Training epoch 777 iteration 1846 of 1847\n",
      "Epoch 777 loss: 0.585369054343033\n",
      "Saving model as weights/model_weights_777.pth\n",
      "Training epoch 778 iteration 1846 of 1847\n",
      "Epoch 778 loss: 0.5847642571621479\n",
      "Saving model as weights/model_weights_778.pth\n",
      "Training epoch 779 iteration 1846 of 1847\n",
      "Epoch 779 loss: 0.5838485980556666\n",
      "Saving model as weights/model_weights_779.pth\n",
      "Training epoch 780 iteration 1846 of 1847\n",
      "Epoch 780 loss: 0.5856116505397224\n",
      "Saving model as weights/model_weights_780.pth\n",
      "Training epoch 781 iteration 1846 of 1847\n",
      "Epoch 781 loss: 0.583598850640853\n",
      "Saving model as weights/model_weights_781.pth\n",
      "Training epoch 782 iteration 1846 of 1847\n",
      "Epoch 782 loss: 0.5853440367052474\n",
      "Saving model as weights/model_weights_782.pth\n",
      "Training epoch 783 iteration 1846 of 1847\n",
      "Epoch 783 loss: 0.5829270641320966\n",
      "Saving model as weights/model_weights_783.pth\n",
      "Training epoch 784 iteration 1846 of 1847\n",
      "Epoch 784 loss: 0.585037513236194\n",
      "Saving model as weights/model_weights_784.pth\n",
      "Training epoch 785 iteration 1846 of 1847\n",
      "Epoch 785 loss: 0.5851534285220057\n",
      "Saving model as weights/model_weights_785.pth\n",
      "Training epoch 786 iteration 1846 of 1847\n",
      "Epoch 786 loss: 0.5847227381866044\n",
      "Saving model as weights/model_weights_786.pth\n",
      "Training epoch 787 iteration 1846 of 1847\n",
      "Epoch 787 loss: 0.5845186588050355\n",
      "Saving model as weights/model_weights_787.pth\n",
      "Training epoch 788 iteration 1846 of 1847\n",
      "Epoch 788 loss: 0.5844923264766037\n",
      "Saving model as weights/model_weights_788.pth\n",
      "Training epoch 789 iteration 1846 of 1847\n",
      "Epoch 789 loss: 0.5840831449790845\n",
      "Saving model as weights/model_weights_789.pth\n",
      "Training epoch 790 iteration 1846 of 1847\n",
      "Epoch 790 loss: 0.5836794559350192\n",
      "Saving model as weights/model_weights_790.pth\n",
      "Training epoch 791 iteration 1846 of 1847\n",
      "Epoch 791 loss: 0.5845526768409954\n",
      "Saving model as weights/model_weights_791.pth\n",
      "Training epoch 792 iteration 1846 of 1847\n",
      "Epoch 792 loss: 0.5833229175857034\n",
      "Saving model as weights/model_weights_792.pth\n",
      "Training epoch 793 iteration 1846 of 1847\n",
      "Epoch 793 loss: 0.5846419038970082\n",
      "Saving model as weights/model_weights_793.pth\n",
      "Training epoch 794 iteration 1846 of 1847\n",
      "Epoch 794 loss: 0.5842775524178904\n",
      "Saving model as weights/model_weights_794.pth\n",
      "Training epoch 795 iteration 1846 of 1847\n",
      "Epoch 795 loss: 0.5845663020690841\n",
      "Saving model as weights/model_weights_795.pth\n",
      "Training epoch 796 iteration 1846 of 1847\n",
      "Epoch 796 loss: 0.5829464942942972\n",
      "Saving model as weights/model_weights_796.pth\n",
      "Training epoch 797 iteration 1846 of 1847\n",
      "Epoch 797 loss: 0.5851002834943029\n",
      "Saving model as weights/model_weights_797.pth\n",
      "Training epoch 798 iteration 1846 of 1847\n",
      "Epoch 798 loss: 0.5827121325422121\n",
      "Saving model as weights/model_weights_798.pth\n",
      "Training epoch 799 iteration 1846 of 1847\n",
      "Epoch 799 loss: 0.5832528674286253\n",
      "Saving model as weights/model_weights_799.pth\n",
      "Training epoch 800 iteration 1846 of 1847\n",
      "Epoch 800 loss: 0.5836350554605401\n",
      "Saving model as weights/model_weights_800.pth\n",
      "Training epoch 801 iteration 1846 of 1847\n",
      "Epoch 801 loss: 0.584241363104447\n",
      "Saving model as weights/model_weights_801.pth\n",
      "Training epoch 802 iteration 1846 of 1847\n",
      "Epoch 802 loss: 0.5831171745826699\n",
      "Saving model as weights/model_weights_802.pth\n",
      "Training epoch 803 iteration 1846 of 1847\n",
      "Epoch 803 loss: 0.5827158245933204\n",
      "Saving model as weights/model_weights_803.pth\n",
      "Training epoch 804 iteration 1846 of 1847\n",
      "Epoch 804 loss: 0.5828152366373819\n",
      "Saving model as weights/model_weights_804.pth\n",
      "Training epoch 805 iteration 1846 of 1847\n",
      "Epoch 805 loss: 0.5834307042759822\n",
      "Saving model as weights/model_weights_805.pth\n",
      "Training epoch 806 iteration 1846 of 1847\n",
      "Epoch 806 loss: 0.5821291322506759\n",
      "Saving model as weights/model_weights_806.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 807 iteration 1846 of 1847\n",
      "Epoch 807 loss: 0.5839484274290546\n",
      "Saving model as weights/model_weights_807.pth\n",
      "Training epoch 808 iteration 1846 of 1847\n",
      "Epoch 808 loss: 0.5826057301673879\n",
      "Saving model as weights/model_weights_808.pth\n",
      "Training epoch 809 iteration 1846 of 1847\n",
      "Epoch 809 loss: 0.5830897682895516\n",
      "Saving model as weights/model_weights_809.pth\n",
      "Training epoch 810 iteration 1846 of 1847\n",
      "Epoch 810 loss: 0.5837320224555944\n",
      "Saving model as weights/model_weights_810.pth\n",
      "Training epoch 811 iteration 1846 of 1847\n",
      "Epoch 811 loss: 0.5837380536098253\n",
      "Saving model as weights/model_weights_811.pth\n",
      "Training epoch 812 iteration 1846 of 1847\n",
      "Epoch 812 loss: 0.582030911508869\n",
      "Saving model as weights/model_weights_812.pth\n",
      "Training epoch 813 iteration 1846 of 1847\n",
      "Epoch 813 loss: 0.5832644971919563\n",
      "Saving model as weights/model_weights_813.pth\n",
      "Training epoch 814 iteration 1846 of 1847\n",
      "Epoch 814 loss: 0.5825090258910195\n",
      "Saving model as weights/model_weights_814.pth\n",
      "Training epoch 815 iteration 1846 of 1847\n",
      "Epoch 815 loss: 0.582258474588007\n",
      "Saving model as weights/model_weights_815.pth\n",
      "Training epoch 816 iteration 1846 of 1847\n",
      "Epoch 816 loss: 0.5829362758250255\n",
      "Saving model as weights/model_weights_816.pth\n",
      "Training epoch 817 iteration 1846 of 1847\n",
      "Epoch 817 loss: 0.5828127524597166\n",
      "Saving model as weights/model_weights_817.pth\n",
      "Training epoch 818 iteration 1846 of 1847\n",
      "Epoch 818 loss: 0.5820393927302564\n",
      "Saving model as weights/model_weights_818.pth\n",
      "Training epoch 819 iteration 1846 of 1847\n",
      "Epoch 819 loss: 0.583502408695918\n",
      "Saving model as weights/model_weights_819.pth\n",
      "Training epoch 820 iteration 1846 of 1847\n",
      "Epoch 820 loss: 0.5819973759090958\n",
      "Saving model as weights/model_weights_820.pth\n",
      "Training epoch 821 iteration 1846 of 1847\n",
      "Epoch 821 loss: 0.5832771477856763\n",
      "Saving model as weights/model_weights_821.pth\n",
      "Training epoch 822 iteration 1846 of 1847\n",
      "Epoch 822 loss: 0.582693805130482\n",
      "Saving model as weights/model_weights_822.pth\n",
      "Training epoch 823 iteration 1846 of 1847\n",
      "Epoch 823 loss: 0.5829518879660414\n",
      "Saving model as weights/model_weights_823.pth\n",
      "Training epoch 824 iteration 1846 of 1847\n",
      "Epoch 824 loss: 0.5821873558555091\n",
      "Saving model as weights/model_weights_824.pth\n",
      "Training epoch 825 iteration 1846 of 1847\n",
      "Epoch 825 loss: 0.582409727796065\n",
      "Saving model as weights/model_weights_825.pth\n",
      "Training epoch 826 iteration 1846 of 1847\n",
      "Epoch 826 loss: 0.5815452919757618\n",
      "Saving model as weights/model_weights_826.pth\n",
      "Training epoch 827 iteration 1846 of 1847\n",
      "Epoch 827 loss: 0.5825185180517165\n",
      "Saving model as weights/model_weights_827.pth\n",
      "Training epoch 828 iteration 1846 of 1847\n",
      "Epoch 828 loss: 0.5831912030835505\n",
      "Saving model as weights/model_weights_828.pth\n",
      "Training epoch 829 iteration 1846 of 1847\n",
      "Epoch 829 loss: 0.5823420800095193\n",
      "Saving model as weights/model_weights_829.pth\n",
      "Training epoch 830 iteration 1846 of 1847\n",
      "Epoch 830 loss: 0.5813835781202745\n",
      "Saving model as weights/model_weights_830.pth\n",
      "Training epoch 831 iteration 1846 of 1847\n",
      "Epoch 831 loss: 0.5825254140864466\n",
      "Saving model as weights/model_weights_831.pth\n",
      "Training epoch 832 iteration 1846 of 1847\n",
      "Epoch 832 loss: 0.5815326019629441\n",
      "Saving model as weights/model_weights_832.pth\n",
      "Training epoch 833 iteration 1846 of 1847\n",
      "Epoch 833 loss: 0.5821104297685701\n",
      "Saving model as weights/model_weights_833.pth\n",
      "Training epoch 834 iteration 1846 of 1847\n",
      "Epoch 834 loss: 0.5818446324396985\n",
      "Saving model as weights/model_weights_834.pth\n",
      "Training epoch 835 iteration 1846 of 1847\n",
      "Epoch 835 loss: 0.5827338495445561\n",
      "Saving model as weights/model_weights_835.pth\n",
      "Training epoch 836 iteration 1846 of 1847\n",
      "Epoch 836 loss: 0.5809955776189557\n",
      "Saving model as weights/model_weights_836.pth\n",
      "Training epoch 837 iteration 1846 of 1847\n",
      "Epoch 837 loss: 0.5829404782590571\n",
      "Saving model as weights/model_weights_837.pth\n",
      "Training epoch 838 iteration 1846 of 1847\n",
      "Epoch 838 loss: 0.5813690482376069\n",
      "Saving model as weights/model_weights_838.pth\n",
      "Training epoch 839 iteration 1846 of 1847\n",
      "Epoch 839 loss: 0.5811500569163107\n",
      "Saving model as weights/model_weights_839.pth\n",
      "Training epoch 840 iteration 1846 of 1847\n",
      "Epoch 840 loss: 0.5807367779463771\n",
      "Saving model as weights/model_weights_840.pth\n",
      "Training epoch 841 iteration 1846 of 1847\n",
      "Epoch 841 loss: 0.5818144730703212\n",
      "Saving model as weights/model_weights_841.pth\n",
      "Training epoch 842 iteration 1846 of 1847\n",
      "Epoch 842 loss: 0.5813293030085148\n",
      "Saving model as weights/model_weights_842.pth\n",
      "Training epoch 843 iteration 1846 of 1847\n",
      "Epoch 843 loss: 0.5809612073121229\n",
      "Saving model as weights/model_weights_843.pth\n",
      "Training epoch 844 iteration 1846 of 1847\n",
      "Epoch 844 loss: 0.5825540101650798\n",
      "Saving model as weights/model_weights_844.pth\n",
      "Training epoch 845 iteration 1846 of 1847\n",
      "Epoch 845 loss: 0.5813568326738892\n",
      "Saving model as weights/model_weights_845.pth\n",
      "Training epoch 846 iteration 1846 of 1847\n",
      "Epoch 846 loss: 0.5821124667984509\n",
      "Saving model as weights/model_weights_846.pth\n",
      "Training epoch 847 iteration 1846 of 1847\n",
      "Epoch 847 loss: 0.5811464551918947\n",
      "Saving model as weights/model_weights_847.pth\n",
      "Training epoch 848 iteration 1846 of 1847\n",
      "Epoch 848 loss: 0.5818748971256748\n",
      "Saving model as weights/model_weights_848.pth\n",
      "Training epoch 849 iteration 1846 of 1847\n",
      "Epoch 849 loss: 0.5804292619163821\n",
      "Saving model as weights/model_weights_849.pth\n",
      "Training epoch 850 iteration 1846 of 1847\n",
      "Epoch 850 loss: 0.58122347873743\n",
      "Saving model as weights/model_weights_850.pth\n",
      "Training epoch 851 iteration 1846 of 1847\n",
      "Epoch 851 loss: 0.582778737053848\n",
      "Saving model as weights/model_weights_851.pth\n",
      "Training epoch 852 iteration 1846 of 1847\n",
      "Epoch 852 loss: 0.5808704680988578\n",
      "Saving model as weights/model_weights_852.pth\n",
      "Training epoch 853 iteration 1846 of 1847\n",
      "Epoch 853 loss: 0.5804521983290726\n",
      "Saving model as weights/model_weights_853.pth\n",
      "Training epoch 854 iteration 1846 of 1847\n",
      "Epoch 854 loss: 0.5804661800878139\n",
      "Saving model as weights/model_weights_854.pth\n",
      "Training epoch 855 iteration 1846 of 1847\n",
      "Epoch 855 loss: 0.580210875984005\n",
      "Saving model as weights/model_weights_855.pth\n",
      "Training epoch 856 iteration 1846 of 1847\n",
      "Epoch 856 loss: 0.5810875470372362\n",
      "Saving model as weights/model_weights_856.pth\n",
      "Training epoch 857 iteration 1846 of 1847\n",
      "Epoch 857 loss: 0.5800493794902312\n",
      "Saving model as weights/model_weights_857.pth\n",
      "Training epoch 858 iteration 1846 of 1847\n",
      "Epoch 858 loss: 0.5800177698272205\n",
      "Saving model as weights/model_weights_858.pth\n",
      "Training epoch 859 iteration 1846 of 1847\n",
      "Epoch 859 loss: 0.5812257374372105\n",
      "Saving model as weights/model_weights_859.pth\n",
      "Training epoch 860 iteration 1846 of 1847\n",
      "Epoch 860 loss: 0.5803158956085209\n",
      "Saving model as weights/model_weights_860.pth\n",
      "Training epoch 861 iteration 1846 of 1847\n",
      "Epoch 861 loss: 0.5811535338001376\n",
      "Saving model as weights/model_weights_861.pth\n",
      "Training epoch 862 iteration 1846 of 1847\n",
      "Epoch 862 loss: 0.5807773117833223\n",
      "Saving model as weights/model_weights_862.pth\n",
      "Training epoch 863 iteration 1846 of 1847\n",
      "Epoch 863 loss: 0.5811801157613412\n",
      "Saving model as weights/model_weights_863.pth\n",
      "Training epoch 864 iteration 1846 of 1847\n",
      "Epoch 864 loss: 0.5805856924510092\n",
      "Saving model as weights/model_weights_864.pth\n",
      "Training epoch 865 iteration 1846 of 1847\n",
      "Epoch 865 loss: 0.5805927263315652\n",
      "Saving model as weights/model_weights_865.pth\n",
      "Training epoch 866 iteration 1846 of 1847\n",
      "Epoch 866 loss: 0.5798445172289222\n",
      "Saving model as weights/model_weights_866.pth\n",
      "Training epoch 867 iteration 1846 of 1847\n",
      "Epoch 867 loss: 0.5814136706240188\n",
      "Saving model as weights/model_weights_867.pth\n",
      "Training epoch 868 iteration 1846 of 1847\n",
      "Epoch 868 loss: 0.5777540045392533\n",
      "Saving model as weights/model_weights_868.pth\n",
      "Training epoch 869 iteration 1846 of 1847\n",
      "Epoch 869 loss: 0.5794880548134067\n",
      "Saving model as weights/model_weights_869.pth\n",
      "Training epoch 870 iteration 1846 of 1847\n",
      "Epoch 870 loss: 0.580999900424035\n",
      "Saving model as weights/model_weights_870.pth\n",
      "Training epoch 871 iteration 1846 of 1847\n",
      "Epoch 871 loss: 0.5808014390626081\n",
      "Saving model as weights/model_weights_871.pth\n",
      "Training epoch 872 iteration 1846 of 1847\n",
      "Epoch 872 loss: 0.5803792876976531\n",
      "Saving model as weights/model_weights_872.pth\n",
      "Training epoch 873 iteration 1846 of 1847\n",
      "Epoch 873 loss: 0.5800840616161654\n",
      "Saving model as weights/model_weights_873.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 874 iteration 1846 of 1847\n",
      "Epoch 874 loss: 0.5797157904458937\n",
      "Saving model as weights/model_weights_874.pth\n",
      "Training epoch 875 iteration 1846 of 1847\n",
      "Epoch 875 loss: 0.5800985803491823\n",
      "Saving model as weights/model_weights_875.pth\n",
      "Training epoch 876 iteration 1846 of 1847\n",
      "Epoch 876 loss: 0.5806761393046211\n",
      "Saving model as weights/model_weights_876.pth\n",
      "Training epoch 877 iteration 1846 of 1847\n",
      "Epoch 877 loss: 0.5807175109466476\n",
      "Saving model as weights/model_weights_877.pth\n",
      "Training epoch 878 iteration 1846 of 1847\n",
      "Epoch 878 loss: 0.5805983385913231\n",
      "Saving model as weights/model_weights_878.pth\n",
      "Training epoch 879 iteration 1846 of 1847\n",
      "Epoch 879 loss: 0.5794853215838486\n",
      "Saving model as weights/model_weights_879.pth\n",
      "Training epoch 880 iteration 1846 of 1847\n",
      "Epoch 880 loss: 0.5774872274126436\n",
      "Saving model as weights/model_weights_880.pth\n",
      "Training epoch 881 iteration 1846 of 1847\n",
      "Epoch 881 loss: 0.5798315958810227\n",
      "Saving model as weights/model_weights_881.pth\n",
      "Training epoch 882 iteration 1846 of 1847\n",
      "Epoch 882 loss: 0.5804038781311683\n",
      "Saving model as weights/model_weights_882.pth\n",
      "Training epoch 883 iteration 1846 of 1847\n",
      "Epoch 883 loss: 0.5792114257037995\n",
      "Saving model as weights/model_weights_883.pth\n",
      "Training epoch 884 iteration 1846 of 1847\n",
      "Epoch 884 loss: 0.5808912814631615\n",
      "Saving model as weights/model_weights_884.pth\n",
      "Training epoch 885 iteration 1846 of 1847\n",
      "Epoch 885 loss: 0.5797247733208832\n",
      "Saving model as weights/model_weights_885.pth\n",
      "Training epoch 886 iteration 1846 of 1847\n",
      "Epoch 886 loss: 0.5796444302452017\n",
      "Saving model as weights/model_weights_886.pth\n",
      "Training epoch 887 iteration 1846 of 1847\n",
      "Epoch 887 loss: 0.5789021028495184\n",
      "Saving model as weights/model_weights_887.pth\n",
      "Training epoch 888 iteration 1846 of 1847\n",
      "Epoch 888 loss: 0.5795685717010085\n",
      "Saving model as weights/model_weights_888.pth\n",
      "Training epoch 889 iteration 1846 of 1847\n",
      "Epoch 889 loss: 0.5794348047918155\n",
      "Saving model as weights/model_weights_889.pth\n",
      "Training epoch 890 iteration 1846 of 1847\n",
      "Epoch 890 loss: 0.580076370503235\n",
      "Saving model as weights/model_weights_890.pth\n",
      "Training epoch 891 iteration 1846 of 1847\n",
      "Epoch 891 loss: 0.5802390009858638\n",
      "Saving model as weights/model_weights_891.pth\n",
      "Training epoch 892 iteration 1846 of 1847\n",
      "Epoch 892 loss: 0.5790407376865083\n",
      "Saving model as weights/model_weights_892.pth\n",
      "Training epoch 893 iteration 1846 of 1847\n",
      "Epoch 893 loss: 0.5796806600426879\n",
      "Saving model as weights/model_weights_893.pth\n",
      "Training epoch 894 iteration 1846 of 1847\n",
      "Epoch 894 loss: 0.5785323347700694\n",
      "Saving model as weights/model_weights_894.pth\n",
      "Training epoch 895 iteration 1846 of 1847\n",
      "Epoch 895 loss: 0.5790323585384785\n",
      "Saving model as weights/model_weights_895.pth\n",
      "Training epoch 896 iteration 1846 of 1847\n",
      "Epoch 896 loss: 0.5800170444060998\n",
      "Saving model as weights/model_weights_896.pth\n",
      "Training epoch 897 iteration 1846 of 1847\n",
      "Epoch 897 loss: 0.5778333754654374\n",
      "Saving model as weights/model_weights_897.pth\n",
      "Training epoch 898 iteration 1846 of 1847\n",
      "Epoch 898 loss: 0.5806067476062176\n",
      "Saving model as weights/model_weights_898.pth\n",
      "Training epoch 899 iteration 1846 of 1847\n",
      "Epoch 899 loss: 0.5775451508966342\n",
      "Saving model as weights/model_weights_899.pth\n",
      "Training epoch 900 iteration 1846 of 1847\n",
      "Epoch 900 loss: 0.579260490491833\n",
      "Saving model as weights/model_weights_900.pth\n",
      "Training epoch 901 iteration 1846 of 1847\n",
      "Epoch 901 loss: 0.5793572224406339\n",
      "Saving model as weights/model_weights_901.pth\n",
      "Training epoch 902 iteration 1846 of 1847\n",
      "Epoch 902 loss: 0.5791298216526484\n",
      "Saving model as weights/model_weights_902.pth\n",
      "Training epoch 903 iteration 1846 of 1847\n",
      "Epoch 903 loss: 0.5786860210707075\n",
      "Saving model as weights/model_weights_903.pth\n",
      "Training epoch 904 iteration 1846 of 1847\n",
      "Epoch 904 loss: 0.578967313574144\n",
      "Saving model as weights/model_weights_904.pth\n",
      "Training epoch 905 iteration 1846 of 1847\n",
      "Epoch 905 loss: 0.5799056637848656\n",
      "Saving model as weights/model_weights_905.pth\n",
      "Training epoch 906 iteration 1846 of 1847\n",
      "Epoch 906 loss: 0.5774770647884383\n",
      "Saving model as weights/model_weights_906.pth\n",
      "Training epoch 907 iteration 1846 of 1847\n",
      "Epoch 907 loss: 0.5788792105997712\n",
      "Saving model as weights/model_weights_907.pth\n",
      "Training epoch 908 iteration 1846 of 1847\n",
      "Epoch 908 loss: 0.5807799102973473\n",
      "Saving model as weights/model_weights_908.pth\n",
      "Training epoch 909 iteration 1846 of 1847\n",
      "Epoch 909 loss: 0.5798653568457318\n",
      "Saving model as weights/model_weights_909.pth\n",
      "Training epoch 910 iteration 1846 of 1847\n",
      "Epoch 910 loss: 0.5797090968959191\n",
      "Saving model as weights/model_weights_910.pth\n",
      "Training epoch 911 iteration 1846 of 1847\n",
      "Epoch 911 loss: 0.5800918809420106\n",
      "Saving model as weights/model_weights_911.pth\n",
      "Training epoch 912 iteration 1846 of 1847\n",
      "Epoch 912 loss: 0.5790865447434723\n",
      "Saving model as weights/model_weights_912.pth\n",
      "Training epoch 913 iteration 1846 of 1847\n",
      "Epoch 913 loss: 0.5786491706684982\n",
      "Saving model as weights/model_weights_913.pth\n",
      "Training epoch 914 iteration 1846 of 1847\n",
      "Epoch 914 loss: 0.5792341135325274\n",
      "Saving model as weights/model_weights_914.pth\n",
      "Training epoch 915 iteration 1846 of 1847\n",
      "Epoch 915 loss: 0.5788812542613545\n",
      "Saving model as weights/model_weights_915.pth\n",
      "Training epoch 916 iteration 1846 of 1847\n",
      "Epoch 916 loss: 0.579192897340189\n",
      "Saving model as weights/model_weights_916.pth\n",
      "Training epoch 917 iteration 1846 of 1847\n",
      "Epoch 917 loss: 0.5782262938178806\n",
      "Saving model as weights/model_weights_917.pth\n",
      "Training epoch 918 iteration 1846 of 1847\n",
      "Epoch 918 loss: 0.5786622410441452\n",
      "Saving model as weights/model_weights_918.pth\n",
      "Training epoch 919 iteration 1846 of 1847\n",
      "Epoch 919 loss: 0.5787630285775268\n",
      "Saving model as weights/model_weights_919.pth\n",
      "Training epoch 920 iteration 1846 of 1847\n",
      "Epoch 920 loss: 0.577819310737805\n",
      "Saving model as weights/model_weights_920.pth\n",
      "Training epoch 921 iteration 1846 of 1847\n",
      "Epoch 921 loss: 0.5783297741774552\n",
      "Saving model as weights/model_weights_921.pth\n",
      "Training epoch 922 iteration 1846 of 1847\n",
      "Epoch 922 loss: 0.5784894446456632\n",
      "Saving model as weights/model_weights_922.pth\n",
      "Training epoch 923 iteration 1846 of 1847\n",
      "Epoch 923 loss: 0.5779943340006686\n",
      "Saving model as weights/model_weights_923.pth\n",
      "Training epoch 924 iteration 1846 of 1847\n",
      "Epoch 924 loss: 0.577928418798839\n",
      "Saving model as weights/model_weights_924.pth\n",
      "Training epoch 925 iteration 1846 of 1847\n",
      "Epoch 925 loss: 0.5782655921573566\n",
      "Saving model as weights/model_weights_925.pth\n",
      "Training epoch 926 iteration 1846 of 1847\n",
      "Epoch 926 loss: 0.5777257672502469\n",
      "Saving model as weights/model_weights_926.pth\n",
      "Training epoch 927 iteration 1846 of 1847\n",
      "Epoch 927 loss: 0.5777648141497719\n",
      "Saving model as weights/model_weights_927.pth\n",
      "Training epoch 928 iteration 1846 of 1847\n",
      "Epoch 928 loss: 0.57731519661275\n",
      "Saving model as weights/model_weights_928.pth\n",
      "Training epoch 929 iteration 1846 of 1847\n",
      "Epoch 929 loss: 0.5785443960781284\n",
      "Saving model as weights/model_weights_929.pth\n",
      "Training epoch 930 iteration 1846 of 1847\n",
      "Epoch 930 loss: 0.5782471970248106\n",
      "Saving model as weights/model_weights_930.pth\n",
      "Training epoch 931 iteration 1846 of 1847\n",
      "Epoch 931 loss: 0.5782585486277543\n",
      "Saving model as weights/model_weights_931.pth\n",
      "Training epoch 932 iteration 1846 of 1847\n",
      "Epoch 932 loss: 0.5769518922649336\n",
      "Saving model as weights/model_weights_932.pth\n",
      "Training epoch 933 iteration 1846 of 1847\n",
      "Epoch 933 loss: 0.5768867763849485\n",
      "Saving model as weights/model_weights_933.pth\n",
      "Training epoch 934 iteration 1846 of 1847\n",
      "Epoch 934 loss: 0.5776587811656171\n",
      "Saving model as weights/model_weights_934.pth\n",
      "Training epoch 935 iteration 1846 of 1847\n",
      "Epoch 935 loss: 0.5776295018280011\n",
      "Saving model as weights/model_weights_935.pth\n",
      "Training epoch 936 iteration 1846 of 1847\n",
      "Epoch 936 loss: 0.5775180278304595\n",
      "Saving model as weights/model_weights_936.pth\n",
      "Training epoch 937 iteration 1846 of 1847\n",
      "Epoch 937 loss: 0.5769866909539306\n",
      "Saving model as weights/model_weights_937.pth\n",
      "Training epoch 938 iteration 1846 of 1847\n",
      "Epoch 938 loss: 0.5779671481834209\n",
      "Saving model as weights/model_weights_938.pth\n",
      "Training epoch 939 iteration 1846 of 1847\n",
      "Epoch 939 loss: 0.5764796193154619\n",
      "Saving model as weights/model_weights_939.pth\n",
      "Training epoch 940 iteration 1846 of 1847\n",
      "Epoch 940 loss: 0.5779499042240684\n",
      "Saving model as weights/model_weights_940.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 941 iteration 1846 of 1847\n",
      "Epoch 941 loss: 0.5774802767752827\n",
      "Saving model as weights/model_weights_941.pth\n",
      "Training epoch 942 iteration 1846 of 1847\n",
      "Epoch 942 loss: 0.5783654051209116\n",
      "Saving model as weights/model_weights_942.pth\n",
      "Training epoch 943 iteration 1846 of 1847\n",
      "Epoch 943 loss: 0.5786520434542481\n",
      "Saving model as weights/model_weights_943.pth\n",
      "Training epoch 944 iteration 1846 of 1847\n",
      "Epoch 944 loss: 0.5767260004232301\n",
      "Saving model as weights/model_weights_944.pth\n",
      "Training epoch 945 iteration 1846 of 1847\n",
      "Epoch 945 loss: 0.5779219571486898\n",
      "Saving model as weights/model_weights_945.pth\n",
      "Training epoch 946 iteration 1846 of 1847\n",
      "Epoch 946 loss: 0.5767216112527191\n",
      "Saving model as weights/model_weights_946.pth\n",
      "Training epoch 947 iteration 1846 of 1847\n",
      "Epoch 947 loss: 0.5763574358283602\n",
      "Saving model as weights/model_weights_947.pth\n",
      "Training epoch 948 iteration 1846 of 1847\n",
      "Epoch 948 loss: 0.5765340271096779\n",
      "Saving model as weights/model_weights_948.pth\n",
      "Training epoch 949 iteration 1846 of 1847\n",
      "Epoch 949 loss: 0.5779327715191895\n",
      "Saving model as weights/model_weights_949.pth\n",
      "Training epoch 950 iteration 1846 of 1847\n",
      "Epoch 950 loss: 0.5785407051887781\n",
      "Saving model as weights/model_weights_950.pth\n",
      "Training epoch 951 iteration 1846 of 1847\n",
      "Epoch 951 loss: 0.5765961885581354\n",
      "Saving model as weights/model_weights_951.pth\n",
      "Training epoch 952 iteration 1846 of 1847\n",
      "Epoch 952 loss: 0.5768474630555658\n",
      "Saving model as weights/model_weights_952.pth\n",
      "Training epoch 953 iteration 1846 of 1847\n",
      "Epoch 953 loss: 0.5763564621943942\n",
      "Saving model as weights/model_weights_953.pth\n",
      "Training epoch 954 iteration 1846 of 1847\n",
      "Epoch 954 loss: 0.5770593413353999\n",
      "Saving model as weights/model_weights_954.pth\n",
      "Training epoch 955 iteration 1846 of 1847\n",
      "Epoch 955 loss: 0.5775767300796302\n",
      "Saving model as weights/model_weights_955.pth\n",
      "Training epoch 956 iteration 1846 of 1847\n",
      "Epoch 956 loss: 0.5775677522873324\n",
      "Saving model as weights/model_weights_956.pth\n",
      "Training epoch 957 iteration 1846 of 1847\n",
      "Epoch 957 loss: 0.5768571855993483\n",
      "Saving model as weights/model_weights_957.pth\n",
      "Training epoch 958 iteration 1846 of 1847\n",
      "Epoch 958 loss: 0.5774286579427425\n",
      "Saving model as weights/model_weights_958.pth\n",
      "Training epoch 959 iteration 1846 of 1847\n",
      "Epoch 959 loss: 0.5762273972106742\n",
      "Saving model as weights/model_weights_959.pth\n",
      "Training epoch 960 iteration 1846 of 1847\n",
      "Epoch 960 loss: 0.5757933373895283\n",
      "Saving model as weights/model_weights_960.pth\n",
      "Training epoch 961 iteration 1846 of 1847\n",
      "Epoch 961 loss: 0.5773572412192919\n",
      "Saving model as weights/model_weights_961.pth\n",
      "Training epoch 962 iteration 1846 of 1847\n",
      "Epoch 962 loss: 0.5762959115074077\n",
      "Saving model as weights/model_weights_962.pth\n",
      "Training epoch 963 iteration 1846 of 1847\n",
      "Epoch 963 loss: 0.5761600521911978\n",
      "Saving model as weights/model_weights_963.pth\n",
      "Training epoch 964 iteration 1846 of 1847\n",
      "Epoch 964 loss: 0.5754385895676141\n",
      "Saving model as weights/model_weights_964.pth\n",
      "Training epoch 965 iteration 1846 of 1847\n",
      "Epoch 965 loss: 0.5783266249416839\n",
      "Saving model as weights/model_weights_965.pth\n",
      "Training epoch 966 iteration 1846 of 1847\n",
      "Epoch 966 loss: 0.5765415136402339\n",
      "Saving model as weights/model_weights_966.pth\n",
      "Training epoch 967 iteration 1846 of 1847\n",
      "Epoch 967 loss: 0.5757644451593926\n",
      "Saving model as weights/model_weights_967.pth\n",
      "Training epoch 968 iteration 1846 of 1847\n",
      "Epoch 968 loss: 0.5772549658771715\n",
      "Saving model as weights/model_weights_968.pth\n",
      "Training epoch 969 iteration 1846 of 1847\n",
      "Epoch 969 loss: 0.5762556853104619\n",
      "Saving model as weights/model_weights_969.pth\n",
      "Training epoch 970 iteration 1846 of 1847\n",
      "Epoch 970 loss: 0.5746148442118376\n",
      "Saving model as weights/model_weights_970.pth\n",
      "Training epoch 971 iteration 1846 of 1847\n",
      "Epoch 971 loss: 0.5784899706316433\n",
      "Saving model as weights/model_weights_971.pth\n",
      "Training epoch 972 iteration 1846 of 1847\n",
      "Epoch 972 loss: 0.5758172056128931\n",
      "Saving model as weights/model_weights_972.pth\n",
      "Training epoch 973 iteration 1846 of 1847\n",
      "Epoch 973 loss: 0.5768258427050414\n",
      "Saving model as weights/model_weights_973.pth\n",
      "Training epoch 974 iteration 1846 of 1847\n",
      "Epoch 974 loss: 0.576943246751588\n",
      "Saving model as weights/model_weights_974.pth\n",
      "Training epoch 975 iteration 1846 of 1847\n",
      "Epoch 975 loss: 0.5755195308841753\n",
      "Saving model as weights/model_weights_975.pth\n",
      "Training epoch 976 iteration 1846 of 1847\n",
      "Epoch 976 loss: 0.5768306290677385\n",
      "Saving model as weights/model_weights_976.pth\n",
      "Training epoch 977 iteration 1846 of 1847\n",
      "Epoch 977 loss: 0.5769628630048466\n",
      "Saving model as weights/model_weights_977.pth\n",
      "Training epoch 978 iteration 1846 of 1847\n",
      "Epoch 978 loss: 0.5761740683347519\n",
      "Saving model as weights/model_weights_978.pth\n",
      "Training epoch 979 iteration 1846 of 1847\n",
      "Epoch 979 loss: 0.5756548804790185\n",
      "Saving model as weights/model_weights_979.pth\n",
      "Training epoch 980 iteration 1846 of 1847\n",
      "Epoch 980 loss: 0.5759145782874221\n",
      "Saving model as weights/model_weights_980.pth\n",
      "Training epoch 981 iteration 1846 of 1847\n",
      "Epoch 981 loss: 0.5766418208834541\n",
      "Saving model as weights/model_weights_981.pth\n",
      "Training epoch 982 iteration 1846 of 1847\n",
      "Epoch 982 loss: 0.5753622320160455\n",
      "Saving model as weights/model_weights_982.pth\n",
      "Training epoch 983 iteration 1846 of 1847\n",
      "Epoch 983 loss: 0.5772184586615322\n",
      "Saving model as weights/model_weights_983.pth\n",
      "Training epoch 984 iteration 1846 of 1847\n",
      "Epoch 984 loss: 0.5762547209866962\n",
      "Saving model as weights/model_weights_984.pth\n",
      "Training epoch 985 iteration 1846 of 1847\n",
      "Epoch 985 loss: 0.5753418996841377\n",
      "Saving model as weights/model_weights_985.pth\n",
      "Training epoch 986 iteration 1846 of 1847\n",
      "Epoch 986 loss: 0.576352263100417\n",
      "Saving model as weights/model_weights_986.pth\n",
      "Training epoch 987 iteration 1846 of 1847\n",
      "Epoch 987 loss: 0.5763797697081202\n",
      "Saving model as weights/model_weights_987.pth\n",
      "Training epoch 988 iteration 1846 of 1847\n",
      "Epoch 988 loss: 0.5763591207971299\n",
      "Saving model as weights/model_weights_988.pth\n",
      "Training epoch 989 iteration 1846 of 1847\n",
      "Epoch 989 loss: 0.5769193622474743\n",
      "Saving model as weights/model_weights_989.pth\n",
      "Training epoch 990 iteration 1846 of 1847\n",
      "Epoch 990 loss: 0.5756343691234145\n",
      "Saving model as weights/model_weights_990.pth\n",
      "Training epoch 991 iteration 1846 of 1847\n",
      "Epoch 991 loss: 0.5754536093894894\n",
      "Saving model as weights/model_weights_991.pth\n",
      "Training epoch 992 iteration 1846 of 1847\n",
      "Epoch 992 loss: 0.5763567306895997\n",
      "Saving model as weights/model_weights_992.pth\n",
      "Training epoch 993 iteration 1846 of 1847\n",
      "Epoch 993 loss: 0.5754950022013302\n",
      "Saving model as weights/model_weights_993.pth\n",
      "Training epoch 994 iteration 1846 of 1847\n",
      "Epoch 994 loss: 0.5752283113352595\n",
      "Saving model as weights/model_weights_994.pth\n",
      "Training epoch 995 iteration 1846 of 1847\n",
      "Epoch 995 loss: 0.5782961209174033\n",
      "Saving model as weights/model_weights_995.pth\n",
      "Training epoch 996 iteration 1846 of 1847\n",
      "Epoch 996 loss: 0.5758724089532397\n",
      "Saving model as weights/model_weights_996.pth\n",
      "Training epoch 997 iteration 1846 of 1847\n",
      "Epoch 997 loss: 0.574985408143992\n",
      "Saving model as weights/model_weights_997.pth\n",
      "Training epoch 998 iteration 1846 of 1847\n",
      "Epoch 998 loss: 0.5761070782001043\n",
      "Saving model as weights/model_weights_998.pth\n",
      "Training epoch 999 iteration 1846 of 1847\n",
      "Epoch 999 loss: 0.5763670879082868\n",
      "Saving model as weights/model_weights_999.pth\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    for epoch in range(train_iterations):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            print (f'Training epoch {epoch} iteration {i} of {len(train_loader)}', end = '\\r'),\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.squeeze(-1)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            raw_out = outputs\n",
    "            #returning to real values instead of logs\n",
    "            labels = torch.exp(labels)-1\n",
    "            outputs = torch.exp(outputs)-1\n",
    "            loss = criterion(outputs, labels)\n",
    "            if (math.isnan(loss)):\n",
    "                print(f'inputs = {inputs}')\n",
    "                print(f'outputs = {outputs}')\n",
    "                print(f'raw outputs = {raw_out}')\n",
    "                print(f'expected ={labels}')\n",
    "                print(f'NaN error on epoch {epoch}\\n')\n",
    "                for param in model.parameters():\n",
    "                    print(param.data)\n",
    "                return\n",
    "                break\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'\\nEpoch {epoch} loss: {running_loss/len(train_loader)}')\n",
    "        running_loss_es.append(running_loss/len(train_loader))\n",
    "        if (epoch % save_every == 0):\n",
    "            model_file_name = f'weights/model_weights_{epoch}.pth'\n",
    "            print(f'Saving model as {model_file_name}')\n",
    "            torch.save(model, model_file_name)\n",
    "        torch.save(model, f'weights/model_weights_{train_iterations}.pth')\n",
    "train()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72741c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3a408feb90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # for making figures\n",
    "plt.plot(running_loss_es, label = \"RMSLE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86fd0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5987\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "machine_epsilon = 1\n",
    "# Initialize the total loss and accuracy\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "machine_epsilon = train_sales_log.std()/10 \n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Loop over the validation set\n",
    "    for batch_data, batch_labels in val_loader:\n",
    "        # Move the data and labels to the device\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        batch_labels = batch_labels.squeeze(-1)\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        \n",
    "        batch_labels = torch.exp(batch_labels)-1\n",
    "        outputs = torch.exp(outputs)-1\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item() * batch_data.size(0)\n",
    "\n",
    "        # Get the predicted class\n",
    "        \n",
    "        \n",
    "        # Count the number of correct predictions\n",
    "        total_correct += ((\n",
    "            (outputs - batch_labels)**2)<machine_epsilon).sum().item()\n",
    "\n",
    "        # Increment the total number of samples\n",
    "        total_samples += batch_data.size(0)\n",
    "        #break\n",
    "# Calculate the average loss and accuracy over the validation set\n",
    "average_loss = total_loss / total_samples\n",
    "accuracy = total_correct / total_samples\n",
    "\n",
    "# Print the results\n",
    "print('Validation Loss: {:.4f}'.format(average_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53964b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_file, val_loader):\n",
    "    # Load the neural network from file\n",
    "    model = torch.load(model_file)\n",
    "    print('Testing model ' + model_file)\n",
    "    # Get the name of the model\n",
    "    model_name = model_file.split(\"/\")[-1]\n",
    "    \n",
    "    # Evaluate the neural network on the testing set\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "            # Loop over the validation set\n",
    "        for batch_data, batch_labels in val_loader:\n",
    "            # Move the data and labels to the device\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_data)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            #batch_labels = torch.squeeze(-1)\n",
    "            \n",
    "            batch_labels = torch.exp(batch_labels)-1\n",
    "            outputs = torch.exp(outputs)-1\n",
    "        \n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            # Accumulate the loss\n",
    "            total_loss += loss.item() * batch_data.size(0)\n",
    "\n",
    "            # Get the predicted class\n",
    "            # Count the number of correct predictions\n",
    "            total_correct += (\n",
    "                    ((outputs - batch_labels)**2)<machine_epsilon).sum().item()\n",
    "    \n",
    "            # Increment the total number of samples\n",
    "            total_samples += batch_data.size(0)\n",
    "\n",
    "# Calculate the average loss and accuracy over the validation set\n",
    "    average_loss = total_loss / total_samples\n",
    "    #accuracy = total_correct / total_samples\n",
    "\n",
    "# Print the results\n",
    "    #accuracy = 0\n",
    "    print('Validation Loss: {:.4f}'.format(average_loss))\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "689dd90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model weights/model_weights_0.pth\n",
      "Validation Loss: 3.7795\n",
      "Testing model weights/model_weights_1.pth\n",
      "Validation Loss: 3.4566\n",
      "Testing model weights/model_weights_2.pth\n",
      "Validation Loss: 3.0630\n",
      "Testing model weights/model_weights_3.pth\n",
      "Validation Loss: 2.8273\n",
      "Testing model weights/model_weights_4.pth\n",
      "Validation Loss: 2.4788\n",
      "Testing model weights/model_weights_5.pth\n",
      "Validation Loss: 2.1612\n",
      "Testing model weights/model_weights_6.pth\n",
      "Validation Loss: 1.8959\n",
      "Testing model weights/model_weights_7.pth\n",
      "Validation Loss: 1.8005\n",
      "Testing model weights/model_weights_8.pth\n",
      "Validation Loss: 1.6047\n",
      "Testing model weights/model_weights_9.pth\n",
      "Validation Loss: 1.5383\n",
      "Testing model weights/model_weights_10.pth\n",
      "Validation Loss: 1.4562\n",
      "Testing model weights/model_weights_11.pth\n",
      "Validation Loss: 1.4038\n",
      "Testing model weights/model_weights_12.pth\n",
      "Validation Loss: 1.2884\n",
      "Testing model weights/model_weights_13.pth\n",
      "Validation Loss: 1.2672\n",
      "Testing model weights/model_weights_14.pth\n",
      "Validation Loss: 1.2284\n",
      "Testing model weights/model_weights_15.pth\n",
      "Validation Loss: 1.2075\n",
      "Testing model weights/model_weights_16.pth\n",
      "Validation Loss: 1.2019\n",
      "Testing model weights/model_weights_17.pth\n",
      "Validation Loss: 1.1606\n",
      "Testing model weights/model_weights_18.pth\n",
      "Validation Loss: 1.2248\n",
      "Testing model weights/model_weights_19.pth\n",
      "Validation Loss: 1.1682\n",
      "Testing model weights/model_weights_20.pth\n",
      "Validation Loss: 1.1752\n",
      "Testing model weights/model_weights_21.pth\n",
      "Validation Loss: 1.1392\n",
      "Testing model weights/model_weights_22.pth\n",
      "Validation Loss: 1.1112\n",
      "Testing model weights/model_weights_23.pth\n",
      "Validation Loss: 1.0687\n",
      "Testing model weights/model_weights_24.pth\n",
      "Validation Loss: 1.1134\n",
      "Testing model weights/model_weights_25.pth\n",
      "Validation Loss: 1.0871\n",
      "Testing model weights/model_weights_26.pth\n",
      "Validation Loss: 1.0657\n",
      "Testing model weights/model_weights_27.pth\n",
      "Validation Loss: 1.0149\n",
      "Testing model weights/model_weights_28.pth\n",
      "Validation Loss: 1.0659\n",
      "Testing model weights/model_weights_29.pth\n",
      "Validation Loss: 1.0857\n",
      "Testing model weights/model_weights_30.pth\n",
      "Validation Loss: 0.9975\n",
      "Testing model weights/model_weights_31.pth\n",
      "Validation Loss: 1.0089\n",
      "Testing model weights/model_weights_32.pth\n",
      "Validation Loss: 1.0082\n",
      "Testing model weights/model_weights_33.pth\n",
      "Validation Loss: 0.9970\n",
      "Testing model weights/model_weights_34.pth\n",
      "Validation Loss: 0.9678\n",
      "Testing model weights/model_weights_35.pth\n",
      "Validation Loss: 0.9834\n",
      "Testing model weights/model_weights_36.pth\n",
      "Validation Loss: 0.9515\n",
      "Testing model weights/model_weights_37.pth\n",
      "Validation Loss: 1.0107\n",
      "Testing model weights/model_weights_38.pth\n",
      "Validation Loss: 0.9557\n",
      "Testing model weights/model_weights_39.pth\n",
      "Validation Loss: 1.0121\n",
      "Testing model weights/model_weights_40.pth\n",
      "Validation Loss: 0.9091\n",
      "Testing model weights/model_weights_41.pth\n",
      "Validation Loss: 0.9793\n",
      "Testing model weights/model_weights_42.pth\n",
      "Validation Loss: 1.0015\n",
      "Testing model weights/model_weights_43.pth\n",
      "Validation Loss: 0.9709\n",
      "Testing model weights/model_weights_44.pth\n",
      "Validation Loss: 0.9045\n",
      "Testing model weights/model_weights_45.pth\n",
      "Validation Loss: 0.9151\n",
      "Testing model weights/model_weights_46.pth\n",
      "Validation Loss: 0.9118\n",
      "Testing model weights/model_weights_47.pth\n",
      "Validation Loss: 0.9329\n",
      "Testing model weights/model_weights_48.pth\n",
      "Validation Loss: 0.9421\n",
      "Testing model weights/model_weights_49.pth\n",
      "Validation Loss: 0.8891\n",
      "Testing model weights/model_weights_50.pth\n",
      "Validation Loss: 0.9031\n",
      "Testing model weights/model_weights_51.pth\n",
      "Validation Loss: 0.9121\n",
      "Testing model weights/model_weights_52.pth\n",
      "Validation Loss: 0.8767\n",
      "Testing model weights/model_weights_53.pth\n",
      "Validation Loss: 0.8966\n",
      "Testing model weights/model_weights_54.pth\n",
      "Validation Loss: 0.8571\n",
      "Testing model weights/model_weights_55.pth\n",
      "Validation Loss: 0.9896\n",
      "Testing model weights/model_weights_56.pth\n",
      "Validation Loss: 0.8485\n",
      "Testing model weights/model_weights_57.pth\n",
      "Validation Loss: 0.8598\n",
      "Testing model weights/model_weights_58.pth\n",
      "Validation Loss: 0.8701\n",
      "Testing model weights/model_weights_59.pth\n",
      "Validation Loss: 0.8999\n",
      "Testing model weights/model_weights_60.pth\n",
      "Validation Loss: 0.8475\n",
      "Testing model weights/model_weights_61.pth\n",
      "Validation Loss: 0.8525\n",
      "Testing model weights/model_weights_62.pth\n",
      "Validation Loss: 0.8647\n",
      "Testing model weights/model_weights_63.pth\n",
      "Validation Loss: 0.8419\n",
      "Testing model weights/model_weights_64.pth\n",
      "Validation Loss: 0.8616\n",
      "Testing model weights/model_weights_65.pth\n",
      "Validation Loss: 0.8325\n",
      "Testing model weights/model_weights_66.pth\n",
      "Validation Loss: 0.8695\n",
      "Testing model weights/model_weights_67.pth\n",
      "Validation Loss: 0.8407\n",
      "Testing model weights/model_weights_68.pth\n",
      "Validation Loss: 0.8108\n",
      "Testing model weights/model_weights_69.pth\n",
      "Validation Loss: 0.8521\n",
      "Testing model weights/model_weights_70.pth\n",
      "Validation Loss: 0.8214\n",
      "Testing model weights/model_weights_71.pth\n",
      "Validation Loss: 0.8158\n",
      "Testing model weights/model_weights_72.pth\n",
      "Validation Loss: 0.8283\n",
      "Testing model weights/model_weights_73.pth\n",
      "Validation Loss: 0.8442\n",
      "Testing model weights/model_weights_74.pth\n",
      "Validation Loss: 0.8067\n",
      "Testing model weights/model_weights_75.pth\n",
      "Validation Loss: 0.7933\n",
      "Testing model weights/model_weights_76.pth\n",
      "Validation Loss: 0.8425\n",
      "Testing model weights/model_weights_77.pth\n",
      "Validation Loss: 0.8207\n",
      "Testing model weights/model_weights_78.pth\n",
      "Validation Loss: 0.8242\n",
      "Testing model weights/model_weights_79.pth\n",
      "Validation Loss: 0.7952\n",
      "Testing model weights/model_weights_80.pth\n",
      "Validation Loss: 0.9711\n",
      "Testing model weights/model_weights_81.pth\n",
      "Validation Loss: 0.8102\n",
      "Testing model weights/model_weights_82.pth\n",
      "Validation Loss: 0.7830\n",
      "Testing model weights/model_weights_83.pth\n",
      "Validation Loss: 0.7914\n",
      "Testing model weights/model_weights_84.pth\n",
      "Validation Loss: 0.7845\n",
      "Testing model weights/model_weights_85.pth\n",
      "Validation Loss: 0.7935\n",
      "Testing model weights/model_weights_86.pth\n",
      "Validation Loss: 0.7680\n",
      "Testing model weights/model_weights_87.pth\n",
      "Validation Loss: 0.7854\n",
      "Testing model weights/model_weights_88.pth\n",
      "Validation Loss: 0.7958\n",
      "Testing model weights/model_weights_89.pth\n",
      "Validation Loss: 0.7655\n",
      "Testing model weights/model_weights_90.pth\n",
      "Validation Loss: 0.8227\n",
      "Testing model weights/model_weights_91.pth\n",
      "Validation Loss: 0.7752\n",
      "Testing model weights/model_weights_92.pth\n",
      "Validation Loss: 0.8304\n",
      "Testing model weights/model_weights_93.pth\n",
      "Validation Loss: 0.7767\n",
      "Testing model weights/model_weights_94.pth\n",
      "Validation Loss: 0.7652\n",
      "Testing model weights/model_weights_95.pth\n",
      "Validation Loss: 0.7740\n",
      "Testing model weights/model_weights_96.pth\n",
      "Validation Loss: 0.7872\n",
      "Testing model weights/model_weights_97.pth\n",
      "Validation Loss: 0.7555\n",
      "Testing model weights/model_weights_98.pth\n",
      "Validation Loss: 0.7877\n",
      "Testing model weights/model_weights_99.pth\n",
      "Validation Loss: 0.7609\n",
      "Testing model weights/model_weights_100.pth\n",
      "Validation Loss: 0.7487\n",
      "Testing model weights/model_weights_101.pth\n",
      "Validation Loss: 0.7572\n",
      "Testing model weights/model_weights_102.pth\n",
      "Validation Loss: 0.7947\n",
      "Testing model weights/model_weights_103.pth\n",
      "Validation Loss: 0.7487\n",
      "Testing model weights/model_weights_104.pth\n",
      "Validation Loss: 0.7609\n",
      "Testing model weights/model_weights_105.pth\n",
      "Validation Loss: 0.7677\n",
      "Testing model weights/model_weights_106.pth\n",
      "Validation Loss: 0.7578\n",
      "Testing model weights/model_weights_107.pth\n",
      "Validation Loss: 0.7419\n",
      "Testing model weights/model_weights_108.pth\n",
      "Validation Loss: 0.7541\n",
      "Testing model weights/model_weights_109.pth\n",
      "Validation Loss: 0.7430\n",
      "Testing model weights/model_weights_110.pth\n",
      "Validation Loss: 0.7642\n",
      "Testing model weights/model_weights_111.pth\n",
      "Validation Loss: 0.7432\n",
      "Testing model weights/model_weights_112.pth\n",
      "Validation Loss: 0.7582\n",
      "Testing model weights/model_weights_113.pth\n",
      "Validation Loss: 0.7355\n",
      "Testing model weights/model_weights_114.pth\n",
      "Validation Loss: 0.7362\n",
      "Testing model weights/model_weights_115.pth\n",
      "Validation Loss: 0.7597\n",
      "Testing model weights/model_weights_116.pth\n",
      "Validation Loss: 0.7428\n",
      "Testing model weights/model_weights_117.pth\n",
      "Validation Loss: 0.7448\n",
      "Testing model weights/model_weights_118.pth\n",
      "Validation Loss: 0.7451\n",
      "Testing model weights/model_weights_119.pth\n",
      "Validation Loss: 0.7463\n",
      "Testing model weights/model_weights_120.pth\n",
      "Validation Loss: 0.7390\n",
      "Testing model weights/model_weights_121.pth\n",
      "Validation Loss: 0.7639\n",
      "Testing model weights/model_weights_122.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7506\n",
      "Testing model weights/model_weights_123.pth\n",
      "Validation Loss: 0.7357\n",
      "Testing model weights/model_weights_124.pth\n",
      "Validation Loss: 0.7671\n",
      "Testing model weights/model_weights_125.pth\n",
      "Validation Loss: 0.7511\n",
      "Testing model weights/model_weights_126.pth\n",
      "Validation Loss: 0.7390\n",
      "Testing model weights/model_weights_127.pth\n",
      "Validation Loss: 0.7425\n",
      "Testing model weights/model_weights_128.pth\n",
      "Validation Loss: 0.7565\n",
      "Testing model weights/model_weights_129.pth\n",
      "Validation Loss: 0.7472\n",
      "Testing model weights/model_weights_130.pth\n",
      "Validation Loss: 0.7331\n",
      "Testing model weights/model_weights_131.pth\n",
      "Validation Loss: 0.7325\n",
      "Testing model weights/model_weights_132.pth\n",
      "Validation Loss: 0.7151\n",
      "Testing model weights/model_weights_133.pth\n",
      "Validation Loss: 0.7392\n",
      "Testing model weights/model_weights_134.pth\n",
      "Validation Loss: 0.7393\n",
      "Testing model weights/model_weights_135.pth\n",
      "Validation Loss: 0.7265\n",
      "Testing model weights/model_weights_136.pth\n",
      "Validation Loss: 0.7374\n",
      "Testing model weights/model_weights_137.pth\n",
      "Validation Loss: 0.7357\n",
      "Testing model weights/model_weights_138.pth\n",
      "Validation Loss: 0.7182\n",
      "Testing model weights/model_weights_139.pth\n",
      "Validation Loss: 0.7256\n",
      "Testing model weights/model_weights_140.pth\n",
      "Validation Loss: 0.7275\n",
      "Testing model weights/model_weights_141.pth\n",
      "Validation Loss: 0.7301\n",
      "Testing model weights/model_weights_142.pth\n",
      "Validation Loss: 0.7384\n",
      "Testing model weights/model_weights_143.pth\n",
      "Validation Loss: 0.7222\n",
      "Testing model weights/model_weights_144.pth\n",
      "Validation Loss: 0.7169\n",
      "Testing model weights/model_weights_145.pth\n",
      "Validation Loss: 0.6993\n",
      "Testing model weights/model_weights_146.pth\n",
      "Validation Loss: 0.7280\n",
      "Testing model weights/model_weights_147.pth\n",
      "Validation Loss: 0.7145\n",
      "Testing model weights/model_weights_148.pth\n",
      "Validation Loss: 0.7500\n",
      "Testing model weights/model_weights_149.pth\n",
      "Validation Loss: 0.7076\n",
      "Testing model weights/model_weights_150.pth\n",
      "Validation Loss: 0.7091\n",
      "Testing model weights/model_weights_151.pth\n",
      "Validation Loss: 0.7158\n",
      "Testing model weights/model_weights_152.pth\n",
      "Validation Loss: 0.7079\n",
      "Testing model weights/model_weights_153.pth\n",
      "Validation Loss: 0.7400\n",
      "Testing model weights/model_weights_154.pth\n",
      "Validation Loss: 0.7077\n",
      "Testing model weights/model_weights_155.pth\n",
      "Validation Loss: 0.6954\n",
      "Testing model weights/model_weights_156.pth\n",
      "Validation Loss: 0.7385\n",
      "Testing model weights/model_weights_157.pth\n",
      "Validation Loss: 0.7220\n",
      "Testing model weights/model_weights_158.pth\n",
      "Validation Loss: 0.6937\n",
      "Testing model weights/model_weights_159.pth\n",
      "Validation Loss: 0.7167\n",
      "Testing model weights/model_weights_160.pth\n",
      "Validation Loss: 0.7303\n",
      "Testing model weights/model_weights_161.pth\n",
      "Validation Loss: 0.7081\n",
      "Testing model weights/model_weights_162.pth\n",
      "Validation Loss: 0.7132\n",
      "Testing model weights/model_weights_163.pth\n",
      "Validation Loss: 0.7102\n",
      "Testing model weights/model_weights_164.pth\n",
      "Validation Loss: 0.6968\n",
      "Testing model weights/model_weights_165.pth\n",
      "Validation Loss: 0.7408\n",
      "Testing model weights/model_weights_166.pth\n",
      "Validation Loss: 0.6942\n",
      "Testing model weights/model_weights_167.pth\n",
      "Validation Loss: 0.7171\n",
      "Testing model weights/model_weights_168.pth\n",
      "Validation Loss: 0.7060\n",
      "Testing model weights/model_weights_169.pth\n",
      "Validation Loss: 0.7041\n",
      "Testing model weights/model_weights_170.pth\n",
      "Validation Loss: 0.7094\n",
      "Testing model weights/model_weights_171.pth\n",
      "Validation Loss: 0.7088\n",
      "Testing model weights/model_weights_172.pth\n",
      "Validation Loss: 0.7105\n",
      "Testing model weights/model_weights_173.pth\n",
      "Validation Loss: 0.6996\n",
      "Testing model weights/model_weights_174.pth\n",
      "Validation Loss: 0.6906\n",
      "Testing model weights/model_weights_175.pth\n",
      "Validation Loss: 0.7109\n",
      "Testing model weights/model_weights_176.pth\n",
      "Validation Loss: 0.6838\n",
      "Testing model weights/model_weights_177.pth\n",
      "Validation Loss: 0.7005\n",
      "Testing model weights/model_weights_178.pth\n",
      "Validation Loss: 0.7244\n",
      "Testing model weights/model_weights_179.pth\n",
      "Validation Loss: 0.6906\n",
      "Testing model weights/model_weights_180.pth\n",
      "Validation Loss: 0.6913\n",
      "Testing model weights/model_weights_181.pth\n",
      "Validation Loss: 0.7351\n",
      "Testing model weights/model_weights_182.pth\n",
      "Validation Loss: 0.7007\n",
      "Testing model weights/model_weights_183.pth\n",
      "Validation Loss: 0.6962\n",
      "Testing model weights/model_weights_184.pth\n",
      "Validation Loss: 0.7100\n",
      "Testing model weights/model_weights_185.pth\n",
      "Validation Loss: 0.6900\n",
      "Testing model weights/model_weights_186.pth\n",
      "Validation Loss: 0.7064\n",
      "Testing model weights/model_weights_187.pth\n",
      "Validation Loss: 0.6833\n",
      "Testing model weights/model_weights_188.pth\n",
      "Validation Loss: 0.7045\n",
      "Testing model weights/model_weights_189.pth\n",
      "Validation Loss: 0.6926\n",
      "Testing model weights/model_weights_190.pth\n",
      "Validation Loss: 0.6970\n",
      "Testing model weights/model_weights_191.pth\n",
      "Validation Loss: 0.6826\n",
      "Testing model weights/model_weights_192.pth\n",
      "Validation Loss: 0.6954\n",
      "Testing model weights/model_weights_193.pth\n",
      "Validation Loss: 0.6808\n",
      "Testing model weights/model_weights_194.pth\n",
      "Validation Loss: 0.6895\n",
      "Testing model weights/model_weights_195.pth\n",
      "Validation Loss: 0.7028\n",
      "Testing model weights/model_weights_196.pth\n",
      "Validation Loss: 0.6770\n",
      "Testing model weights/model_weights_197.pth\n",
      "Validation Loss: 0.6795\n",
      "Testing model weights/model_weights_198.pth\n",
      "Validation Loss: 0.7153\n",
      "Testing model weights/model_weights_199.pth\n",
      "Validation Loss: 0.6932\n",
      "Testing model weights/model_weights_200.pth\n",
      "Validation Loss: 0.7337\n",
      "Testing model weights/model_weights_201.pth\n",
      "Validation Loss: 0.6909\n",
      "Testing model weights/model_weights_202.pth\n",
      "Validation Loss: 0.6918\n",
      "Testing model weights/model_weights_203.pth\n",
      "Validation Loss: 0.6763\n",
      "Testing model weights/model_weights_204.pth\n",
      "Validation Loss: 0.6985\n",
      "Testing model weights/model_weights_205.pth\n",
      "Validation Loss: 0.6831\n",
      "Testing model weights/model_weights_206.pth\n",
      "Validation Loss: 0.6827\n",
      "Testing model weights/model_weights_207.pth\n",
      "Validation Loss: 0.6885\n",
      "Testing model weights/model_weights_208.pth\n",
      "Validation Loss: 0.6905\n",
      "Testing model weights/model_weights_209.pth\n",
      "Validation Loss: 0.6742\n",
      "Testing model weights/model_weights_210.pth\n",
      "Validation Loss: 0.7265\n",
      "Testing model weights/model_weights_211.pth\n",
      "Validation Loss: 0.6726\n",
      "Testing model weights/model_weights_212.pth\n",
      "Validation Loss: 0.6933\n",
      "Testing model weights/model_weights_213.pth\n",
      "Validation Loss: 0.6843\n",
      "Testing model weights/model_weights_214.pth\n",
      "Validation Loss: 0.6869\n",
      "Testing model weights/model_weights_215.pth\n",
      "Validation Loss: 0.6835\n",
      "Testing model weights/model_weights_216.pth\n",
      "Validation Loss: 0.6897\n",
      "Testing model weights/model_weights_217.pth\n",
      "Validation Loss: 0.6766\n",
      "Testing model weights/model_weights_218.pth\n",
      "Validation Loss: 0.6916\n",
      "Testing model weights/model_weights_219.pth\n",
      "Validation Loss: 0.6909\n",
      "Testing model weights/model_weights_220.pth\n",
      "Validation Loss: 0.7057\n",
      "Testing model weights/model_weights_221.pth\n",
      "Validation Loss: 0.6931\n",
      "Testing model weights/model_weights_222.pth\n",
      "Validation Loss: 0.6639\n",
      "Testing model weights/model_weights_223.pth\n",
      "Validation Loss: 0.7089\n",
      "Testing model weights/model_weights_224.pth\n",
      "Validation Loss: 0.6794\n",
      "Testing model weights/model_weights_225.pth\n",
      "Validation Loss: 0.6748\n",
      "Testing model weights/model_weights_226.pth\n",
      "Validation Loss: 0.6860\n",
      "Testing model weights/model_weights_227.pth\n",
      "Validation Loss: 0.6863\n",
      "Testing model weights/model_weights_228.pth\n",
      "Validation Loss: 0.6848\n",
      "Testing model weights/model_weights_229.pth\n",
      "Validation Loss: 0.6703\n",
      "Testing model weights/model_weights_230.pth\n",
      "Validation Loss: 0.6754\n",
      "Testing model weights/model_weights_231.pth\n",
      "Validation Loss: 0.6707\n",
      "Testing model weights/model_weights_232.pth\n",
      "Validation Loss: 0.6683\n",
      "Testing model weights/model_weights_233.pth\n",
      "Validation Loss: 0.6759\n",
      "Testing model weights/model_weights_234.pth\n",
      "Validation Loss: 0.6750\n",
      "Testing model weights/model_weights_235.pth\n",
      "Validation Loss: 0.7142\n",
      "Testing model weights/model_weights_236.pth\n",
      "Validation Loss: 0.6948\n",
      "Testing model weights/model_weights_237.pth\n",
      "Validation Loss: 0.6817\n",
      "Testing model weights/model_weights_238.pth\n",
      "Validation Loss: 0.7022\n",
      "Testing model weights/model_weights_239.pth\n",
      "Validation Loss: 0.6688\n",
      "Testing model weights/model_weights_240.pth\n",
      "Validation Loss: 0.6887\n",
      "Testing model weights/model_weights_241.pth\n",
      "Validation Loss: 0.6665\n",
      "Testing model weights/model_weights_242.pth\n",
      "Validation Loss: 0.6746\n",
      "Testing model weights/model_weights_243.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6864\n",
      "Testing model weights/model_weights_244.pth\n",
      "Validation Loss: 0.6790\n",
      "Testing model weights/model_weights_245.pth\n",
      "Validation Loss: 0.6620\n",
      "Testing model weights/model_weights_246.pth\n",
      "Validation Loss: 0.6808\n",
      "Testing model weights/model_weights_247.pth\n",
      "Validation Loss: 0.7046\n",
      "Testing model weights/model_weights_248.pth\n",
      "Validation Loss: 0.6630\n",
      "Testing model weights/model_weights_249.pth\n",
      "Validation Loss: 0.6724\n",
      "Testing model weights/model_weights_250.pth\n",
      "Validation Loss: 0.6580\n",
      "Testing model weights/model_weights_251.pth\n",
      "Validation Loss: 0.6563\n",
      "Testing model weights/model_weights_252.pth\n",
      "Validation Loss: 0.6623\n",
      "Testing model weights/model_weights_253.pth\n",
      "Validation Loss: 0.6743\n",
      "Testing model weights/model_weights_254.pth\n",
      "Validation Loss: 0.6851\n",
      "Testing model weights/model_weights_255.pth\n",
      "Validation Loss: 0.6637\n",
      "Testing model weights/model_weights_256.pth\n",
      "Validation Loss: 0.6745\n",
      "Testing model weights/model_weights_257.pth\n",
      "Validation Loss: 0.6635\n",
      "Testing model weights/model_weights_258.pth\n",
      "Validation Loss: 0.6819\n",
      "Testing model weights/model_weights_259.pth\n",
      "Validation Loss: 0.6571\n",
      "Testing model weights/model_weights_260.pth\n",
      "Validation Loss: 0.6536\n",
      "Testing model weights/model_weights_261.pth\n",
      "Validation Loss: 0.6581\n",
      "Testing model weights/model_weights_262.pth\n",
      "Validation Loss: 0.6750\n",
      "Testing model weights/model_weights_263.pth\n",
      "Validation Loss: 0.6655\n",
      "Testing model weights/model_weights_264.pth\n",
      "Validation Loss: 0.6921\n",
      "Testing model weights/model_weights_265.pth\n",
      "Validation Loss: 0.6583\n",
      "Testing model weights/model_weights_266.pth\n",
      "Validation Loss: 0.6550\n",
      "Testing model weights/model_weights_267.pth\n",
      "Validation Loss: 0.6496\n",
      "Testing model weights/model_weights_268.pth\n",
      "Validation Loss: 0.6641\n",
      "Testing model weights/model_weights_269.pth\n",
      "Validation Loss: 0.7006\n",
      "Testing model weights/model_weights_270.pth\n",
      "Validation Loss: 0.6518\n",
      "Testing model weights/model_weights_271.pth\n",
      "Validation Loss: 0.6666\n",
      "Testing model weights/model_weights_272.pth\n",
      "Validation Loss: 0.6646\n",
      "Testing model weights/model_weights_273.pth\n",
      "Validation Loss: 0.6567\n",
      "Testing model weights/model_weights_274.pth\n",
      "Validation Loss: 0.6664\n",
      "Testing model weights/model_weights_275.pth\n",
      "Validation Loss: 0.6618\n",
      "Testing model weights/model_weights_276.pth\n",
      "Validation Loss: 0.6539\n",
      "Testing model weights/model_weights_277.pth\n",
      "Validation Loss: 0.6652\n",
      "Testing model weights/model_weights_278.pth\n",
      "Validation Loss: 0.6549\n",
      "Testing model weights/model_weights_279.pth\n",
      "Validation Loss: 0.6633\n",
      "Testing model weights/model_weights_280.pth\n",
      "Validation Loss: 0.6619\n",
      "Testing model weights/model_weights_281.pth\n",
      "Validation Loss: 0.6748\n",
      "Testing model weights/model_weights_282.pth\n",
      "Validation Loss: 0.6708\n",
      "Testing model weights/model_weights_283.pth\n",
      "Validation Loss: 0.6668\n",
      "Testing model weights/model_weights_284.pth\n",
      "Validation Loss: 0.6485\n",
      "Testing model weights/model_weights_285.pth\n",
      "Validation Loss: 0.6695\n",
      "Testing model weights/model_weights_286.pth\n",
      "Validation Loss: 0.6640\n",
      "Testing model weights/model_weights_287.pth\n",
      "Validation Loss: 0.6559\n",
      "Testing model weights/model_weights_288.pth\n",
      "Validation Loss: 0.6588\n",
      "Testing model weights/model_weights_289.pth\n",
      "Validation Loss: 0.6936\n",
      "Testing model weights/model_weights_290.pth\n",
      "Validation Loss: 0.6440\n",
      "Testing model weights/model_weights_291.pth\n",
      "Validation Loss: 0.6679\n",
      "Testing model weights/model_weights_292.pth\n",
      "Validation Loss: 0.6571\n",
      "Testing model weights/model_weights_293.pth\n",
      "Validation Loss: 0.6671\n",
      "Testing model weights/model_weights_294.pth\n",
      "Validation Loss: 0.6618\n",
      "Testing model weights/model_weights_295.pth\n",
      "Validation Loss: 0.6449\n",
      "Testing model weights/model_weights_296.pth\n",
      "Validation Loss: 0.6587\n",
      "Testing model weights/model_weights_297.pth\n",
      "Validation Loss: 0.6679\n",
      "Testing model weights/model_weights_298.pth\n",
      "Validation Loss: 0.6624\n",
      "Testing model weights/model_weights_299.pth\n",
      "Validation Loss: 0.6662\n",
      "Testing model weights/model_weights_300.pth\n",
      "Validation Loss: 0.6627\n",
      "Testing model weights/model_weights_301.pth\n",
      "Validation Loss: 0.6609\n",
      "Testing model weights/model_weights_302.pth\n",
      "Validation Loss: 0.6578\n",
      "Testing model weights/model_weights_303.pth\n",
      "Validation Loss: 0.6424\n",
      "Testing model weights/model_weights_304.pth\n",
      "Validation Loss: 0.6608\n",
      "Testing model weights/model_weights_305.pth\n",
      "Validation Loss: 0.6638\n",
      "Testing model weights/model_weights_306.pth\n",
      "Validation Loss: 0.6628\n",
      "Testing model weights/model_weights_307.pth\n",
      "Validation Loss: 0.6433\n",
      "Testing model weights/model_weights_308.pth\n",
      "Validation Loss: 0.6530\n",
      "Testing model weights/model_weights_309.pth\n",
      "Validation Loss: 0.6427\n",
      "Testing model weights/model_weights_310.pth\n",
      "Validation Loss: 0.6466\n",
      "Testing model weights/model_weights_311.pth\n",
      "Validation Loss: 0.6500\n",
      "Testing model weights/model_weights_312.pth\n",
      "Validation Loss: 0.6573\n",
      "Testing model weights/model_weights_313.pth\n",
      "Validation Loss: 0.6506\n",
      "Testing model weights/model_weights_314.pth\n",
      "Validation Loss: 0.6449\n",
      "Testing model weights/model_weights_315.pth\n",
      "Validation Loss: 0.6586\n",
      "Testing model weights/model_weights_316.pth\n",
      "Validation Loss: 0.6503\n",
      "Testing model weights/model_weights_317.pth\n",
      "Validation Loss: 0.6398\n",
      "Testing model weights/model_weights_318.pth\n",
      "Validation Loss: 0.6687\n",
      "Testing model weights/model_weights_319.pth\n",
      "Validation Loss: 0.6488\n",
      "Testing model weights/model_weights_320.pth\n",
      "Validation Loss: 0.6495\n",
      "Testing model weights/model_weights_321.pth\n",
      "Validation Loss: 0.6587\n",
      "Testing model weights/model_weights_322.pth\n",
      "Validation Loss: 0.6523\n",
      "Testing model weights/model_weights_323.pth\n",
      "Validation Loss: 0.6462\n",
      "Testing model weights/model_weights_324.pth\n",
      "Validation Loss: 0.6383\n",
      "Testing model weights/model_weights_325.pth\n",
      "Validation Loss: 0.6661\n",
      "Testing model weights/model_weights_326.pth\n",
      "Validation Loss: 0.6415\n",
      "Testing model weights/model_weights_327.pth\n",
      "Validation Loss: 0.6507\n",
      "Testing model weights/model_weights_328.pth\n",
      "Validation Loss: 0.6426\n",
      "Testing model weights/model_weights_329.pth\n",
      "Validation Loss: 0.6452\n",
      "Testing model weights/model_weights_330.pth\n",
      "Validation Loss: 0.6679\n",
      "Testing model weights/model_weights_331.pth\n",
      "Validation Loss: 0.6772\n",
      "Testing model weights/model_weights_332.pth\n",
      "Validation Loss: 0.6527\n",
      "Testing model weights/model_weights_333.pth\n",
      "Validation Loss: 0.6489\n",
      "Testing model weights/model_weights_334.pth\n",
      "Validation Loss: 0.6555\n",
      "Testing model weights/model_weights_335.pth\n",
      "Validation Loss: 0.6462\n",
      "Testing model weights/model_weights_336.pth\n",
      "Validation Loss: 0.6306\n",
      "Testing model weights/model_weights_337.pth\n",
      "Validation Loss: 0.6405\n",
      "Testing model weights/model_weights_338.pth\n",
      "Validation Loss: 0.6522\n",
      "Testing model weights/model_weights_339.pth\n",
      "Validation Loss: 0.6396\n",
      "Testing model weights/model_weights_340.pth\n",
      "Validation Loss: 0.6434\n",
      "Testing model weights/model_weights_341.pth\n",
      "Validation Loss: 0.6458\n",
      "Testing model weights/model_weights_342.pth\n",
      "Validation Loss: 0.6417\n",
      "Testing model weights/model_weights_343.pth\n",
      "Validation Loss: 0.6707\n",
      "Testing model weights/model_weights_344.pth\n",
      "Validation Loss: 0.6687\n",
      "Testing model weights/model_weights_345.pth\n",
      "Validation Loss: 0.6444\n",
      "Testing model weights/model_weights_346.pth\n",
      "Validation Loss: 0.6435\n",
      "Testing model weights/model_weights_347.pth\n",
      "Validation Loss: 0.6380\n",
      "Testing model weights/model_weights_348.pth\n",
      "Validation Loss: 0.6455\n",
      "Testing model weights/model_weights_349.pth\n",
      "Validation Loss: 0.6423\n",
      "Testing model weights/model_weights_350.pth\n",
      "Validation Loss: 0.6447\n",
      "Testing model weights/model_weights_351.pth\n",
      "Validation Loss: 0.6466\n",
      "Testing model weights/model_weights_352.pth\n",
      "Validation Loss: 0.6498\n",
      "Testing model weights/model_weights_353.pth\n",
      "Validation Loss: 0.6318\n",
      "Testing model weights/model_weights_354.pth\n",
      "Validation Loss: 0.6396\n",
      "Testing model weights/model_weights_355.pth\n",
      "Validation Loss: 0.6653\n",
      "Testing model weights/model_weights_356.pth\n",
      "Validation Loss: 0.6422\n",
      "Testing model weights/model_weights_357.pth\n",
      "Validation Loss: 0.6643\n",
      "Testing model weights/model_weights_358.pth\n",
      "Validation Loss: 0.6322\n",
      "Testing model weights/model_weights_359.pth\n",
      "Validation Loss: 0.6398\n",
      "Testing model weights/model_weights_360.pth\n",
      "Validation Loss: 0.6399\n",
      "Testing model weights/model_weights_361.pth\n",
      "Validation Loss: 0.6293\n",
      "Testing model weights/model_weights_362.pth\n",
      "Validation Loss: 0.6375\n",
      "Testing model weights/model_weights_363.pth\n",
      "Validation Loss: 0.6791\n",
      "Testing model weights/model_weights_364.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6410\n",
      "Testing model weights/model_weights_365.pth\n",
      "Validation Loss: 0.6371\n",
      "Testing model weights/model_weights_366.pth\n",
      "Validation Loss: 0.6371\n",
      "Testing model weights/model_weights_367.pth\n",
      "Validation Loss: 0.6871\n",
      "Testing model weights/model_weights_368.pth\n",
      "Validation Loss: 0.6377\n",
      "Testing model weights/model_weights_369.pth\n",
      "Validation Loss: 0.6338\n",
      "Testing model weights/model_weights_370.pth\n",
      "Validation Loss: 0.6473\n",
      "Testing model weights/model_weights_371.pth\n",
      "Validation Loss: 0.6323\n",
      "Testing model weights/model_weights_372.pth\n",
      "Validation Loss: 0.6400\n",
      "Testing model weights/model_weights_373.pth\n",
      "Validation Loss: 0.6276\n",
      "Testing model weights/model_weights_374.pth\n",
      "Validation Loss: 0.6307\n",
      "Testing model weights/model_weights_375.pth\n",
      "Validation Loss: 0.6388\n",
      "Testing model weights/model_weights_376.pth\n",
      "Validation Loss: 0.6303\n",
      "Testing model weights/model_weights_377.pth\n",
      "Validation Loss: 0.6411\n",
      "Testing model weights/model_weights_378.pth\n",
      "Validation Loss: 0.6458\n",
      "Testing model weights/model_weights_379.pth\n",
      "Validation Loss: 0.6348\n",
      "Testing model weights/model_weights_380.pth\n",
      "Validation Loss: 0.6642\n",
      "Testing model weights/model_weights_381.pth\n",
      "Validation Loss: 0.6446\n",
      "Testing model weights/model_weights_382.pth\n",
      "Validation Loss: 0.6267\n",
      "Testing model weights/model_weights_383.pth\n",
      "Validation Loss: 0.6575\n",
      "Testing model weights/model_weights_384.pth\n",
      "Validation Loss: 0.6287\n",
      "Testing model weights/model_weights_385.pth\n",
      "Validation Loss: 0.6270\n",
      "Testing model weights/model_weights_386.pth\n",
      "Validation Loss: 0.6311\n",
      "Testing model weights/model_weights_387.pth\n",
      "Validation Loss: 0.6483\n",
      "Testing model weights/model_weights_388.pth\n",
      "Validation Loss: 0.6327\n",
      "Testing model weights/model_weights_389.pth\n",
      "Validation Loss: 0.6389\n",
      "Testing model weights/model_weights_390.pth\n",
      "Validation Loss: 0.6359\n",
      "Testing model weights/model_weights_391.pth\n",
      "Validation Loss: 0.6407\n",
      "Testing model weights/model_weights_392.pth\n",
      "Validation Loss: 0.6448\n",
      "Testing model weights/model_weights_393.pth\n",
      "Validation Loss: 0.6309\n",
      "Testing model weights/model_weights_394.pth\n",
      "Validation Loss: 0.6428\n",
      "Testing model weights/model_weights_395.pth\n",
      "Validation Loss: 0.6317\n",
      "Testing model weights/model_weights_396.pth\n",
      "Validation Loss: 0.6330\n",
      "Testing model weights/model_weights_397.pth\n",
      "Validation Loss: 0.6283\n",
      "Testing model weights/model_weights_398.pth\n",
      "Validation Loss: 0.6539\n",
      "Testing model weights/model_weights_399.pth\n",
      "Validation Loss: 0.6371\n",
      "Testing model weights/model_weights_400.pth\n",
      "Validation Loss: 0.6539\n",
      "Testing model weights/model_weights_401.pth\n",
      "Validation Loss: 0.6322\n",
      "Testing model weights/model_weights_402.pth\n",
      "Validation Loss: 0.6264\n",
      "Testing model weights/model_weights_403.pth\n",
      "Validation Loss: 0.6548\n",
      "Testing model weights/model_weights_404.pth\n",
      "Validation Loss: 0.6517\n",
      "Testing model weights/model_weights_405.pth\n",
      "Validation Loss: 0.6633\n",
      "Testing model weights/model_weights_406.pth\n",
      "Validation Loss: 0.6433\n",
      "Testing model weights/model_weights_407.pth\n",
      "Validation Loss: 0.6284\n",
      "Testing model weights/model_weights_408.pth\n",
      "Validation Loss: 0.6395\n",
      "Testing model weights/model_weights_409.pth\n",
      "Validation Loss: 0.6504\n",
      "Testing model weights/model_weights_410.pth\n",
      "Validation Loss: 0.6499\n",
      "Testing model weights/model_weights_411.pth\n",
      "Validation Loss: 0.6363\n",
      "Testing model weights/model_weights_412.pth\n",
      "Validation Loss: 0.6301\n",
      "Testing model weights/model_weights_413.pth\n",
      "Validation Loss: 0.6345\n",
      "Testing model weights/model_weights_414.pth\n",
      "Validation Loss: 0.6298\n",
      "Testing model weights/model_weights_415.pth\n",
      "Validation Loss: 0.6348\n",
      "Testing model weights/model_weights_416.pth\n",
      "Validation Loss: 0.6359\n",
      "Testing model weights/model_weights_417.pth\n",
      "Validation Loss: 0.6201\n",
      "Testing model weights/model_weights_418.pth\n",
      "Validation Loss: 0.6400\n",
      "Testing model weights/model_weights_419.pth\n",
      "Validation Loss: 0.6215\n",
      "Testing model weights/model_weights_420.pth\n",
      "Validation Loss: 0.6303\n",
      "Testing model weights/model_weights_421.pth\n",
      "Validation Loss: 0.6348\n",
      "Testing model weights/model_weights_422.pth\n",
      "Validation Loss: 0.6298\n",
      "Testing model weights/model_weights_423.pth\n",
      "Validation Loss: 0.6292\n",
      "Testing model weights/model_weights_424.pth\n",
      "Validation Loss: 0.6181\n",
      "Testing model weights/model_weights_425.pth\n",
      "Validation Loss: 0.6411\n",
      "Testing model weights/model_weights_426.pth\n",
      "Validation Loss: 0.6156\n",
      "Testing model weights/model_weights_427.pth\n",
      "Validation Loss: 0.6255\n",
      "Testing model weights/model_weights_428.pth\n",
      "Validation Loss: 0.6369\n",
      "Testing model weights/model_weights_429.pth\n",
      "Validation Loss: 0.6322\n",
      "Testing model weights/model_weights_430.pth\n",
      "Validation Loss: 0.6359\n",
      "Testing model weights/model_weights_431.pth\n",
      "Validation Loss: 0.6304\n",
      "Testing model weights/model_weights_432.pth\n",
      "Validation Loss: 0.6323\n",
      "Testing model weights/model_weights_433.pth\n",
      "Validation Loss: 0.6347\n",
      "Testing model weights/model_weights_434.pth\n",
      "Validation Loss: 0.6323\n",
      "Testing model weights/model_weights_435.pth\n",
      "Validation Loss: 0.6344\n",
      "Testing model weights/model_weights_436.pth\n",
      "Validation Loss: 0.6267\n",
      "Testing model weights/model_weights_437.pth\n",
      "Validation Loss: 0.6323\n",
      "Testing model weights/model_weights_438.pth\n",
      "Validation Loss: 0.6419\n",
      "Testing model weights/model_weights_439.pth\n",
      "Validation Loss: 0.6273\n",
      "Testing model weights/model_weights_440.pth\n",
      "Validation Loss: 0.6336\n",
      "Testing model weights/model_weights_441.pth\n",
      "Validation Loss: 0.6443\n",
      "Testing model weights/model_weights_442.pth\n",
      "Validation Loss: 0.6339\n",
      "Testing model weights/model_weights_443.pth\n",
      "Validation Loss: 0.6326\n",
      "Testing model weights/model_weights_444.pth\n",
      "Validation Loss: 0.6207\n",
      "Testing model weights/model_weights_445.pth\n",
      "Validation Loss: 0.6261\n",
      "Testing model weights/model_weights_446.pth\n",
      "Validation Loss: 0.6211\n",
      "Testing model weights/model_weights_447.pth\n",
      "Validation Loss: 0.6423\n",
      "Testing model weights/model_weights_448.pth\n",
      "Validation Loss: 0.6237\n",
      "Testing model weights/model_weights_449.pth\n",
      "Validation Loss: 0.6389\n",
      "Testing model weights/model_weights_450.pth\n",
      "Validation Loss: 0.6222\n",
      "Testing model weights/model_weights_451.pth\n",
      "Validation Loss: 0.6281\n",
      "Testing model weights/model_weights_452.pth\n",
      "Validation Loss: 0.6215\n",
      "Testing model weights/model_weights_453.pth\n",
      "Validation Loss: 0.6281\n",
      "Testing model weights/model_weights_454.pth\n",
      "Validation Loss: 0.6307\n",
      "Testing model weights/model_weights_455.pth\n",
      "Validation Loss: 0.6310\n",
      "Testing model weights/model_weights_456.pth\n",
      "Validation Loss: 0.6301\n",
      "Testing model weights/model_weights_457.pth\n",
      "Validation Loss: 0.6155\n",
      "Testing model weights/model_weights_458.pth\n",
      "Validation Loss: 0.6174\n",
      "Testing model weights/model_weights_459.pth\n",
      "Validation Loss: 0.6215\n",
      "Testing model weights/model_weights_460.pth\n",
      "Validation Loss: 0.6313\n",
      "Testing model weights/model_weights_461.pth\n",
      "Validation Loss: 0.6378\n",
      "Testing model weights/model_weights_462.pth\n",
      "Validation Loss: 0.6407\n",
      "Testing model weights/model_weights_463.pth\n",
      "Validation Loss: 0.6380\n",
      "Testing model weights/model_weights_464.pth\n",
      "Validation Loss: 0.6394\n",
      "Testing model weights/model_weights_465.pth\n",
      "Validation Loss: 0.6280\n",
      "Testing model weights/model_weights_466.pth\n",
      "Validation Loss: 0.6252\n",
      "Testing model weights/model_weights_467.pth\n",
      "Validation Loss: 0.6322\n",
      "Testing model weights/model_weights_468.pth\n",
      "Validation Loss: 0.6263\n",
      "Testing model weights/model_weights_469.pth\n",
      "Validation Loss: 0.6355\n",
      "Testing model weights/model_weights_470.pth\n",
      "Validation Loss: 0.6486\n",
      "Testing model weights/model_weights_471.pth\n",
      "Validation Loss: 0.6144\n",
      "Testing model weights/model_weights_472.pth\n",
      "Validation Loss: 0.6324\n",
      "Testing model weights/model_weights_473.pth\n",
      "Validation Loss: 0.6194\n",
      "Testing model weights/model_weights_474.pth\n",
      "Validation Loss: 0.6290\n",
      "Testing model weights/model_weights_475.pth\n",
      "Validation Loss: 0.6566\n",
      "Testing model weights/model_weights_476.pth\n",
      "Validation Loss: 0.6315\n",
      "Testing model weights/model_weights_477.pth\n",
      "Validation Loss: 0.6179\n",
      "Testing model weights/model_weights_478.pth\n",
      "Validation Loss: 0.6361\n",
      "Testing model weights/model_weights_479.pth\n",
      "Validation Loss: 0.6325\n",
      "Testing model weights/model_weights_480.pth\n",
      "Validation Loss: 0.6204\n",
      "Testing model weights/model_weights_481.pth\n",
      "Validation Loss: 0.6199\n",
      "Testing model weights/model_weights_482.pth\n",
      "Validation Loss: 0.6121\n",
      "Testing model weights/model_weights_483.pth\n",
      "Validation Loss: 0.6181\n",
      "Testing model weights/model_weights_484.pth\n",
      "Validation Loss: 0.6360\n",
      "Testing model weights/model_weights_485.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6492\n",
      "Testing model weights/model_weights_486.pth\n",
      "Validation Loss: 0.6364\n",
      "Testing model weights/model_weights_487.pth\n",
      "Validation Loss: 0.6369\n",
      "Testing model weights/model_weights_488.pth\n",
      "Validation Loss: 0.6269\n",
      "Testing model weights/model_weights_489.pth\n",
      "Validation Loss: 0.6403\n",
      "Testing model weights/model_weights_490.pth\n",
      "Validation Loss: 0.6537\n",
      "Testing model weights/model_weights_491.pth\n",
      "Validation Loss: 0.6186\n",
      "Testing model weights/model_weights_492.pth\n",
      "Validation Loss: 0.6281\n",
      "Testing model weights/model_weights_493.pth\n",
      "Validation Loss: 0.6119\n",
      "Testing model weights/model_weights_494.pth\n",
      "Validation Loss: 0.6234\n",
      "Testing model weights/model_weights_495.pth\n",
      "Validation Loss: 0.6161\n",
      "Testing model weights/model_weights_496.pth\n",
      "Validation Loss: 0.6166\n",
      "Testing model weights/model_weights_497.pth\n",
      "Validation Loss: 0.6273\n",
      "Testing model weights/model_weights_498.pth\n",
      "Validation Loss: 0.6081\n",
      "Testing model weights/model_weights_499.pth\n",
      "Validation Loss: 0.6110\n",
      "Testing model weights/model_weights_500.pth\n",
      "Validation Loss: 0.6680\n",
      "Testing model weights/model_weights_501.pth\n",
      "Validation Loss: 0.6227\n",
      "Testing model weights/model_weights_502.pth\n",
      "Validation Loss: 0.6262\n",
      "Testing model weights/model_weights_503.pth\n",
      "Validation Loss: 0.6161\n",
      "Testing model weights/model_weights_504.pth\n",
      "Validation Loss: 0.6274\n",
      "Testing model weights/model_weights_505.pth\n",
      "Validation Loss: 0.6324\n",
      "Testing model weights/model_weights_506.pth\n",
      "Validation Loss: 0.6164\n",
      "Testing model weights/model_weights_507.pth\n",
      "Validation Loss: 0.6274\n",
      "Testing model weights/model_weights_508.pth\n",
      "Validation Loss: 0.6315\n",
      "Testing model weights/model_weights_509.pth\n",
      "Validation Loss: 0.6519\n",
      "Testing model weights/model_weights_510.pth\n",
      "Validation Loss: 0.6163\n",
      "Testing model weights/model_weights_511.pth\n",
      "Validation Loss: 0.6251\n",
      "Testing model weights/model_weights_512.pth\n",
      "Validation Loss: 0.6163\n",
      "Testing model weights/model_weights_513.pth\n",
      "Validation Loss: 0.6255\n",
      "Testing model weights/model_weights_514.pth\n",
      "Validation Loss: 0.6195\n",
      "Testing model weights/model_weights_515.pth\n",
      "Validation Loss: 0.6083\n",
      "Testing model weights/model_weights_516.pth\n",
      "Validation Loss: 0.6234\n",
      "Testing model weights/model_weights_517.pth\n",
      "Validation Loss: 0.6107\n",
      "Testing model weights/model_weights_518.pth\n",
      "Validation Loss: 0.6310\n",
      "Testing model weights/model_weights_519.pth\n",
      "Validation Loss: 0.6185\n",
      "Testing model weights/model_weights_520.pth\n",
      "Validation Loss: 0.6149\n",
      "Testing model weights/model_weights_521.pth\n",
      "Validation Loss: 0.6087\n",
      "Testing model weights/model_weights_522.pth\n",
      "Validation Loss: 0.6166\n",
      "Testing model weights/model_weights_523.pth\n",
      "Validation Loss: 0.6079\n",
      "Testing model weights/model_weights_524.pth\n",
      "Validation Loss: 0.6265\n",
      "Testing model weights/model_weights_525.pth\n",
      "Validation Loss: 0.6311\n",
      "Testing model weights/model_weights_526.pth\n",
      "Validation Loss: 0.6273\n",
      "Testing model weights/model_weights_527.pth\n",
      "Validation Loss: 0.6250\n",
      "Testing model weights/model_weights_528.pth\n",
      "Validation Loss: 0.6224\n",
      "Testing model weights/model_weights_529.pth\n",
      "Validation Loss: 0.6060\n",
      "Testing model weights/model_weights_530.pth\n",
      "Validation Loss: 0.6137\n",
      "Testing model weights/model_weights_531.pth\n",
      "Validation Loss: 0.6539\n",
      "Testing model weights/model_weights_532.pth\n",
      "Validation Loss: 0.6274\n",
      "Testing model weights/model_weights_533.pth\n",
      "Validation Loss: 0.6125\n",
      "Testing model weights/model_weights_534.pth\n",
      "Validation Loss: 0.6264\n",
      "Testing model weights/model_weights_535.pth\n",
      "Validation Loss: 0.6158\n",
      "Testing model weights/model_weights_536.pth\n",
      "Validation Loss: 0.6202\n",
      "Testing model weights/model_weights_537.pth\n",
      "Validation Loss: 0.6243\n",
      "Testing model weights/model_weights_538.pth\n",
      "Validation Loss: 0.6082\n",
      "Testing model weights/model_weights_539.pth\n",
      "Validation Loss: 0.6194\n",
      "Testing model weights/model_weights_540.pth\n",
      "Validation Loss: 0.6115\n",
      "Testing model weights/model_weights_541.pth\n",
      "Validation Loss: 0.6182\n",
      "Testing model weights/model_weights_542.pth\n",
      "Validation Loss: 0.6263\n",
      "Testing model weights/model_weights_543.pth\n",
      "Validation Loss: 0.6037\n",
      "Testing model weights/model_weights_544.pth\n",
      "Validation Loss: 0.6129\n",
      "Testing model weights/model_weights_545.pth\n",
      "Validation Loss: 0.6310\n",
      "Testing model weights/model_weights_546.pth\n",
      "Validation Loss: 0.6093\n",
      "Testing model weights/model_weights_547.pth\n",
      "Validation Loss: 0.6522\n",
      "Testing model weights/model_weights_548.pth\n",
      "Validation Loss: 0.6042\n",
      "Testing model weights/model_weights_549.pth\n",
      "Validation Loss: 0.6144\n",
      "Testing model weights/model_weights_550.pth\n",
      "Validation Loss: 0.6049\n",
      "Testing model weights/model_weights_551.pth\n",
      "Validation Loss: 0.6144\n",
      "Testing model weights/model_weights_552.pth\n",
      "Validation Loss: 0.6207\n",
      "Testing model weights/model_weights_553.pth\n",
      "Validation Loss: 0.6170\n",
      "Testing model weights/model_weights_554.pth\n",
      "Validation Loss: 0.6086\n",
      "Testing model weights/model_weights_555.pth\n",
      "Validation Loss: 0.6025\n",
      "Testing model weights/model_weights_556.pth\n",
      "Validation Loss: 0.6095\n",
      "Testing model weights/model_weights_557.pth\n",
      "Validation Loss: 0.6588\n",
      "Testing model weights/model_weights_558.pth\n",
      "Validation Loss: 0.6057\n",
      "Testing model weights/model_weights_559.pth\n",
      "Validation Loss: 0.6189\n",
      "Testing model weights/model_weights_560.pth\n",
      "Validation Loss: 0.6158\n",
      "Testing model weights/model_weights_561.pth\n",
      "Validation Loss: 0.6135\n",
      "Testing model weights/model_weights_562.pth\n",
      "Validation Loss: 0.6301\n",
      "Testing model weights/model_weights_563.pth\n",
      "Validation Loss: 0.6277\n",
      "Testing model weights/model_weights_564.pth\n",
      "Validation Loss: 0.6190\n",
      "Testing model weights/model_weights_565.pth\n",
      "Validation Loss: 0.6322\n",
      "Testing model weights/model_weights_566.pth\n",
      "Validation Loss: 0.6057\n",
      "Testing model weights/model_weights_567.pth\n",
      "Validation Loss: 0.6171\n",
      "Testing model weights/model_weights_568.pth\n",
      "Validation Loss: 0.6240\n",
      "Testing model weights/model_weights_569.pth\n",
      "Validation Loss: 0.6075\n",
      "Testing model weights/model_weights_570.pth\n",
      "Validation Loss: 0.6445\n",
      "Testing model weights/model_weights_571.pth\n",
      "Validation Loss: 0.6259\n",
      "Testing model weights/model_weights_572.pth\n",
      "Validation Loss: 0.6135\n",
      "Testing model weights/model_weights_573.pth\n",
      "Validation Loss: 0.6173\n",
      "Testing model weights/model_weights_574.pth\n",
      "Validation Loss: 0.6162\n",
      "Testing model weights/model_weights_575.pth\n",
      "Validation Loss: 0.6138\n",
      "Testing model weights/model_weights_576.pth\n",
      "Validation Loss: 0.6177\n",
      "Testing model weights/model_weights_577.pth\n",
      "Validation Loss: 0.6111\n",
      "Testing model weights/model_weights_578.pth\n",
      "Validation Loss: 0.6401\n",
      "Testing model weights/model_weights_579.pth\n",
      "Validation Loss: 0.6073\n",
      "Testing model weights/model_weights_580.pth\n",
      "Validation Loss: 0.6015\n",
      "Testing model weights/model_weights_581.pth\n",
      "Validation Loss: 0.6167\n",
      "Testing model weights/model_weights_582.pth\n",
      "Validation Loss: 0.6248\n",
      "Testing model weights/model_weights_583.pth\n",
      "Validation Loss: 0.6029\n",
      "Testing model weights/model_weights_584.pth\n",
      "Validation Loss: 0.6057\n",
      "Testing model weights/model_weights_585.pth\n",
      "Validation Loss: 0.6051\n",
      "Testing model weights/model_weights_586.pth\n",
      "Validation Loss: 0.6233\n",
      "Testing model weights/model_weights_587.pth\n",
      "Validation Loss: 0.6226\n",
      "Testing model weights/model_weights_588.pth\n",
      "Validation Loss: 0.6309\n",
      "Testing model weights/model_weights_589.pth\n",
      "Validation Loss: 0.6076\n",
      "Testing model weights/model_weights_590.pth\n",
      "Validation Loss: 0.6300\n",
      "Testing model weights/model_weights_591.pth\n",
      "Validation Loss: 0.6033\n",
      "Testing model weights/model_weights_592.pth\n",
      "Validation Loss: 0.6149\n",
      "Testing model weights/model_weights_593.pth\n",
      "Validation Loss: 0.6048\n",
      "Testing model weights/model_weights_594.pth\n",
      "Validation Loss: 0.6240\n",
      "Testing model weights/model_weights_595.pth\n",
      "Validation Loss: 0.6177\n",
      "Testing model weights/model_weights_596.pth\n",
      "Validation Loss: 0.6111\n",
      "Testing model weights/model_weights_597.pth\n",
      "Validation Loss: 0.6125\n",
      "Testing model weights/model_weights_598.pth\n",
      "Validation Loss: 0.6074\n",
      "Testing model weights/model_weights_599.pth\n",
      "Validation Loss: 0.6064\n",
      "Testing model weights/model_weights_600.pth\n",
      "Validation Loss: 0.6241\n",
      "Testing model weights/model_weights_601.pth\n",
      "Validation Loss: 0.6059\n",
      "Testing model weights/model_weights_602.pth\n",
      "Validation Loss: 0.6151\n",
      "Testing model weights/model_weights_603.pth\n",
      "Validation Loss: 0.6165\n",
      "Testing model weights/model_weights_604.pth\n",
      "Validation Loss: 0.5976\n",
      "Testing model weights/model_weights_605.pth\n",
      "Validation Loss: 0.6166\n",
      "Testing model weights/model_weights_606.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6204\n",
      "Testing model weights/model_weights_607.pth\n",
      "Validation Loss: 0.6103\n",
      "Testing model weights/model_weights_608.pth\n",
      "Validation Loss: 0.6214\n",
      "Testing model weights/model_weights_609.pth\n",
      "Validation Loss: 0.6151\n",
      "Testing model weights/model_weights_610.pth\n",
      "Validation Loss: 0.6226\n",
      "Testing model weights/model_weights_611.pth\n",
      "Validation Loss: 0.6076\n",
      "Testing model weights/model_weights_612.pth\n",
      "Validation Loss: 0.6171\n",
      "Testing model weights/model_weights_613.pth\n",
      "Validation Loss: 0.6128\n",
      "Testing model weights/model_weights_614.pth\n",
      "Validation Loss: 0.6109\n",
      "Testing model weights/model_weights_615.pth\n",
      "Validation Loss: 0.6214\n",
      "Testing model weights/model_weights_616.pth\n",
      "Validation Loss: 0.6216\n",
      "Testing model weights/model_weights_617.pth\n",
      "Validation Loss: 0.6039\n",
      "Testing model weights/model_weights_618.pth\n",
      "Validation Loss: 0.6028\n",
      "Testing model weights/model_weights_619.pth\n",
      "Validation Loss: 0.6234\n",
      "Testing model weights/model_weights_620.pth\n",
      "Validation Loss: 0.6132\n",
      "Testing model weights/model_weights_621.pth\n",
      "Validation Loss: 0.6211\n",
      "Testing model weights/model_weights_622.pth\n",
      "Validation Loss: 0.6091\n",
      "Testing model weights/model_weights_623.pth\n",
      "Validation Loss: 0.6140\n",
      "Testing model weights/model_weights_624.pth\n",
      "Validation Loss: 0.6099\n",
      "Testing model weights/model_weights_625.pth\n",
      "Validation Loss: 0.6084\n",
      "Testing model weights/model_weights_626.pth\n",
      "Validation Loss: 0.6095\n",
      "Testing model weights/model_weights_627.pth\n",
      "Validation Loss: 0.6286\n",
      "Testing model weights/model_weights_628.pth\n",
      "Validation Loss: 0.6090\n",
      "Testing model weights/model_weights_629.pth\n",
      "Validation Loss: 0.6253\n",
      "Testing model weights/model_weights_630.pth\n",
      "Validation Loss: 0.6052\n",
      "Testing model weights/model_weights_631.pth\n",
      "Validation Loss: 0.6171\n",
      "Testing model weights/model_weights_632.pth\n",
      "Validation Loss: 0.6041\n",
      "Testing model weights/model_weights_633.pth\n",
      "Validation Loss: 0.6019\n",
      "Testing model weights/model_weights_634.pth\n",
      "Validation Loss: 0.5957\n",
      "Testing model weights/model_weights_635.pth\n",
      "Validation Loss: 0.6169\n",
      "Testing model weights/model_weights_636.pth\n",
      "Validation Loss: 0.6114\n",
      "Testing model weights/model_weights_637.pth\n",
      "Validation Loss: 0.6103\n",
      "Testing model weights/model_weights_638.pth\n",
      "Validation Loss: 0.6151\n",
      "Testing model weights/model_weights_639.pth\n",
      "Validation Loss: 0.6131\n",
      "Testing model weights/model_weights_640.pth\n",
      "Validation Loss: 0.6078\n",
      "Testing model weights/model_weights_641.pth\n",
      "Validation Loss: 0.6160\n",
      "Testing model weights/model_weights_642.pth\n",
      "Validation Loss: 0.6082\n",
      "Testing model weights/model_weights_643.pth\n",
      "Validation Loss: 0.6274\n",
      "Testing model weights/model_weights_644.pth\n",
      "Validation Loss: 0.6176\n",
      "Testing model weights/model_weights_645.pth\n",
      "Validation Loss: 0.6270\n",
      "Testing model weights/model_weights_646.pth\n",
      "Validation Loss: 0.6102\n",
      "Testing model weights/model_weights_647.pth\n",
      "Validation Loss: 0.6126\n",
      "Testing model weights/model_weights_648.pth\n",
      "Validation Loss: 0.5996\n",
      "Testing model weights/model_weights_649.pth\n",
      "Validation Loss: 0.6020\n",
      "Testing model weights/model_weights_650.pth\n",
      "Validation Loss: 0.6171\n",
      "Testing model weights/model_weights_651.pth\n",
      "Validation Loss: 0.6190\n",
      "Testing model weights/model_weights_652.pth\n",
      "Validation Loss: 0.6250\n",
      "Testing model weights/model_weights_653.pth\n",
      "Validation Loss: 0.6241\n",
      "Testing model weights/model_weights_654.pth\n",
      "Validation Loss: 0.6012\n",
      "Testing model weights/model_weights_655.pth\n",
      "Validation Loss: 0.6136\n",
      "Testing model weights/model_weights_656.pth\n",
      "Validation Loss: 0.6070\n",
      "Testing model weights/model_weights_657.pth\n",
      "Validation Loss: 0.6237\n",
      "Testing model weights/model_weights_658.pth\n",
      "Validation Loss: 0.6158\n",
      "Testing model weights/model_weights_659.pth\n",
      "Validation Loss: 0.6033\n",
      "Testing model weights/model_weights_660.pth\n",
      "Validation Loss: 0.6132\n",
      "Testing model weights/model_weights_661.pth\n",
      "Validation Loss: 0.6073\n",
      "Testing model weights/model_weights_662.pth\n",
      "Validation Loss: 0.6051\n",
      "Testing model weights/model_weights_663.pth\n",
      "Validation Loss: 0.6222\n",
      "Testing model weights/model_weights_664.pth\n",
      "Validation Loss: 0.6284\n",
      "Testing model weights/model_weights_665.pth\n",
      "Validation Loss: 0.6115\n",
      "Testing model weights/model_weights_666.pth\n",
      "Validation Loss: 0.6128\n",
      "Testing model weights/model_weights_667.pth\n",
      "Validation Loss: 0.6162\n",
      "Testing model weights/model_weights_668.pth\n",
      "Validation Loss: 0.6054\n",
      "Testing model weights/model_weights_669.pth\n",
      "Validation Loss: 0.6100\n",
      "Testing model weights/model_weights_670.pth\n",
      "Validation Loss: 0.6000\n",
      "Testing model weights/model_weights_671.pth\n",
      "Validation Loss: 0.5998\n",
      "Testing model weights/model_weights_672.pth\n",
      "Validation Loss: 0.6010\n",
      "Testing model weights/model_weights_673.pth\n",
      "Validation Loss: 0.6046\n",
      "Testing model weights/model_weights_674.pth\n",
      "Validation Loss: 0.5983\n",
      "Testing model weights/model_weights_675.pth\n",
      "Validation Loss: 0.5998\n",
      "Testing model weights/model_weights_676.pth\n",
      "Validation Loss: 0.6116\n",
      "Testing model weights/model_weights_677.pth\n",
      "Validation Loss: 0.6066\n",
      "Testing model weights/model_weights_678.pth\n",
      "Validation Loss: 0.6204\n",
      "Testing model weights/model_weights_679.pth\n",
      "Validation Loss: 0.6087\n",
      "Testing model weights/model_weights_680.pth\n",
      "Validation Loss: 0.6022\n",
      "Testing model weights/model_weights_681.pth\n",
      "Validation Loss: 0.6034\n",
      "Testing model weights/model_weights_682.pth\n",
      "Validation Loss: 0.6121\n",
      "Testing model weights/model_weights_683.pth\n",
      "Validation Loss: 0.6098\n",
      "Testing model weights/model_weights_684.pth\n",
      "Validation Loss: 0.6041\n",
      "Testing model weights/model_weights_685.pth\n",
      "Validation Loss: 0.5988\n",
      "Testing model weights/model_weights_686.pth\n",
      "Validation Loss: 0.6046\n",
      "Testing model weights/model_weights_687.pth\n",
      "Validation Loss: 0.6027\n",
      "Testing model weights/model_weights_688.pth\n",
      "Validation Loss: 0.6100\n",
      "Testing model weights/model_weights_689.pth\n",
      "Validation Loss: 0.6052\n",
      "Testing model weights/model_weights_690.pth\n",
      "Validation Loss: 0.6061\n",
      "Testing model weights/model_weights_691.pth\n",
      "Validation Loss: 0.6146\n",
      "Testing model weights/model_weights_692.pth\n",
      "Validation Loss: 0.6085\n",
      "Testing model weights/model_weights_693.pth\n",
      "Validation Loss: 0.6230\n",
      "Testing model weights/model_weights_694.pth\n",
      "Validation Loss: 0.6001\n",
      "Testing model weights/model_weights_695.pth\n",
      "Validation Loss: 0.5990\n",
      "Testing model weights/model_weights_696.pth\n",
      "Validation Loss: 0.6089\n",
      "Testing model weights/model_weights_697.pth\n",
      "Validation Loss: 0.6042\n",
      "Testing model weights/model_weights_698.pth\n",
      "Validation Loss: 0.6030\n",
      "Testing model weights/model_weights_699.pth\n",
      "Validation Loss: 0.6082\n",
      "Testing model weights/model_weights_700.pth\n",
      "Validation Loss: 0.5960\n",
      "Testing model weights/model_weights_701.pth\n",
      "Validation Loss: 0.6078\n",
      "Testing model weights/model_weights_702.pth\n",
      "Validation Loss: 0.6163\n",
      "Testing model weights/model_weights_703.pth\n",
      "Validation Loss: 0.6031\n",
      "Testing model weights/model_weights_704.pth\n",
      "Validation Loss: 0.6072\n",
      "Testing model weights/model_weights_705.pth\n",
      "Validation Loss: 0.6048\n",
      "Testing model weights/model_weights_706.pth\n",
      "Validation Loss: 0.6123\n",
      "Testing model weights/model_weights_707.pth\n",
      "Validation Loss: 0.6094\n",
      "Testing model weights/model_weights_708.pth\n",
      "Validation Loss: 0.6150\n",
      "Testing model weights/model_weights_709.pth\n",
      "Validation Loss: 0.6133\n",
      "Testing model weights/model_weights_710.pth\n",
      "Validation Loss: 0.5985\n",
      "Testing model weights/model_weights_711.pth\n",
      "Validation Loss: 0.6289\n",
      "Testing model weights/model_weights_712.pth\n",
      "Validation Loss: 0.6085\n",
      "Testing model weights/model_weights_713.pth\n",
      "Validation Loss: 0.6188\n",
      "Testing model weights/model_weights_714.pth\n",
      "Validation Loss: 0.6041\n",
      "Testing model weights/model_weights_715.pth\n",
      "Validation Loss: 0.6201\n",
      "Testing model weights/model_weights_716.pth\n",
      "Validation Loss: 0.5988\n",
      "Testing model weights/model_weights_717.pth\n",
      "Validation Loss: 0.6033\n",
      "Testing model weights/model_weights_718.pth\n",
      "Validation Loss: 0.5956\n",
      "Testing model weights/model_weights_719.pth\n",
      "Validation Loss: 0.6248\n",
      "Testing model weights/model_weights_720.pth\n",
      "Validation Loss: 0.6092\n",
      "Testing model weights/model_weights_721.pth\n",
      "Validation Loss: 0.6060\n",
      "Testing model weights/model_weights_722.pth\n",
      "Validation Loss: 0.6174\n",
      "Testing model weights/model_weights_723.pth\n",
      "Validation Loss: 0.5952\n",
      "Testing model weights/model_weights_724.pth\n",
      "Validation Loss: 0.6045\n",
      "Testing model weights/model_weights_725.pth\n",
      "Validation Loss: 0.6164\n",
      "Testing model weights/model_weights_726.pth\n",
      "Validation Loss: 0.6069\n",
      "Testing model weights/model_weights_727.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6197\n",
      "Testing model weights/model_weights_728.pth\n",
      "Validation Loss: 0.6123\n",
      "Testing model weights/model_weights_729.pth\n",
      "Validation Loss: 0.6011\n",
      "Testing model weights/model_weights_730.pth\n",
      "Validation Loss: 0.6194\n",
      "Testing model weights/model_weights_731.pth\n",
      "Validation Loss: 0.6028\n",
      "Testing model weights/model_weights_732.pth\n",
      "Validation Loss: 0.5996\n",
      "Testing model weights/model_weights_733.pth\n",
      "Validation Loss: 0.6033\n",
      "Testing model weights/model_weights_734.pth\n",
      "Validation Loss: 0.6059\n",
      "Testing model weights/model_weights_735.pth\n",
      "Validation Loss: 0.6008\n",
      "Testing model weights/model_weights_736.pth\n",
      "Validation Loss: 0.5957\n",
      "Testing model weights/model_weights_737.pth\n",
      "Validation Loss: 0.6095\n",
      "Testing model weights/model_weights_738.pth\n",
      "Validation Loss: 0.6140\n",
      "Testing model weights/model_weights_739.pth\n",
      "Validation Loss: 0.6006\n",
      "Testing model weights/model_weights_740.pth\n",
      "Validation Loss: 0.6233\n",
      "Testing model weights/model_weights_741.pth\n",
      "Validation Loss: 0.6380\n",
      "Testing model weights/model_weights_742.pth\n",
      "Validation Loss: 0.6208\n",
      "Testing model weights/model_weights_743.pth\n",
      "Validation Loss: 0.6153\n",
      "Testing model weights/model_weights_744.pth\n",
      "Validation Loss: 0.6108\n",
      "Testing model weights/model_weights_745.pth\n",
      "Validation Loss: 0.6081\n",
      "Testing model weights/model_weights_746.pth\n",
      "Validation Loss: 0.5960\n",
      "Testing model weights/model_weights_747.pth\n",
      "Validation Loss: 0.6043\n",
      "Testing model weights/model_weights_748.pth\n",
      "Validation Loss: 0.5957\n",
      "Testing model weights/model_weights_749.pth\n",
      "Validation Loss: 0.6047\n",
      "Testing model weights/model_weights_750.pth\n",
      "Validation Loss: 0.6242\n",
      "Testing model weights/model_weights_751.pth\n",
      "Validation Loss: 0.6282\n",
      "Testing model weights/model_weights_752.pth\n",
      "Validation Loss: 0.6034\n",
      "Testing model weights/model_weights_753.pth\n",
      "Validation Loss: 0.5872\n",
      "Testing model weights/model_weights_754.pth\n",
      "Validation Loss: 0.6458\n",
      "Testing model weights/model_weights_755.pth\n",
      "Validation Loss: 0.6347\n",
      "Testing model weights/model_weights_756.pth\n",
      "Validation Loss: 0.5983\n",
      "Testing model weights/model_weights_757.pth\n",
      "Validation Loss: 0.6134\n",
      "Testing model weights/model_weights_758.pth\n",
      "Validation Loss: 0.5974\n",
      "Testing model weights/model_weights_759.pth\n",
      "Validation Loss: 0.5973\n",
      "Testing model weights/model_weights_760.pth\n",
      "Validation Loss: 0.5976\n",
      "Testing model weights/model_weights_761.pth\n",
      "Validation Loss: 0.6143\n",
      "Testing model weights/model_weights_762.pth\n",
      "Validation Loss: 0.6008\n",
      "Testing model weights/model_weights_763.pth\n",
      "Validation Loss: 0.6068\n",
      "Testing model weights/model_weights_764.pth\n",
      "Validation Loss: 0.6020\n",
      "Testing model weights/model_weights_765.pth\n",
      "Validation Loss: 0.5962\n",
      "Testing model weights/model_weights_766.pth\n",
      "Validation Loss: 0.5954\n",
      "Testing model weights/model_weights_767.pth\n",
      "Validation Loss: 0.6156\n",
      "Testing model weights/model_weights_768.pth\n",
      "Validation Loss: 0.6006\n",
      "Testing model weights/model_weights_769.pth\n",
      "Validation Loss: 0.6010\n",
      "Testing model weights/model_weights_770.pth\n",
      "Validation Loss: 0.6003\n",
      "Testing model weights/model_weights_771.pth\n",
      "Validation Loss: 0.6022\n",
      "Testing model weights/model_weights_772.pth\n",
      "Validation Loss: 0.6225\n",
      "Testing model weights/model_weights_773.pth\n",
      "Validation Loss: 0.5983\n",
      "Testing model weights/model_weights_774.pth\n",
      "Validation Loss: 0.5931\n",
      "Testing model weights/model_weights_775.pth\n",
      "Validation Loss: 0.6110\n",
      "Testing model weights/model_weights_776.pth\n",
      "Validation Loss: 0.5962\n",
      "Testing model weights/model_weights_777.pth\n",
      "Validation Loss: 0.5992\n",
      "Testing model weights/model_weights_778.pth\n",
      "Validation Loss: 0.6081\n",
      "Testing model weights/model_weights_779.pth\n",
      "Validation Loss: 0.5955\n",
      "Testing model weights/model_weights_780.pth\n",
      "Validation Loss: 0.6098\n",
      "Testing model weights/model_weights_781.pth\n",
      "Validation Loss: 0.6049\n",
      "Testing model weights/model_weights_782.pth\n",
      "Validation Loss: 0.6223\n",
      "Testing model weights/model_weights_783.pth\n",
      "Validation Loss: 0.6082\n",
      "Testing model weights/model_weights_784.pth\n",
      "Validation Loss: 0.6157\n",
      "Testing model weights/model_weights_785.pth\n",
      "Validation Loss: 0.5920\n",
      "Testing model weights/model_weights_786.pth\n",
      "Validation Loss: 0.6114\n",
      "Testing model weights/model_weights_787.pth\n",
      "Validation Loss: 0.6003\n",
      "Testing model weights/model_weights_788.pth\n",
      "Validation Loss: 0.5983\n",
      "Testing model weights/model_weights_789.pth\n",
      "Validation Loss: 0.5945\n",
      "Testing model weights/model_weights_790.pth\n",
      "Validation Loss: 0.6079\n",
      "Testing model weights/model_weights_791.pth\n",
      "Validation Loss: 0.6073\n",
      "Testing model weights/model_weights_792.pth\n",
      "Validation Loss: 0.5989\n",
      "Testing model weights/model_weights_793.pth\n",
      "Validation Loss: 0.6092\n",
      "Testing model weights/model_weights_794.pth\n",
      "Validation Loss: 0.6082\n",
      "Testing model weights/model_weights_795.pth\n",
      "Validation Loss: 0.5918\n",
      "Testing model weights/model_weights_796.pth\n",
      "Validation Loss: 0.6194\n",
      "Testing model weights/model_weights_797.pth\n",
      "Validation Loss: 0.6045\n",
      "Testing model weights/model_weights_798.pth\n",
      "Validation Loss: 0.6092\n",
      "Testing model weights/model_weights_799.pth\n",
      "Validation Loss: 0.6067\n",
      "Testing model weights/model_weights_800.pth\n",
      "Validation Loss: 0.6083\n",
      "Testing model weights/model_weights_801.pth\n",
      "Validation Loss: 0.6076\n",
      "Testing model weights/model_weights_802.pth\n",
      "Validation Loss: 0.6093\n",
      "Testing model weights/model_weights_803.pth\n",
      "Validation Loss: 0.6147\n",
      "Testing model weights/model_weights_804.pth\n",
      "Validation Loss: 0.6005\n",
      "Testing model weights/model_weights_805.pth\n",
      "Validation Loss: 0.6121\n",
      "Testing model weights/model_weights_806.pth\n",
      "Validation Loss: 0.5860\n",
      "Testing model weights/model_weights_807.pth\n",
      "Validation Loss: 0.5962\n",
      "Testing model weights/model_weights_808.pth\n",
      "Validation Loss: 0.6065\n",
      "Testing model weights/model_weights_809.pth\n",
      "Validation Loss: 0.5940\n",
      "Testing model weights/model_weights_810.pth\n",
      "Validation Loss: 0.5970\n",
      "Testing model weights/model_weights_811.pth\n",
      "Validation Loss: 0.5944\n",
      "Testing model weights/model_weights_812.pth\n",
      "Validation Loss: 0.5905\n",
      "Testing model weights/model_weights_813.pth\n",
      "Validation Loss: 0.6058\n",
      "Testing model weights/model_weights_814.pth\n",
      "Validation Loss: 0.5948\n",
      "Testing model weights/model_weights_815.pth\n",
      "Validation Loss: 0.5970\n",
      "Testing model weights/model_weights_816.pth\n",
      "Validation Loss: 0.5923\n",
      "Testing model weights/model_weights_817.pth\n",
      "Validation Loss: 0.6013\n",
      "Testing model weights/model_weights_818.pth\n",
      "Validation Loss: 0.6201\n",
      "Testing model weights/model_weights_819.pth\n",
      "Validation Loss: 0.5927\n",
      "Testing model weights/model_weights_820.pth\n",
      "Validation Loss: 0.6107\n",
      "Testing model weights/model_weights_821.pth\n",
      "Validation Loss: 0.5974\n",
      "Testing model weights/model_weights_822.pth\n",
      "Validation Loss: 0.5956\n",
      "Testing model weights/model_weights_823.pth\n",
      "Validation Loss: 0.6032\n",
      "Testing model weights/model_weights_824.pth\n",
      "Validation Loss: 0.6133\n",
      "Testing model weights/model_weights_825.pth\n",
      "Validation Loss: 0.5929\n",
      "Testing model weights/model_weights_826.pth\n",
      "Validation Loss: 0.6022\n",
      "Testing model weights/model_weights_827.pth\n",
      "Validation Loss: 0.6237\n",
      "Testing model weights/model_weights_828.pth\n",
      "Validation Loss: 0.6084\n",
      "Testing model weights/model_weights_829.pth\n",
      "Validation Loss: 0.5877\n",
      "Testing model weights/model_weights_830.pth\n",
      "Validation Loss: 0.6011\n",
      "Testing model weights/model_weights_831.pth\n",
      "Validation Loss: 0.6118\n",
      "Testing model weights/model_weights_832.pth\n",
      "Validation Loss: 0.6044\n",
      "Testing model weights/model_weights_833.pth\n",
      "Validation Loss: 0.5994\n",
      "Testing model weights/model_weights_834.pth\n",
      "Validation Loss: 0.6118\n",
      "Testing model weights/model_weights_835.pth\n",
      "Validation Loss: 0.6039\n",
      "Testing model weights/model_weights_836.pth\n",
      "Validation Loss: 0.6045\n",
      "Testing model weights/model_weights_837.pth\n",
      "Validation Loss: 0.5972\n",
      "Testing model weights/model_weights_838.pth\n",
      "Validation Loss: 0.5977\n",
      "Testing model weights/model_weights_839.pth\n",
      "Validation Loss: 0.5903\n",
      "Testing model weights/model_weights_840.pth\n",
      "Validation Loss: 0.6299\n",
      "Testing model weights/model_weights_841.pth\n",
      "Validation Loss: 0.6073\n",
      "Testing model weights/model_weights_842.pth\n",
      "Validation Loss: 0.5963\n",
      "Testing model weights/model_weights_843.pth\n",
      "Validation Loss: 0.6001\n",
      "Testing model weights/model_weights_844.pth\n",
      "Validation Loss: 0.5919\n",
      "Testing model weights/model_weights_845.pth\n",
      "Validation Loss: 0.5989\n",
      "Testing model weights/model_weights_846.pth\n",
      "Validation Loss: 0.5893\n",
      "Testing model weights/model_weights_847.pth\n",
      "Validation Loss: 0.5972\n",
      "Testing model weights/model_weights_848.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6010\n",
      "Testing model weights/model_weights_849.pth\n",
      "Validation Loss: 0.6103\n",
      "Testing model weights/model_weights_850.pth\n",
      "Validation Loss: 0.5912\n",
      "Testing model weights/model_weights_851.pth\n",
      "Validation Loss: 0.5898\n",
      "Testing model weights/model_weights_852.pth\n",
      "Validation Loss: 0.5960\n",
      "Testing model weights/model_weights_853.pth\n",
      "Validation Loss: 0.5915\n",
      "Testing model weights/model_weights_854.pth\n",
      "Validation Loss: 0.6160\n",
      "Testing model weights/model_weights_855.pth\n",
      "Validation Loss: 0.6043\n",
      "Testing model weights/model_weights_856.pth\n",
      "Validation Loss: 0.5953\n",
      "Testing model weights/model_weights_857.pth\n",
      "Validation Loss: 0.6030\n",
      "Testing model weights/model_weights_858.pth\n",
      "Validation Loss: 0.5948\n",
      "Testing model weights/model_weights_859.pth\n",
      "Validation Loss: 0.6039\n",
      "Testing model weights/model_weights_860.pth\n",
      "Validation Loss: 0.5972\n",
      "Testing model weights/model_weights_861.pth\n",
      "Validation Loss: 0.6022\n",
      "Testing model weights/model_weights_862.pth\n",
      "Validation Loss: 0.6039\n",
      "Testing model weights/model_weights_863.pth\n",
      "Validation Loss: 0.5982\n",
      "Testing model weights/model_weights_864.pth\n",
      "Validation Loss: 0.6069\n",
      "Testing model weights/model_weights_865.pth\n",
      "Validation Loss: 0.6071\n",
      "Testing model weights/model_weights_866.pth\n",
      "Validation Loss: 0.5872\n",
      "Testing model weights/model_weights_867.pth\n",
      "Validation Loss: 0.6026\n",
      "Testing model weights/model_weights_868.pth\n",
      "Validation Loss: 0.5934\n",
      "Testing model weights/model_weights_869.pth\n",
      "Validation Loss: 0.5904\n",
      "Testing model weights/model_weights_870.pth\n",
      "Validation Loss: 0.6083\n",
      "Testing model weights/model_weights_871.pth\n",
      "Validation Loss: 0.5925\n",
      "Testing model weights/model_weights_872.pth\n",
      "Validation Loss: 0.6041\n",
      "Testing model weights/model_weights_873.pth\n",
      "Validation Loss: 0.6016\n",
      "Testing model weights/model_weights_874.pth\n",
      "Validation Loss: 0.5878\n",
      "Testing model weights/model_weights_875.pth\n",
      "Validation Loss: 0.5932\n",
      "Testing model weights/model_weights_876.pth\n",
      "Validation Loss: 0.5984\n",
      "Testing model weights/model_weights_877.pth\n",
      "Validation Loss: 0.6057\n",
      "Testing model weights/model_weights_878.pth\n",
      "Validation Loss: 0.5973\n",
      "Testing model weights/model_weights_879.pth\n",
      "Validation Loss: 0.5856\n",
      "Testing model weights/model_weights_880.pth\n",
      "Validation Loss: 0.6033\n",
      "Testing model weights/model_weights_881.pth\n",
      "Validation Loss: 0.5943\n",
      "Testing model weights/model_weights_882.pth\n",
      "Validation Loss: 0.6009\n",
      "Testing model weights/model_weights_883.pth\n",
      "Validation Loss: 0.5934\n",
      "Testing model weights/model_weights_884.pth\n",
      "Validation Loss: 0.6057\n",
      "Testing model weights/model_weights_885.pth\n",
      "Validation Loss: 0.6147\n",
      "Testing model weights/model_weights_886.pth\n",
      "Validation Loss: 0.5928\n",
      "Testing model weights/model_weights_887.pth\n",
      "Validation Loss: 0.5976\n",
      "Testing model weights/model_weights_888.pth\n",
      "Validation Loss: 0.5995\n",
      "Testing model weights/model_weights_889.pth\n",
      "Validation Loss: 0.5933\n",
      "Testing model weights/model_weights_890.pth\n",
      "Validation Loss: 0.5981\n",
      "Testing model weights/model_weights_891.pth\n",
      "Validation Loss: 0.6128\n",
      "Testing model weights/model_weights_892.pth\n",
      "Validation Loss: 0.6130\n",
      "Testing model weights/model_weights_893.pth\n",
      "Validation Loss: 0.5819\n",
      "Testing model weights/model_weights_894.pth\n",
      "Validation Loss: 0.5933\n",
      "Testing model weights/model_weights_895.pth\n",
      "Validation Loss: 0.5965\n",
      "Testing model weights/model_weights_896.pth\n",
      "Validation Loss: 0.6136\n",
      "Testing model weights/model_weights_897.pth\n",
      "Validation Loss: 0.6092\n",
      "Testing model weights/model_weights_898.pth\n",
      "Validation Loss: 0.5900\n",
      "Testing model weights/model_weights_899.pth\n",
      "Validation Loss: 0.6146\n",
      "Testing model weights/model_weights_900.pth\n",
      "Validation Loss: 0.6074\n",
      "Testing model weights/model_weights_901.pth\n",
      "Validation Loss: 0.5980\n",
      "Testing model weights/model_weights_902.pth\n",
      "Validation Loss: 0.5993\n",
      "Testing model weights/model_weights_903.pth\n",
      "Validation Loss: 0.6042\n",
      "Testing model weights/model_weights_904.pth\n",
      "Validation Loss: 0.6228\n",
      "Testing model weights/model_weights_905.pth\n",
      "Validation Loss: 0.6001\n",
      "Testing model weights/model_weights_906.pth\n",
      "Validation Loss: 0.6109\n",
      "Testing model weights/model_weights_907.pth\n",
      "Validation Loss: 0.5862\n",
      "Testing model weights/model_weights_908.pth\n",
      "Validation Loss: 0.6129\n",
      "Testing model weights/model_weights_909.pth\n",
      "Validation Loss: 0.6012\n",
      "Testing model weights/model_weights_910.pth\n",
      "Validation Loss: 0.6004\n",
      "Testing model weights/model_weights_911.pth\n",
      "Validation Loss: 0.5932\n",
      "Testing model weights/model_weights_912.pth\n",
      "Validation Loss: 0.6066\n",
      "Testing model weights/model_weights_913.pth\n",
      "Validation Loss: 0.5935\n",
      "Testing model weights/model_weights_914.pth\n",
      "Validation Loss: 0.6078\n",
      "Testing model weights/model_weights_915.pth\n",
      "Validation Loss: 0.6048\n",
      "Testing model weights/model_weights_916.pth\n",
      "Validation Loss: 0.5955\n",
      "Testing model weights/model_weights_917.pth\n",
      "Validation Loss: 0.5940\n",
      "Testing model weights/model_weights_918.pth\n",
      "Validation Loss: 0.6094\n",
      "Testing model weights/model_weights_919.pth\n",
      "Validation Loss: 0.5946\n",
      "Testing model weights/model_weights_920.pth\n",
      "Validation Loss: 0.5900\n",
      "Testing model weights/model_weights_921.pth\n",
      "Validation Loss: 0.5886\n",
      "Testing model weights/model_weights_922.pth\n",
      "Validation Loss: 0.6132\n",
      "Testing model weights/model_weights_923.pth\n",
      "Validation Loss: 0.5949\n",
      "Testing model weights/model_weights_924.pth\n",
      "Validation Loss: 0.5963\n",
      "Testing model weights/model_weights_925.pth\n",
      "Validation Loss: 0.5970\n",
      "Testing model weights/model_weights_926.pth\n",
      "Validation Loss: 0.5904\n",
      "Testing model weights/model_weights_927.pth\n",
      "Validation Loss: 0.5950\n",
      "Testing model weights/model_weights_928.pth\n",
      "Validation Loss: 0.5896\n",
      "Testing model weights/model_weights_929.pth\n",
      "Validation Loss: 0.5977\n",
      "Testing model weights/model_weights_930.pth\n",
      "Validation Loss: 0.5960\n",
      "Testing model weights/model_weights_931.pth\n",
      "Validation Loss: 0.5955\n",
      "Testing model weights/model_weights_932.pth\n",
      "Validation Loss: 0.6064\n",
      "Testing model weights/model_weights_933.pth\n",
      "Validation Loss: 0.6169\n",
      "Testing model weights/model_weights_934.pth\n",
      "Validation Loss: 0.6041\n",
      "Testing model weights/model_weights_935.pth\n",
      "Validation Loss: 0.5929\n",
      "Testing model weights/model_weights_936.pth\n",
      "Validation Loss: 0.6016\n",
      "Testing model weights/model_weights_937.pth\n",
      "Validation Loss: 0.5919\n",
      "Testing model weights/model_weights_938.pth\n",
      "Validation Loss: 0.6081\n",
      "Testing model weights/model_weights_939.pth\n",
      "Validation Loss: 0.6040\n",
      "Testing model weights/model_weights_940.pth\n",
      "Validation Loss: 0.5859\n",
      "Testing model weights/model_weights_941.pth\n",
      "Validation Loss: 0.5971\n",
      "Testing model weights/model_weights_942.pth\n",
      "Validation Loss: 0.5952\n",
      "Testing model weights/model_weights_943.pth\n",
      "Validation Loss: 0.5955\n",
      "Testing model weights/model_weights_944.pth\n",
      "Validation Loss: 0.6256\n",
      "Testing model weights/model_weights_945.pth\n",
      "Validation Loss: 0.5858\n",
      "Testing model weights/model_weights_946.pth\n",
      "Validation Loss: 0.5900\n",
      "Testing model weights/model_weights_947.pth\n",
      "Validation Loss: 0.5945\n",
      "Testing model weights/model_weights_948.pth\n",
      "Validation Loss: 0.5890\n",
      "Testing model weights/model_weights_949.pth\n",
      "Validation Loss: 0.5940\n",
      "Testing model weights/model_weights_950.pth\n",
      "Validation Loss: 0.6039\n",
      "Testing model weights/model_weights_951.pth\n",
      "Validation Loss: 0.5838\n",
      "Testing model weights/model_weights_952.pth\n",
      "Validation Loss: 0.6029\n",
      "Testing model weights/model_weights_953.pth\n",
      "Validation Loss: 0.6062\n",
      "Testing model weights/model_weights_954.pth\n",
      "Validation Loss: 0.5938\n",
      "Testing model weights/model_weights_955.pth\n",
      "Validation Loss: 0.5842\n",
      "Testing model weights/model_weights_956.pth\n",
      "Validation Loss: 0.5840\n",
      "Testing model weights/model_weights_957.pth\n",
      "Validation Loss: 0.5947\n",
      "Testing model weights/model_weights_958.pth\n",
      "Validation Loss: 0.5866\n",
      "Testing model weights/model_weights_959.pth\n",
      "Validation Loss: 0.6068\n",
      "Testing model weights/model_weights_960.pth\n",
      "Validation Loss: 0.5900\n",
      "Testing model weights/model_weights_961.pth\n",
      "Validation Loss: 0.5858\n",
      "Testing model weights/model_weights_962.pth\n",
      "Validation Loss: 0.6019\n",
      "Testing model weights/model_weights_963.pth\n",
      "Validation Loss: 0.5969\n",
      "Testing model weights/model_weights_964.pth\n",
      "Validation Loss: 0.6075\n",
      "Testing model weights/model_weights_965.pth\n",
      "Validation Loss: 0.5977\n",
      "Testing model weights/model_weights_966.pth\n",
      "Validation Loss: 0.5991\n",
      "Testing model weights/model_weights_967.pth\n",
      "Validation Loss: 0.6175\n",
      "Testing model weights/model_weights_968.pth\n",
      "Validation Loss: 0.5886\n",
      "Testing model weights/model_weights_969.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5913\n",
      "Testing model weights/model_weights_970.pth\n",
      "Validation Loss: 0.5921\n",
      "Testing model weights/model_weights_971.pth\n",
      "Validation Loss: 0.5985\n",
      "Testing model weights/model_weights_972.pth\n",
      "Validation Loss: 0.5838\n",
      "Testing model weights/model_weights_973.pth\n",
      "Validation Loss: 0.6050\n",
      "Testing model weights/model_weights_974.pth\n",
      "Validation Loss: 0.5917\n",
      "Testing model weights/model_weights_975.pth\n",
      "Validation Loss: 0.5879\n",
      "Testing model weights/model_weights_976.pth\n",
      "Validation Loss: 0.6031\n",
      "Testing model weights/model_weights_977.pth\n",
      "Validation Loss: 0.6154\n",
      "Testing model weights/model_weights_978.pth\n",
      "Validation Loss: 0.6055\n",
      "Testing model weights/model_weights_979.pth\n",
      "Validation Loss: 0.5760\n",
      "Testing model weights/model_weights_980.pth\n",
      "Validation Loss: 0.5893\n",
      "Testing model weights/model_weights_981.pth\n",
      "Validation Loss: 0.6110\n",
      "Testing model weights/model_weights_982.pth\n",
      "Validation Loss: 0.5830\n",
      "Testing model weights/model_weights_983.pth\n",
      "Validation Loss: 0.5984\n",
      "Testing model weights/model_weights_984.pth\n",
      "Validation Loss: 0.5875\n",
      "Testing model weights/model_weights_985.pth\n",
      "Validation Loss: 0.5869\n",
      "Testing model weights/model_weights_986.pth\n",
      "Validation Loss: 0.6261\n",
      "Testing model weights/model_weights_987.pth\n",
      "Validation Loss: 0.5929\n",
      "Testing model weights/model_weights_988.pth\n",
      "Validation Loss: 0.5825\n",
      "Testing model weights/model_weights_989.pth\n",
      "Validation Loss: 0.6035\n",
      "Testing model weights/model_weights_990.pth\n",
      "Validation Loss: 0.6126\n",
      "Testing model weights/model_weights_991.pth\n",
      "Validation Loss: 0.5927\n",
      "Testing model weights/model_weights_992.pth\n",
      "Validation Loss: 0.5909\n",
      "Testing model weights/model_weights_993.pth\n",
      "Validation Loss: 0.5994\n",
      "Testing model weights/model_weights_994.pth\n",
      "Validation Loss: 0.5913\n",
      "Testing model weights/model_weights_995.pth\n",
      "Validation Loss: 0.5856\n",
      "Testing model weights/model_weights_996.pth\n",
      "Validation Loss: 0.5961\n",
      "Testing model weights/model_weights_997.pth\n",
      "Validation Loss: 0.5837\n",
      "Testing model weights/model_weights_998.pth\n",
      "Validation Loss: 0.5926\n",
      "Testing model weights/model_weights_999.pth\n",
      "Validation Loss: 0.5987\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "num = []\n",
    "#train_iterations = 1000\n",
    "for i in range(train_iterations):\n",
    "    if (i % save_every == 0):\n",
    "        #print(i)\n",
    "        num.append(i)\n",
    "        val_loss.append(evaluate(f'weights/model_weights_{i}.pth',val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a0d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5759910686224395\n"
     ]
    }
   ],
   "source": [
    "print(min(val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8ea5035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3a40b415d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(running_loss_es, label = \"Train loss\")\n",
    "plt.plot(val_loss, label = \"Validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bc01b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!systemctl suspend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35b78826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGdCAYAAAAbudkLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFj0lEQVR4nO3deXwTZf4H8E+aNOlBCbTYlkK5fiKigCIooK7gioCCrD93RRe34k8WdFUQgfVYdWVdBdcDWGFVRATkEN1FXECtgCKKlKtQbjkLFGhpgTa9c83z+6N0mklmkkk6k5kk3/frVWiTJzPPTOb4znMaGGMMhBBCCCFRKE7rDBBCCCGEqIUCHUIIIYRELQp0CCGEEBK1KNAhhBBCSNSiQIcQQgghUYsCHUIIIYRELQp0CCGEEBK1KNAhhBBCSNQyaZ0BLXEch3PnziElJQUGg0Hr7BBCCCFEBsYYqqqqkJWVhbg4/2U2MR3onDt3DtnZ2VpngxBCCCEhKCoqQvv27f2mielAJyUlBUDDjmrZsqXGuSGEEEKIHJWVlcjOzubv4/7EdKDTWF3VsmVLCnQIIYSQCCOn2Qk1RiaEEEJI1KJAhxBCCCFRiwIdQgghhEStmG6jQwghJPowxuByueB2u7XOCgmR0WiEyWRSZOgXCnQIIYREDYfDgeLiYtTW1mqdFdJMSUlJaNu2Lcxmc7OWQ4EOIYSQqMBxHAoLC2E0GpGVlQWz2UyDwUYgxhgcDgfKyspQWFiIrl27BhwU0B8KdAghhEQFh8MBjuOQnZ2NpKQkrbNDmiExMRHx8fE4deoUHA4HEhISQl4WNUYmhBASVZrz9E/0Q6nvkY4GQgghhEQtCnQIIYSQGNKpUyfMnj2b/9tgMODLL78Mez6mTZuG66+/XvX1UKBDCCGExLDi4mLcddddstKGKzhREjVGJoQQQiKMw+FodrfrRpmZmYosR6+oREdLLgewZS5w/qDWOSGEEKKhQYMG4amnnsJTTz2FVq1aIS0tDS+99BIYYwAaqptee+01PPLII7BarRg3bhwAYMuWLbjtttuQmJiI7OxsTJw4ETU1NfxyS0tLcc899yAxMRGdO3fGsmXLfNbtXXV15swZPPjgg0hNTUVycjL69u2Lbdu2YdGiRfjb3/6GPXv2wGAwwGAwYNGiRQAAm82G8ePHIz09HS1btsSvf/1r7NmzR7CeN954AxkZGUhJScHYsWNRX1+v8F4URyU6Wtr6HrDhlYbfp9m0zQshhEQhxhjqnOEfITkx3hj0GD6LFy/G2LFjsW3bNuzcuRPjx49Hx44d+aDmrbfewssvv4yXXnoJALBv3z4MHToUf//737FgwQKUlZXxwdLChQsBAI888giKiorw/fffw2w2Y+LEiSgtLZXMQ3V1NQYOHIh27dph9erVyMzMxK5du8BxHB544AHs378fubm52LBhAwDAarWCMYbhw4cjNTUVX3/9NaxWK+bNm4c77rgDR44cQWpqKj7//HO88sor+Ne//oVf/epXWLJkCd5991106dIllN0bFAp0tHRul9Y5IISQqFbndOOav34b9vUefHUokszB3WKzs7Mxa9YsGAwGdOvWDfv27cOsWbP4QOfXv/41pk6dyqd/+OGHMXr0aEyaNAkA0LVrV7z77rsYOHAg3n//fZw+fRrffPMNtm7din79+gEAFixYgO7du0vmYfny5SgrK8OOHTuQmpoKALjyyiv591u0aAGTySSo7vr++++xb98+lJaWwmKxAADefvttfPnll/jPf/6D8ePHY/bs2Xj00Ufxxz/+EQDw2muvYcOGDWEp1aGqK0IIIUQH+vfvLygFGjBgAI4ePcrP2dW3b19B+vz8fCxatAgtWrTgf4YOHcqPEH3o0CGYTCbB566++mq0atVKMg8FBQXo3bs3H+TIkZ+fj+rqaqSlpQnyUlhYiOPHjwMADh06hAEDBgg+5/23WqhEhxBCSNRKjDfi4KtDNVmv0pKTkwV/cxyHxx57DBMnTvRJ26FDBxw+fBgAgqpCS0xMDDpfHMehbdu2+OGHH3ze8xdUhQsFOoQQQqKWwWAIugpJK1u3bvX5u2vXrjAaxYOmG264AQcOHBBULXnq3r07XC4Xdu7ciZtuugkAcPjwYVRUVEjmoVevXvjoo49w6dIl0VIds9nsMyv8DTfcgJKSEphMJnTq1EkyL1u3bsXDDz8s2L5woKorQgghRAeKioowefJkHD58GJ9++inmzJmDp59+WjL9c889h7y8PDz55JMoKCjA0aNHsXr1akyYMAEA0K1bNwwbNgzjxo3Dtm3bkJ+fjz/+8Y9+S21+//vfIzMzE/feey9+/vlnnDhxAitXrkReXh6Aht5fhYWFKCgowIULF2C32zF48GAMGDAA9957L7799lucPHkSW7ZswUsvvYSdO3cCAJ5++ml8/PHH+Pjjj3HkyBG88sorOHDggIJ7TxoFOoQQQogOPPzww6irq8NNN92EJ598EhMmTMD48eMl0/fq1QubNm3C0aNH8atf/Qq9e/fGyy+/jLZt2/JpFi5ciOzsbAwcOBD33Xcf3wVcitlsxrp165Ceno67774bPXv2xBtvvMGXKv32t7/FsGHDcPvtt+OKK67Ap59+CoPBgK+//hq33XYbHn30UVx11VV48MEHcfLkSWRkZAAAHnjgAfz1r3/Fc889hz59+uDUqVP405/+pNCe88/AGjvpx6DKykpYrVbYbDa0bNky/Bn4/GHg4H8bfqfu5YQQ0iz19fUoLCxE586dmzXbtRYGDRqE66+/XjA1Q6zz930Gc/+mEh1CCCGERC0KdAghhBAStSKjKTohhBASxcS6ZhNlUIkOIYQQQqIWBTqEEEIIiVoU6BBCCCEkagUd6Pz444+45557kJWV5TO1u7fHHnsMBoPBp7uc3W7HhAkT0KZNGyQnJ2PkyJE4c+aMIE15eTlycnJgtVphtVqRk5PjM5rj6dOncc899yA5ORlt2rTBxIkT4XA4gt0kQgghhESpoAOdmpoaXHfddZg7d67fdF9++SW2bduGrKwsn/cmTZqEVatWYcWKFdi8eTOqq6sxYsQIwbDSo0ePRkFBAXJzc5Gbm4uCggLk5OTw77vdbgwfPhw1NTXYvHkzVqxYgZUrV2LKlCnBbhIhhBBColTQva7uuusu3HXXXX7TnD17Fk899RS+/fZbDB8+XPCezWbDggULsGTJEgwePBgAsHTpUmRnZ2PDhg0YOnQoDh06hNzcXMHU8vPnz8eAAQNw+PBhdOvWDevWrcPBgwdRVFTEB1PvvPMOHnnkEbz++uvaDABICCGEEF1RvI0Ox3HIycnBn//8Z1x77bU+7+fn58PpdGLIkCH8a1lZWejRowe2bNkCAMjLy4PVauWDHKBh+nqr1SpI06NHD0GJ0dChQ2G325Gfny+aN7vdjsrKSsEPIYQQQsLnhx9+gMFg8Du5qJIUD3T+8Y9/wGQyiU4bDwAlJSUwm81o3bq14PWMjAyUlJTwacTm4khPTxekaZxDo1Hr1q1hNpv5NN5mzJjBt/mxWq3Izs4OevsUFbuzbxBCCIkg4Q5OlKRooJOfn49//vOfWLRoEQwGQ1CfZYwJPiP2+VDSeHrhhRdgs9n4n6KioqDySAghhJDIomig89NPP6G0tBQdOnSAyWSCyWTCqVOnMGXKFHTq1AkAkJmZCYfDgfLycsFnS0tL+RKazMxMnD9/3mf5ZWVlgjTeJTfl5eVwOp0+JT2NLBYLWrZsKfjRVJDBICGEkOjEGMObb76JLl26IDExEddddx3+85//gDGGwYMHY9iwYWicg7uiogIdOnTAiy++CKCptOWrr77Cddddh4SEBPTr1w/79u0TrGPLli247bbbkJiYiOzsbEycOBE1NTX8+3a7Hc8++yyys7NhsVjQtWtXLFiwACdPnsTtt98OoKHmxGAw4JFHHvGbb09ff/01rrrqKiQmJuL222/HyZMnVdqLElgzAGCrVq3i/75w4QLbt2+f4CcrK4s999xz7JdffmGMMVZRUcHi4+PZZ599xn/u3LlzLC4ujuXm5jLGGDt48CADwLZt28an2bp1KwPAL+frr79mcXFx7Ny5c3yaFStWMIvFwmw2m6z822w2BkB2esV9lsPYKy0bfgghhDRLXV0dO3jwIKurq2t6keMYs1eH/4fjgsr7X/7yF3b11Vez3Nxcdvz4cbZw4UJmsVjYDz/8wM6cOcNat27NZs+ezRhj7IEHHmB9+/ZlDoeDMcbYxo0bGQDWvXt3tm7dOrZ37142YsQI1qlTJz7N3r17WYsWLdisWbPYkSNH2M8//8x69+7NHnnkET4Po0aNYtnZ2eyLL75gx48fZxs2bGArVqxgLpeLrVy5kgFghw8fZsXFxayioiJgvhlj7PTp08xisbCnn36a/fLLL2zp0qUsIyODAWDl5eXBf5+XBXP/DrrXVXV1NY4dO8b/XVhYiIKCAqSmpqJDhw5IS0sTpI+Pj0dmZia6desGALBarRg7diymTJmCtLQ0pKamYurUqejZsyffC6t79+4YNmwYxo0bh3nz5gEAxo8fjxEjRvDLGTJkCK655hrk5OTgrbfewqVLlzB16lSMGzdO+5IaQggh+uCsBab7DnOiur+cA8zJspLW1NRg5syZ+P777zFgwAAAQJcuXbB582bMmzcPy5cvx7x585CTk4Pz589jzZo12L17N+Lj4wXLeeWVV3DnnXcCABYvXoz27dtj1apVGDVqFN566y2MHj0akyZNAgB07doV7777LgYOHIj3338fp0+fxueff47169fz9+IuXbrwy05NTQXQ0Fa2VatWsvLduOwuXbpg1qxZMBgM6NatG/bt24d//OMfoe3XEAQd6OzcuZMvwgKAyZMnAwDGjBmDRYsWyVrGrFmzYDKZMGrUKNTV1eGOO+7AokWLYDQa+TTLli3DxIkT+d5ZI0eOFIzdYzQa8dVXX+GJJ57ALbfcgsTERIwePRpvv/12sJtECCGEaObgwYOor6/ng5RGDocDvXv3BgDcf//9WLVqFWbMmIH3338fV111lc9yGoMNoCEw6datGw4dOgSgoQ3tsWPHsGzZMj4NYwwcx6GwsBD79u2D0WjEwIEDFc33oUOH0L9/f0HbWc98hkPQgc6gQYP4ekI5xOriEhISMGfOHMyZM0fyc6mpqVi6dKnfZXfo0AFr166VnRdCCCExJj6poXRFi/XKxHEcAOCrr75Cu3btBO9ZLBYAQG1tLfLz82E0GnH06FHZy24MMDiOw2OPPSbaI7pDhw6Cmhol8x1MvKCWoAMdQgghJGIYDLKrkLRyzTXXwGKx4PTp05IlKlOmTEFcXBy++eYb3H333Rg+fDh+/etfC9Js3boVHTp0ANDQOefIkSO4+uqrAQA33HADDhw4gCuvvFJ0+T179gTHcdi0aRNfdeXJbDYDgGAGAzn5vuaaa3ymitq6datoWrVQoEMIIYRoKCUlBVOnTsUzzzwDjuNw6623orKyElu2bEGLFi3Qpk0bfPzxx8jLy8MNN9yA559/HmPGjMHevXsFY9K9+uqrSEtLQ0ZGBl588UW0adMG9957LwDgueeeQ//+/fHkk09i3LhxSE5OxqFDh7B+/XrMmTMHnTp1wpgxY/Doo4/i3XffxXXXXYdTp06htLQUo0aNQseOHWEwGLB27VrcfffdSExMDJjvMWPG4PHHH8c777yDyZMn47HHHkN+fr7sZi6KCdhcOYpRrytCCIke/nrp6B3Hceyf//wn69atG4uPj2dXXHEFGzp0KPvhhx9YRkYGmz59Op/W6XSym266iY0aNYox1tTras2aNezaa69lZrOZ3XjjjaygoECwju3bt7M777yTtWjRgiUnJ7NevXqx119/nX+/rq6OPfPMM6xt27bMbDazK6+8kn388cf8+6+++irLzMxkBoOBjRkzxm++N23axH9uzZo17Morr2QWi4X96le/Yh9//HFYe10ZGNNBBZpGKisrYbVaYbPZtOmp9fnDwMH/Nvw+zRb+9RNCSBSpr69HYWEhOnfujISEBK2zEzY//PADbr/9dpSXl/M9oqKBv+8zmPu34lNAEEIIIYToBQU6hBBCCIla1BiZEEIIiWDBDvsSa6hEhxBCCCFRiwIdQgghhEQtCnQIIYREFarGiQ5KfY8U6BBCCIkKjZNc1tbWapwTooTG79F78tJgUWNkQgghUcFoNKJVq1YoLS0FACQlJQkmkySRgTGG2tpalJaWolWrVoIJv0NBgQ4hhJCokZmZCQB8sEMiV6tWrfjvszko0CGEEBI1DAYD2rZti/T0dDidTq2zQ0IUHx/f7JKcRhToEEIIiTpGo1GxGyWJbNQYmRBCCCFRiwIdQgghhEQtCnQIIYQQErUo0CGEEEJI1KJAh5Bo5KgBcv8CnMrTOieEEKIpCnQIiUY/vg1s/RewcJjWOSGEEE1RoENINLp4VOscEEKILlCgQwghhJCoRYEOIYQQQqIWBTqEEEIIiVoU6BBCCCEkalGgQwghhJCoRYEOIYQQQqIWBTqEEEIIiVoU6BBCCCEkalGgoyXGtM4BIYQQEtUo0CHRz1kH5C8CKou1zgkhhJAwM2mdgZhmMGidg9iwYRqw7QMgpS0w5Retc0MIISSMqESHRL8juQ3/V1GJDiGExJqgA50ff/wR99xzD7KysmAwGPDll1/y7zmdTjz33HPo2bMnkpOTkZWVhYcffhjnzp0TLMNut2PChAlo06YNkpOTMXLkSJw5c0aQpry8HDk5ObBarbBarcjJyUFFRYUgzenTp3HPPfcgOTkZbdq0wcSJE+FwOILdJEIIIYREqaADnZqaGlx33XWYO3euz3u1tbXYtWsXXn75ZezatQtffPEFjhw5gpEjRwrSTZo0CatWrcKKFSuwefNmVFdXY8SIEXC73Xya0aNHo6CgALm5ucjNzUVBQQFycnL4991uN4YPH46amhps3rwZK1aswMqVKzFlypRgN4kQQgghUSroNjp33XUX7rrrLtH3rFYr1q9fL3htzpw5uOmmm3D69Gl06NABNpsNCxYswJIlSzB48GAAwNKlS5GdnY0NGzZg6NChOHToEHJzc7F161b069cPADB//nwMGDAAhw8fRrdu3bBu3TocPHgQRUVFyMrKAgC88847eOSRR/D666+jZcuWwW4aIYQQQqKM6m10bDYbDAYDWrVqBQDIz8+H0+nEkCFD+DRZWVno0aMHtmzZAgDIy8uD1WrlgxwA6N+/P6xWqyBNjx49+CAHAIYOHQq73Y78/HzRvNjtdlRWVgp+CCGEEBK9VA106uvr8fzzz2P06NF8CUtJSQnMZjNat24tSJuRkYGSkhI+TXp6us/y0tPTBWkyMjIE77du3Rpms5lP423GjBl8mx+r1Yrs7OxmbyMhhBBC9Eu1QMfpdOLBBx8Ex3F47733AqZnjMHg0d3aINL1OpQ0nl544QXYbDb+p6ioSM6mEEIIISRCqRLoOJ1OjBo1CoWFhVi/fr2gvUxmZiYcDgfKy8sFnyktLeVLaDIzM3H+/Hmf5ZaVlQnSeJfclJeXw+l0+pT0NLJYLGjZsqXghxBCCCHRS/FApzHIOXr0KDZs2IC0tDTB+3369EF8fLyg0XJxcTH279+Pm2++GQAwYMAA2Gw2bN++nU+zbds22Gw2QZr9+/ejuLhpbJR169bBYrGgT58+Sm+WOmgKCEIIIURVQfe6qq6uxrFjx/i/CwsLUVBQgNTUVGRlZeF3v/sddu3ahbVr18LtdvOlLqmpqTCbzbBarRg7diymTJmCtLQ0pKamYurUqejZsyffC6t79+4YNmwYxo0bh3nz5gEAxo8fjxEjRqBbt24AgCFDhuCaa65BTk4O3nrrLVy6dAlTp07FuHHjqKSGEEIIIQBCCHR27tyJ22+/nf978uTJAIAxY8Zg2rRpWL16NQDg+uuvF3xu48aNGDRoEABg1qxZMJlMGDVqFOrq6nDHHXdg0aJFMBqNfPply5Zh4sSJfO+skSNHCsbuMRqN+Oqrr/DEE0/glltuQWJiIkaPHo2333472E3SDk0BQQghhKgq6EBn0KBBYH6qXPy91yghIQFz5szBnDlzJNOkpqZi6dKlfpfToUMHrF27NuD6SIyjKkJCCIlZNNcVIYQQQqIWBTok+lEVISGExCwKdEj0E6m6+nhzIab+ew84jqq1CCEkmgXdRoeQaPDq2oMAgOG92uL2br6jcBNCCIkOVKJDop+fqqtauzuMGSGEEBJuFOiQ6Ee9rgghJGZRoEMIIYSQqEWBDol+1OuKEEJiFgU6JPpR1RUhhMQsCnQIIYQQErUo0CHRj6quCIltLjuw5H+BzbO1zgnRAAU6WqIqlfCg/UxIbNv7GXD8e2DDK1rnhGiAAh1CCFFZaWU9Rs/fim/2FWudldjkrNM6B0RDFOhoiapUwoP2M9HY3786hC3HL+JPy3ZpnZXYRKW6MY0CHRL96CJHNFZe49A6CyRUHAdUnNY6F6QZKNAhhBAS3ZpTqrtmIjC7J5C/WLn8kLCiQIdEP6q6IoSEaveShv9/mKFtPkjIKNAh0Y+qrgghJGZRoEMIIYSQqEWBDol+VHVFCCExiwIdEv2o6ooQIqXiNHD+YOB0dB2JWCatM0AIIYRoZnbPhv+nHAFSMrTNC1EFlehoiZ4QwoOqrgghgVw6rnUOiEoo0CHRjwJKQgiJWRToaIlKGgghRH30sBPTKNAhhBBCSNSiQIcQQkh0o9LzmEaBDiGEkOhGVVcxjQIdQgghJCAKliIVBTqEEEKiG1VdxTQKdAghhEQ3RaquKFiKVBToEEIIIQFR1VWkokCHEEJIdKOqq5hGgY6WqCcAIYSoj661MY0CHUIIIYREraADnR9//BH33HMPsrKyYDAY8OWXXwreZ4xh2rRpyMrKQmJiIgYNGoQDBw4I0tjtdkyYMAFt2rRBcnIyRo4ciTNnzgjSlJeXIycnB1arFVarFTk5OaioqBCkOX36NO655x4kJyejTZs2mDhxIhwOR7CbpB0qTiWEEEJUFXSgU1NTg+uuuw5z584Vff/NN9/EzJkzMXfuXOzYsQOZmZm48847UVVVxaeZNGkSVq1ahRUrVmDz5s2orq7GiBEj4Ha7+TSjR49GQUEBcnNzkZubi4KCAuTk5PDvu91uDB8+HDU1Ndi8eTNWrFiBlStXYsqUKcFuEiGEEEKilCnYD9x111246667RN9jjGH27Nl48cUXcd999wEAFi9ejIyMDCxfvhyPPfYYbDYbFixYgCVLlmDw4MEAgKVLlyI7OxsbNmzA0KFDcejQIeTm5mLr1q3o168fAGD+/PkYMGAADh8+jG7dumHdunU4ePAgioqKkJWVBQB455138Mgjj+D1119Hy5YtQ9ohYUX1xoQQoj4qPY9pirbRKSwsRElJCYYMGcK/ZrFYMHDgQGzZsgUAkJ+fD6fTKUiTlZWFHj168Gny8vJgtVr5IAcA+vfvD6vVKkjTo0cPPsgBgKFDh8JutyM/P180f3a7HZWVlYIfQgghUY4eKmOaooFOSUkJACAjI0PwekZGBv9eSUkJzGYzWrdu7TdNenq6z/LT09MFabzX07p1a5jNZj6NtxkzZvBtfqxWK7Kzs0PYSgXRU4ZmMnAJ1xhOap0NQkikoGApYqnS68rgdQNnjPm85s07jVj6UNJ4euGFF2Cz2fifoqIiv3ki0WtbwlP42vIXJFWf1jorhBC10UNlTFM00MnMzAQAnxKV0tJSvvQlMzMTDocD5eXlftOcP3/eZ/llZWWCNN7rKS8vh9Pp9CnpaWSxWNCyZUvBD4ltLSsOap0FQojalCiNoWApYika6HTu3BmZmZlYv349/5rD4cCmTZtw8803AwD69OmD+Ph4QZri4mLs37+fTzNgwADYbDZs376dT7Nt2zbYbDZBmv3796O4uJhPs27dOlgsFvTp00fJzSKEEEJIhAq611V1dTWOHTvG/11YWIiCggKkpqaiQ4cOmDRpEqZPn46uXbuia9eumD59OpKSkjB69GgAgNVqxdixYzFlyhSkpaUhNTUVU6dORc+ePfleWN27d8ewYcMwbtw4zJs3DwAwfvx4jBgxAt26dQMADBkyBNdccw1ycnLw1ltv4dKlS5g6dSrGjRsXMSU1jNE0cYQQojoqjYlpQQc6O3fuxO23387/PXnyZADAmDFjsGjRIjz77LOoq6vDE088gfLycvTr1w/r1q1DSkoK/5lZs2bBZDJh1KhRqKurwx133IFFixbBaDTyaZYtW4aJEyfyvbNGjhwpGLvHaDTiq6++whNPPIFbbrkFiYmJGD16NN5+++3g94JGzpbXor3WmSCEkGinRNUVNUaOWEEHOoMGDQLz84UbDAZMmzYN06ZNk0yTkJCAOXPmYM6cOZJpUlNTsXTpUr956dChA9auXRswz3pVWm2nQIcQQghREc11RQghJLpJVV1RKU1MoECHEEJIdKOAJuy2nbiIcxV1WmcDQAhVV4QQQgghUvJPleOBD7cCAE6+MVzj3FCJDiGEkFhFJT2q2HnyktZZEKBAhxBCCCFRiwIdDdHDBCGEaIkuwrGAAh1CCFHZFa5ibDQ/g9HG77TOCiExhwIdDdFgnYTEhocr3kPnuPOYHr9A66wQEnMo0CFRz8lR8TTRlok5tM4CEUPtB2ICBTok6l2sppsMIaS5KCiKVBToaIgeJsKDox1NCCExiwIdQgghMYoegmIBBToaosbIhBBCiLoo0CEkClH7a0IIaUCBDiFR6OSFGq2zQIj+Ufu9mECBjoboHCNqqahzap0FQgjRBQp0CCGExCh62owFFOhoiBojE0IIIeqiQIcQQgghUYsCHUIIIbGJGkrGBAp0NETnGCGERAi6YEcsCnQIIYQQErUo0NEQNUbWBqMnM0IIAOp1FRso0CGEEEJI1KJAhxBCCCFRiwIdLVGpaVgYvHY01VwRQgDQxSBGUKCjITrFCCGEEHVRoEOiHgO1+iaEiKHHzVhAgY6G6PYbLszPX4QQQqIZBTpaokiHEEIIURUFOhqidnDhQhElIUQEXYRjAgU6JAZ497qiixshhMQKCnQIIYQEzc3RAwOJDBTokBhAVVeEKGnJ1lO49pVc7Dx5SeusNFMwwRoFdpFK8UDH5XLhpZdeQufOnZGYmIguXbrg1VdfBcdxfBrGGKZNm4asrCwkJiZi0KBBOHDggGA5drsdEyZMQJs2bZCcnIyRI0fizJkzgjTl5eXIycmB1WqF1WpFTk4OKioqlN4k1dBcV+FCva4IUdLLX+5HvZPD0ysKtM4KIQEpHuj84x//wAcffIC5c+fi0KFDePPNN/HWW29hzpw5fJo333wTM2fOxNy5c7Fjxw5kZmbizjvvRFVVFZ9m0qRJWLVqFVasWIHNmzejuroaI0aMgNvt5tOMHj0aBQUFyM3NRW5uLgoKCpCTk6P0JqmH7riEEEKIqkxKLzAvLw+/+c1vMHz4cABAp06d8Omnn2Lnzp0AGkpzZs+ejRdffBH33XcfAGDx4sXIyMjA8uXL8dhjj8Fms2HBggVYsmQJBg8eDABYunQpsrOzsWHDBgwdOhSHDh1Cbm4utm7din79+gEA5s+fjwEDBuDw4cPo1q2b0ptGIhYVnRFCRFDHhJigeInOrbfeiu+++w5HjhwBAOzZswebN2/G3XffDQAoLCxESUkJhgwZwn/GYrFg4MCB2LJlCwAgPz8fTqdTkCYrKws9evTg0+Tl5cFqtfJBDgD0798fVquVT+PNbrejsrJS8KMlOsXChea6IoSQWKV4ic5zzz0Hm82Gq6++GkajEW63G6+//jp+//vfAwBKSkoAABkZGYLPZWRk4NSpU3was9mM1q1b+6Rp/HxJSQnS09N91p+ens6n8TZjxgz87W9/a94GEkIIiRL01BMLFC/R+eyzz7B06VIsX74cu3btwuLFi/H2229j8eLFgnQGr5a4jDGf17x5pxFL7285L7zwAmw2G/9TVFQkd7NUQY2Rw8XrWKOLGyGExAzFS3T+/Oc/4/nnn8eDDz4IAOjZsydOnTqFGTNmYMyYMcjMzATQUCLTtm1b/nOlpaV8KU9mZiYcDgfKy8sFpTqlpaW4+eab+TTnz5/3WX9ZWZlPaVEji8UCi8WizIYqge63YUI7mhBCYpXiJTq1tbWIixMu1mg08t3LO3fujMzMTKxfv55/3+FwYNOmTXwQ06dPH8THxwvSFBcXY//+/XyaAQMGwGazYfv27Xyabdu2wWaz8Wn0jm6/hBCiIWqwFxMUL9G555578Prrr6NDhw649tprsXv3bsycOROPPvoogIbqpkmTJmH69Ono2rUrunbtiunTpyMpKQmjR48GAFitVowdOxZTpkxBWloaUlNTMXXqVPTs2ZPvhdW9e3cMGzYM48aNw7x58wAA48ePx4gRI6jHFfHiXU2qUTYIIYSEneKBzpw5c/Dyyy/jiSeeQGlpKbKysvDYY4/hr3/9K5/m2WefRV1dHZ544gmUl5ejX79+WLduHVJSUvg0s2bNgslkwqhRo1BXV4c77rgDixYtgtFo5NMsW7YMEydO5HtnjRw5EnPnzlV6k0jEo8iGEEJileKBTkpKCmbPno3Zs2dLpjEYDJg2bRqmTZsmmSYhIQFz5swRDDToLTU1FUuXLm1GbrVFjZEJIURLQTwEUVFwxKK5roi2LhwD5g0EDq1VcSUUURJCSKyiQIdoa9VjQHEB8NlDKq6EnsQIISRWUaCjJbr/AvUVWueAEBL1JC62VB0VEyjQ0RCdYtqgaxshhMQOCnQIIYREOWqnF8so0NEQnXoaoSIdQmIMnfOxjAIdLVGkowma64oQQmIHBToaooIFQggJB4mnSroIxwQKdEh4uF2Ay6F1Li6jixshsYXO+XDS22C4FOhoSGfHgnoYA969HninW0PAo4PsEEIIUYferrEU6BD1ueoBWxFQdwmoPKN1bvR3FhJCVCb1WBnMtYCuG5GKAh0txUyRDiGEEKINCnQ0FDMFCzrbUH3lhhBCiJoo0IkUF44Bp7ZonQsF6KEYi0IdQmILTQERy0xaZ4DINLdPw/9P7QTadNU2L0GjiwkhhBBtUIlOpCk9qHUOmkcH/Q4Zx2mdBUJIWCnRGJnIZXTXY4X573jcuFrrrACgEh1N6eCeHx7+iocvHgtfPgghMUpGQEPVWIq5uvi/6B93CP3jDgGYp3V2qERHUzF5XnlEd1XntcsGISQ2UUCjOhNXr3UWBCjQ0VDsnG4SW3rpeHizcRnNdUVIrKEpIGIZBTpEfZ4Xk5ipryOE6IecgIaCnmhFgY6GYvKWr4cnKD3kgRCiDTr/Yw4FOlqKmUhHXxcWus6RmJK/CFj6W8BRo3VONES9rmIZBToaipkbLlVdEaKdNU8DxzYA2z7QOicaol5XsYwCHRIGeruA6C0/hISBvUrrHOhEiOc/BUIRiwIdoj7BBUIHJTp0vSKEABS8xAgKdEjsoYsbIcQHXReiFQU6GoqZ5irURocQoheCBx0KbmIBBTpaiplzTF8bSgMGEkJI7KBAh6hPd1VFessPIWGgu/NQZ2j/RC0KdDQUO6eVx5bSxYQQoim6HsUaCnQiDKMTs9kYR/uQxCBqHxcAXReiFQU6GgrlsnOsLAJHN6XGf4QQQjRCgU6Eqap3ap2FEFBwQwjRCXrwijkU6GgoZk4xpq86cep1RWTTwfGqVwZwWmdBWfRdRy0KdEgY0AWERKDv/g7MuhaoLtU6J7ozyrgRBZbxuJY7rHVWQhDq9YiuY5FKlUDn7Nmz+MMf/oC0tDQkJSXh+uuvR35+Pv8+YwzTpk1DVlYWEhMTMWjQIBw4cECwDLvdjgkTJqBNmzZITk7GyJEjcebMGUGa8vJy5OTkwGq1wmq1IicnBxUVFWpskipipmkgFRXL56wDXA6tc0EA4Ke3gcqzwObZWudEd96Mnw+roRavOt7WOivNQ6U4MUHxQKe8vBy33HIL4uPj8c033+DgwYN455130KpVKz7Nm2++iZkzZ2Lu3LnYsWMHMjMzceedd6KqqmnSuUmTJmHVqlVYsWIFNm/ejOrqaowYMQJut5tPM3r0aBQUFCA3Nxe5ubkoKChATk6O0ptEmk1fFxPd9lxz2YHp7YB3rqILsK7QdyEtmh7X6HuOVialF/iPf/wD2dnZWLhwIf9ap06d+N8ZY5g9ezZefPFF3HfffQCAxYsXIyMjA8uXL8djjz0Gm82GBQsWYMmSJRg8eDAAYOnSpcjOzsaGDRswdOhQHDp0CLm5udi6dSv69esHAJg/fz4GDBiAw4cPo1u3bkpvmuJi5rTSWRsd3So/CTA3UFeudU4IiV5UwhxzFC/RWb16Nfr27Yv7778f6enp6N27N+bPn8+/X1hYiJKSEgwZMoR/zWKxYODAgdiyZQsAID8/H06nU5AmKysLPXr04NPk5eXBarXyQQ4A9O/fH1arlU/jzW63o7KyUvCjpWh6FvJPXxcTQyQEW5GQR0IIiQCKBzonTpzA+++/j65du+Lbb7/F448/jokTJ+KTTz4BAJSUlAAAMjIyBJ/LyMjg3yspKYHZbEbr1q39pklPT/dZf3p6Op/G24wZM/j2PFarFdnZ2c3bWCKPzp6gmJ+/9EOv+VIJY0CV+HlLSFjQw0XUUjzQ4TgON9xwA6ZPn47evXvjsccew7hx4/D+++8L0hm8RulkjPm85s07jVh6f8t54YUXYLPZ+J+ioiK5m6WKmDytdHEx0UMeiMCGV4B3ugE7P9Y6J9FLF+eeHlBVeqxRPNBp27YtrrnmGsFr3bt3x+nTpwEAmZmZAOBT6lJaWsqX8mRmZsLhcKC8vNxvmvPnz/usv6yszKe0qJHFYkHLli0FPyQcxC8mZdX2MOcjgsTaBfjnfzb8n/uCtvkgMSzGzrkYonigc8stt+DwYeHYCkeOHEHHjh0BAJ07d0ZmZibWr1/Pv+9wOLBp0ybcfPPNAIA+ffogPj5ekKa4uBj79+/n0wwYMAA2mw3bt2/n02zbtg02m41Po3eat9E59h3w5RNAvcptlSSqrsqqtAl0BG2jNcmBHPrNGYlQNNcViVGK97p65plncPPNN2P69OkYNWoUtm/fjg8//BAffvghgIbqpkmTJmH69Ono2rUrunbtiunTpyMpKQmjR48GAFitVowdOxZTpkxBWloaUlNTMXXqVPTs2ZPvhdW9e3cMGzYM48aNw7x58wAA48ePx4gRIyKix5UuLG3o9YYEKzBshoor0tlNO9ZKSwghTXTWZpCoT/FA58Ybb8SqVavwwgsv4NVXX0Xnzp0xe/ZsPPTQQ3yaZ599FnV1dXjiiSdQXl6Ofv36Yd26dUhJSeHTzJo1CyaTCaNGjUJdXR3uuOMOLFq0CEajkU+zbNkyTJw4ke+dNXLkSMydO1fpTVKNbk4xm8ptlah7efBoPxESXnTKRS3FAx0AGDFiBEaMGCH5vsFgwLRp0zBt2jTJNAkJCZgzZw7mzJkjmSY1NRVLly5tTlYJEHM3Vc+5rvS75frNGYlQMXaeK452X8Siua40FDM15rq7wOotP4SQ8KES5lhDgQ4JQyNFupgEjS7AJAJxXCQft5Gcd/3Sw5Q7FOhoSPuv/zK1D0S9tdHhdJYfUXrNFyHi3vr2F9z4+gYU2+q0zkoQ6DyLBRToaChmqq6gbS8HA13MCFG95PZfG4/jYo0D7353VNX1NJtuH26ikx52NwU6hOiRHq4OhIQkQh/h6JyLWhToaChmTiuNq66Y14WXRcSej4Q8EhLhKLhRnR72MAU6kSDiT0Zt809VV4QgCq4jwXO4OMz45hBOXqzxeDX29kOso0BHQxFawBs83Y1Eqoc8BBCDNyWirvOV9WFZj55mmli0pRDzNp3A4i0nZaSmcy5aUaATCSL+pqdt/n2qriKh0xVddInCTlys1ToLYVd4QWSb9XvSRyXqXh7jtP/6w0TjyIKqrgiJVfLPfVudQ8V8EC1RoBMRIv1GrbP86+AJI6BIyCMhInRUcxWU87ZAVXt0ToZCD3uNAh0Nyb4gRPpNT+M2Ot5VV5550O+e1W/OSGSK1ACkecS2OiLqromCKNAhYaC3XlfMz3tEU3TjIZqhYy9aUaCjIfmnVYSfgJHR+ldfaD+RCKWnXleBr510nqnC4yDQw6XMpHUGSKzRvuoqMuIu3WZMXfq6S5IIl+CqwmfmV9EK1U0vhnjSO90c4hXKV9TT2YWVAh0NxUobHcaaQg2OY2EvRvSpnmKSfxCtRfixrmfh2rN6+gpvL/0E/eJ+kZc4QMbtLgp0QqGHkeip6oqorsbh5H+/UG3XMCcNtD/tZNDT3YJEBTXKysJxlDLGsGzbKew6XR70Zy1cgLGD6DyLCVSio6GwtNHZ8VHDyXzTuNCX0Ux2pxstLv+eYAp/bO2v1xVd6HSGqq4iiti3pfRX+MPhMry4aj8A4OQbwxVYIp3zsYYCHQ2pfkm3VwFfTWn4vefvgMTWaq9RPBtOt8dfNGAgiTAUDGvqWGl14ESKoO9ZDXo4fajqKgIwxoX2QXdTlRFc2lUZeQY6OjjmdTEkeUCRkEcSUWLxkAr8kBODOyUGUaCjIbmnGONUPhlVvgLaXS6PVYUYtDWD36or3V7o9JqvGETVaUEx6Hxowi93n9U6C9FPZ+cMBTrRTCePcA5B1VX4UdUVIbq792jmldUH+N8jonSXNBsFOhqSe91RvXueylfAes+qKx1cVzxLyHR7odNrvgiJKnSeqU0PlzIKdKKZ3ABG5SPRM9DR4rriW3WlUxrPCUaiW/9zn4RlPfoqOfI9jzxLeD1POUOA6yCVDAdBD9GNBwp0NCS/jU7427UoifPIP0P4t4UuUISoI9LPLN2W6BJFUaATASL9VGQ6m3PBoNtxdPSaL0LE6arwJgQU6KiPRkaOcfIvEpHdRkfrmzZVXREiVFpVj6VbT6Ha7gqcOKL5nvvSJbx0zkUrGjAwAoQcJ8j9oMqBCBPUiTf9HqhOXCm+c13RBY3EttHzt+FYaTV2nSrHzAeuD3k5kX4m6aG0ISrpbPZyKtHRkOw2OhqMPaMkz4BGDwe9cE5PHWSIR1VXJDwaRxtef/B8s5aj+7LSQOcRnWYxgQIdDaledSWzSsrhVnecG+FTEyd4h3igqitCVOd5VRRem+ici1YU6EQAtauujqo9l4zOSnQ8M0E9sggJndjZo6tSHl1lJjbp4QpLgY6GZB8AIR8p8j7odIVziglNBtLx+pNJvaUxqrrStTP5wMpxgC3ypxC4JW4fvjD/FVfitNZZCTupcXRI9KLGyNFMJ2exZwNk/baP0QGtA0Li30e/bvi/ugQYs0bbvDTTMvMMAMC77C0A47TNjIqC6vBA1yPlCErxtd+vVKKjIdlTQIRedxXi55TFdFdSQVVXpBkuHtc6B4pphcpmfV7sGmbQ19DIfunhJkzUp3qgM2PGDBgMBkyaNIl/jTGGadOmISsrC4mJiRg0aBAOHDgg+JzdbseECRPQpk0bJCcnY+TIkThz5owgTXl5OXJycmC1WmG1WpGTk4OKigq1N0kdap9wWp7QnnEOp32phc7GL/Sg24yRKBUJY0wFiptOllWjziG/Q8V401qJdwKdc3ROyubZvVzDbDRSNdDZsWMHPvzwQ/Tq1Uvw+ptvvomZM2di7ty52LFjBzIzM3HnnXeiqqqKTzNp0iSsWrUKK1aswObNm1FdXY0RI0bA7dFDaPTo0SgoKEBubi5yc3NRUFCAnJwcNTdJUap3L9dNVYjGh7r3hZJJ/qEjes0XIU3CcZT6i/n3/HIE8XN74fO3Hpe9vMdMX3ksO7KH7ogIOnhoUy3Qqa6uxkMPPYT58+ejdevW/OuMMcyePRsvvvgi7rvvPvTo0QOLFy9GbW0tli9fDgCw2WxYsGAB3nnnHQwePBi9e/fG0qVLsW/fPmzYsAEAcOjQIeTm5uKjjz7CgAEDMGDAAMyfPx9r167F4cOH1dqsCCOvhED96huJAQPpZi6kgwsCIcHQujyoduNMtDNcxBjn56EtgE65mKBaoPPkk09i+PDhGDx4sOD1wsJClJSUYMiQIfxrFosFAwcOxJYtWwAA+fn5cDqdgjRZWVno0aMHnyYvLw9WqxX9+vXj0/Tv3x9Wq5VP481ut6OyslLwoyXV2+jopURH6qmJbuxeqOqKqCzKjitDM0tkPPcGPXipQw/toFTpdbVixQrs2rULO3bs8HmvpKQEAJCRkSF4PSMjA6dOneLTmM1mQUlQY5rGz5eUlCA9Pd1n+enp6XwabzNmzMDf/va34DcoHBiTrIxWuzGy6oehYAUaFBX7bKBOAkC/9JovEtH8XGdCWpxiS9JK5G8BCUzxEp2ioiI8/fTTWLp0KRISEiTTebfMZ4wFbK3vnUYsvb/lvPDCC7DZbPxPUVGR3/WpTf0AQyclBJIDBtJFRkAHTz4kMC6iv6fIy7uanbiCeYjUupouonjuV077Y07xQCc/Px+lpaXo06cPTCYTTCYTNm3ahHfffRcmk4kvyfEudSktLeXfy8zMhMPhQHl5ud8058/7ztNSVlbmU1rUyGKxoGXLloIfLck+cRRpMKfdwebZ4E8Pk+gJGiDq6qalk8CU+FVR59Q6C6GLwONKzSzTc1dsUDzQueOOO7Bv3z4UFBTwP3379sVDDz2EgoICdOnSBZmZmVi/fj3/GYfDgU2bNuHmm28GAPTp0wfx8fGCNMXFxdi/fz+fZsCAAbDZbNi+fTufZtu2bbDZbHyayCJ9loV+/unlxilRohOBF93woX2jVy6XunPDkTCia5A6DMIZxbSmeBudlJQU9OjRQ/BacnIy0tLS+NcnTZqE6dOno2vXrujatSumT5+OpKQkjB49GgBgtVoxduxYTJkyBWlpaUhNTcXUqVPRs2dPvnFz9+7dMWzYMIwbNw7z5s0DAIwfPx4jRoxAt27dlN4sVcj/+iO9MbLn7xrkwwA9nGuBRUIeCdJxCSg/BbTuqHVWQkAHmSfaG03OV9bjwQ+34qF+HfDHX3VRbLl66MKvycjIzz77LCZNmoQnnngCffv2xdmzZ7Fu3TqkpKTwaWbNmoV7770Xo0aNwi233IKkpCSsWbMGRqORT7Ns2TL07NkTQ4YMwZAhQ9CrVy8sWbJEi01SVeixgT5OY8lcaPQ0JZiSQldPdHopgSMBffYHrXMQmjAcV2q0qbk5bj/aG0qVXzDVXfHeWXcYhRdq8NpXh7TOiuLCMtfVDz/8IPjbYDBg2rRpmDZtmuRnEhISMGfOHMyZM0cyTWpqKpYuXapQLsNPfhsdj7FnQp27RdPGyB5tdKTmvSIEgN3F4e2vDuLF4ddonRX/yn7ROgchYYyLuEa1GbYCLDdPv/zX/ym7cB2UNuiBm2Ood6qzL/TwMElzXekFY3C6pcabCXmhshYSzgEDBd3Lw3UC+OlerquxM3RwQdAaYwzzfyrUOhtRLPKOsQzbXq2zoBs7Tl7Cb9/fgv1nbYotk+MYBs/chNV7zim2TL2hQEdDnpecVbvPoOuL32DtXt+DjSkx9gx1LxfNg74u+zopgdNQgsGJEXF5WmcjoEj9dpgOuvoGqzk5DvQgE2mdI+7/IA/5p8qRs2CbYsssrbKj8EI1VDuqdbBfKdDRian/aXhqeWr5bt83Q21ULPMAU3tiPyZRgqKHrub6FUX7ZtObwOqJso/HuWbp6mq9cLkj8/uRlWtHDXAqD+ACP2B5Xjl+b/wOn5lfRaKrSjJ9c/1paT72nqlQbHmR+S0C5bUKDnHAGP5t/hs+jX8dauwRPexjCnQ0JH8KiFDXIO+DalffCIMbDxpF+p75CarNk9r0lBclbXwd2LUYKImeKgg99CQJhax8L7kPWDgM2D4vqGXPiF+AfnG/4Fcli0LLnATP6+Q3+0swcu7PzV5mY7sRmnsPiKspwY1xRzDAeBAtUavMQvXS4/cyCnR0wt9J5lnysfXEBTy5fBfscsby0E1jZI9ARxdF5zprEH3pBFDvVecejUGPs17rHMQ8WQ1Di7Y2/L/rk8DLE3kt3l0XXKY00LQbovA8awY1SveZjJJBtVGgo6FQTrEDZyvx1d5irNge7PQVWo6MLPVGWLPhsV4dPW1cOAa82xt4+yqvvOj4AuyO4JGBY1xQPWBCDbbVnLNBITo+u6KDzo4BCnQ0FMrs5Y0lPzY5w9DrsUSHupcLFf7Q8L+rPjJKcf77FDA9C7CdCf6zOrv4xaJwVLkpXSrQnLNC6pRqqrryfE37kodopIe2mBToxAwtDzapbvPa97rSwTkoTq9Bz+4lgNsBbP9Q3fUc3QCsmQQ49V8NEkmCG9NEPO0Xu0IIcnVKkR6tRPfCMmAgCczvM5CgRCcY+ijREfbg1FeUoXkDRMn9IZ4vxhj+tHQX4k1xmPP73vLXoXRpitrH07LfNvzfMgvo/QegRQYQZ/T/mbCKzdKpOocbkz/fg/sS/KVSdt+osafFjl7tr0bRQ2/d9qlER0Nyv/6QjxMdHGCAd88m8VGSCWR9X+cr7cg9UII1e86h2u4KQ6bEucPVwHDXEmBmd2D5KBTb6uQ1wieSmls743AFXgDTURWlVFb4U01fz10yRUxGAegjtxToaEj+5SDUs1EfZ7FwbinBO2HPS0MeImAsH4mgh9NJcHjwXKW8hM1tJ2Y73fD/sQ0YMON73DNnc/DLiBa2sw1j21SXNfSIctQEvYhwVNUwhW8rzQqcJI65xvM+4LXgXEHo61bBsLjtKLCMx61x+1RZviol3Dq4ZlGgoxN+u5d7PIYFdSDqsDFyKMHNv3cWIXd/sXL50S2VAtMgv/uiS7V4cu4XWL9fekj4WofM0iSFj7sj56sVXV7EOLgamHUNsHIssGg4sHoCkPt88MvRwU0naFrde91O4MOByq+8GT4wz0YrQw2WmmeotAY1jg/tjzkKdDSk/tcv98apdk7ES3TkVF2dq6jDn/+zF48v3aVGxvRFJzehLz+ZjX9d+D84PhvjJ5XsilcZSfSx3br209sN/x/4ArhwuOH3Q2sCf85r3/qec35KS0L+XvRTdSWpcdv8TZjsir1xnyLgmwsJBTqRINTGyLop0Wn6NdiRiCuUHOq8kV72iz8y8qVWG6cRlSsAAMON25u/sEB53Pkx8M7Vshb1smkJBsbtaX6eYknAQEeFVSrdRkeVuy/z+Bc+v4tnQ6fXiuZSYXRoaoxMeLLH0VE1F+rzbBfgddkNbjk6OGHUpY82VbIudrK/iwDp1j4DVJfIWtJY0zdYbP6HzPUqp7zGHvZ1qqW5bdLkfV7/5QKNI7Tr7YasBc/vNE6VekLlFxksCnR0wv/NJdSIW383TkGwEmSWlLsOhdpdX2VBbqD81BrWu0fBzePwefUmqVSf1/5XYBydgJ/SUa8ryWEaLj986bYzQhh5HhLKlVrp497TiAIdDYXSvdxo4JAid+I1vVTRSK46uDwp1eOISQVeeiKr6kqlVau0tMi9qWh/43YrNEec9/Ee7FLlHXMKj6OjwoEuNudepB6dzeXZ2eWV+E8wIO6AsstXdGmhoUAnEngciG/Hz8O+hD/CWidndFLto+r8L+cg5eS3TblgntVYapVgRKrA35fnw7JaQZqiVVce3/eJsuC7Q5MGxbYQq8+8v6dmBkxSn9btA4ME/trj72EwwrYpVJ7f3UhjHj41v670CpRdXggo0NFQc557rirLDZxI4xKd4lOH0afgJdzi3CKeINiqGsVKVeUHgG6O4Y+Ld+CddYcVWrly5DeTUf67l33seqzb6db+gqec8G5LnVOZgRKbO46OVEAjrJHWvgQskMYZtf0HaNF0vPqhRomZuosPGgU6ESD0pyVtS3SqL50XeTW4NjqeJRjKVV3J9+PRMmw4VIo53x9TZN1+BRmYann90LZ9EJHPq6pKpRIdoQgIdESGiPbZNj3cocNA/c3Ufj9SoKMhz6/fBDd6GE4gLoommRML0HRRxB1EHuzOcH4fgQPTYMchCoWityk9fN+xrDltckS+O6mHDcGRq6vGyFJEtsM7+ImV2cxV307trwEU6GjI83IwzbQYay0v4QXTcp90IR8mMksI1BofgnEBituDvAmqM/2B9idhMDxzK//hXIVtVKp7ebTjOGDh3ehp3611TgAoEBxLfFy4XP0HOk3dyz0by8u35fgF/G3NAdQrVKWoJbUfPvXQCYFmL9eJ+00/AgDGmb72eY+FPIGitlVXomsM8cLi9dHm0b6NtjgZgSljDHfFbYMbcWC4Q62MBEwhOzjW2Wz1sil1sJXsAU79rMyyQuK9HcFsl/yeSYLXI6FER3RWT6k0vkbP3wYAaNPCgidvv1LBjIWf6oGIDkp1KdDRkPpVo/Law6jWeDDQAR5kkaly+0v7E0+cjKCg3ob3zf8EAJQ6JwFIUDtTEuTtQ8a4CHi+V5EC1QIXqu2odXLKlL8386Yj9fGIa4zMfEt0fDcu8L46fVHmUB86FvqDtL+Fevyqg8stVV1FApUbI6s3tLmybXT0MnN3WEhsapyjaVJL5tZmYs1gROx3pqN8P7+yGTNVKzwFhHQbHfWqrprT5kfqk7L2g1eaqJ0CQuV2oXrYbxToaEj15x6Njy/RxsiC34PLoFL3Hj1VphRd8hhbJshrr1jPESUoOY6OsJeP1ns7Mh0qrmzGp70DHfnHjDvA+Stcrmca/ZfoNG6J4Oj02jh3oDaGiIxaukCa2xNPdJmKL7F5KNCJCAocNlo8oYqt0/NCG2SWlGs017QcNUZdDUaxzXOG5MBBgecTtY4KHSTpoSFiaCI138q5VO3weU3WOaiju7/k8ddYdeUnEK93yiwxjXgqN0bWwYWKAh0Nye63Enq3K1lrU+sJLFCJTvDLa8aHA6kuA+oqVFyBOMlNktONV+nMBEFucTQneCrWzw0wIB1cnJXgXYITzE3H7vIt0YieNjoiJVs+TXRkNMrX/6YGpH4gov25RI2RI0GoB6LG3ctFG2IKVqVNY2ThUxwH1FcCb1/uOTHNptBaQiBrfqumNJxUI8J6G7rW7fX8VDMzFjqqutIWY8Lwsrk3NelAx+NY1NHd3yARdIk/hDWnh1oEU3nYDj08M1CJjobkXg5CL/7X9iYjukaZPcHEqNaw9dJxdZYrg7DqLPD3xfz8xfvwdqRwoQds8qrzZJdHhvAZjVw8Dnz3d6D2EnSfV5l8buhBteuSEww0Llavg+tJ5Fes15V3Wp/GyGL0E9SFSvUSHR1EOlSiEwFCPhA1nutKbJ0syBufEm1SIvJSJPno7PG71M3FK3BjTIXKhBAaI2vdHiqgD28H7Dag7Bfgdwu1zo0qgrqWiDWxY8CdcTtFXvecrFf/Z1xTfv1U6XudX3roPaSG5s5/Jr5Qfe0rKtHRkNxDIfQTTNuDTbwe3CNwkbUMz9+V2R7B/gyhXl5JgrUFO1K07KdoDauuBMeAvi5+PuyXS8FO52mbDxEhXwG82+g0NyOuOsw3zxRZUWQFOnxjZD/PgrFSlaVGryvB8nUQ9FCgoyH5VVdK8PPkovBxyBiD080FXPAX+WeCW26o+QkqsfInJWMMb337C/4T1PaK50MYNsgsVdHwOhNsCZ4sC4c3VDGpSvuLsxK8bzLB3HREH7Cc9b6vAWCcZw8l/Qc6TcelvxIdOVVXkU+dQERf5w8FOpEg9Mc58d9V9tTy3bjh1fWorvftnul5UtnqnAGXpU7Vlb96eelSklAvCLtOV+BfG49j6r/3BEgZ+PsSXHxljPPhj8OlfrsKQfG/Uofgqc3AT28rtDAJOngKVYJvE53mbZfUxwVVV6o2RlaoVFfWgIGBq65kbWpdObDsfmDff2TmDqh3ulF0KUyjLsdArysKdCJA6BG3vKdppS9LX+0rRpXdhbzjZX7TyamS89x0pRoj+1+M9Juh3iNsdb7jkYivOnDg4VmfLvu4EEl38FwlrnrpG8z45pDPe/KqSuUFScJ9pv0FTymR83TvXSrh3Zw92C0R/97Vrv5opFQ7mcZTQjgFhHDbvKuGJdftCnB+//AP4Og6YOVY2fm7c9Ym/OrNjdh/Nhy9QFX47rRuH+pF8UBnxowZuPHGG5GSkoL09HTce++9OHz4sCANYwzTpk1DVlYWEhMTMWjQIBw4cECQxm63Y8KECWjTpg2Sk5MxcuRInDkjLPovLy9HTk4OrFYrrFYrcnJyUFFRofQmqUZ+v5XIbIwsfiNuem206fvAy5D4Pah8BJVY+RKd0NYtsS7OM9CRV6IjtqS3vv0FADBv0wnhGxWnZd1MDLIPXs/GyHrtmSNG+4uzEprTzsQz5YVqO+ocbunLiCAoUO/5WakAU6z9oG9zvcCBTmbdMeC1K4BvX5ReWe2FoPNXdKkOAPDN/uKgPxss1XvM6eBUUvyI3LRpE5588kls3boV69evh8vlwpAhQ1BT0zTU/ZtvvomZM2di7ty52LFjBzIzM3HnnXeiqqqKTzNp0iSsWrUKK1aswObNm1FdXY0RI0bA7W66uI8ePRoFBQXIzc1Fbm4uCgoKkJOTo/QmqUb9p0KZbTjCuH7PC2W/uF8CL0EwbkxoOfXez4ILmIzut8mogwku9c9XGYGp5/5Q/Cl66/vA7J5ox0pkJJbbPiiCGiPrWmhXC+/DOZRj5pO8k+j72gb0/vs6PwNcNl2XG6uuKuud+PZAiejAg95W7T6D5/6zFy63/5uuciU6lxsjB9F2MU4k7e3n5jf8kjdXkXxpQ+02Otqf94p3L8/NzRX8vXDhQqSnpyM/Px+33XYbGGOYPXs2XnzxRdx3330AgMWLFyMjIwPLly/HY489BpvNhgULFmDJkiUYPHgwAGDp0qXIzs7Ghg0bMHToUBw6dAi5ubnYunUr+vXrBwCYP38+BgwYgMOHD6Nbt25Kb5p2lOheHsaqK365ok/wwW2L+iXi3oGO8O94RwUOJIxFIZcBjo1Qd/1yqq644AMH2SVR3/5FXrog+J8dWsd0lNd45sT1cWJjPck5c72rquQ/vTcGFdvWLMDfTQcxzTlGelJPwXHZkK9HF+7AzlPlGHtrZ7w84hq/63rms4b2azd2TsXv+rQPmKfm4gMcwSXSu+F24H1VYqtHT6MiWRIlNeChklSpdtTP6QMgDG10bLaGOsbU1FQAQGFhIUpKSjBkyBA+jcViwcCBA7FlyxYAQH5+PpxOpyBNVlYWevTowafJy8uD1WrlgxwA6N+/P6xWK5/Gm91uR2VlpeBHS6EVIjcI+vDX4MLNiRUPB50PjxKdELfB+1PeF0unWzrYaF22AwDQOe58GNrsyQliPEt0tOxeLjPIEjSY1tnVzy8VyzmDPJD+6PpUakkhrDvoj+Bf5neRY9qA/zVu9hm7qbH0RqwadeepcgAIqrdheY3/9i6yr3v1NuBUnnR16eXt8Dd+qZzvKZKOaClqz0enyjg9QVI10GGMYfLkybj11lvRo0cPAEBJSUOxeEZGhiBtRkYG/15JSQnMZjNat27tN016errPOtPT0/k03mbMmMG357FarcjOzm7eBoZLyHNGaVt8KH4jDi4fShQI+FZdCf8+edFzBnEtT0oZVVeCNjoK51WlrvVqLl8r4dySwe7NIX/W92ldfs69z5vRxu98B9HjJ8dsej2UUpfBcfl43vQpvtl3FltPXJTMSZzcm+b8O4CFw3CDbb1EApE8epfoaDjac2tUopchTCO2B3sdObsL+CwHuHRC/H23C7eefq/5+VKQqoHOU089hb179+LTT32fSAxe/fIYYz6vefNOI5be33JeeOEF2Gw2/qeoqEjOZqhG9jg6EToyclyAAQPl4BjQx3AY1xpOqlMuwQCv2YD85EXkPZcD+GgwkPuCUpkJwCPQkXkhllqq7JuG6ELlfRuepXqREuc4XG5gwzRlFqbiNsupcfB+Wg+mmsI75Q1xxwBItLfxUxoppwv2R+Z38LhpDdqdzcWDH24NmP5cRR1Gzt2MY6XV4gkuHvX7+aY2Ov46HwQ+P9SqWNpqmYDVlpfRrnK3SmtoEvT9Zf7twKHVwIo/iL+/+xPh8sPUI88f1QKdCRMmYPXq1di4cSPat2+qc83MzAQAn1KX0tJSvpQnMzMTDocD5eXlftOcP3/eZ71lZWU+pUWNLBYLWrZsKfiJbtoeYEo8ERnrLmCl5W/4yvIXxaquPDU8fcqrDhJd/eGvgTM7gK3STzCysy2j6kpQoiM3UBHJQJbjFPZbxuJp40qZmQuNZ+8s1sxxf8LF7KgAtn+o0NL8N8hvjlqH7zhVgdbf3GoK75sWX3XlWaLj09ZF/vIzDOV+328sLXp1zUHsPWNrCEpDwfcv95NEw+unxdAwxljnijCM0h3qASk1R2D5yZCzohbFAx3GGJ566il88cUX+P7779G5c2fB+507d0ZmZibWr28qUnQ4HNi0aRNuvvlmAECfPn0QHx8vSFNcXIz9+/fzaQYMGACbzYbt27fzabZt2wabzcan0TvZ978QTzjPC2FlfeDB+ZQmVm8f7NNDfG1p02eV6nXl531/0yqIrp2Tc7ORyV9vMP5lj9dl7g+xRY2q+BBJBjueiVc30PE7aWIsULEYyykjzvVZfbPnuvIqreFLRsLTFqsx0Km2iwxGGsSDldhuaE7pl1rCM52G6o0PVV5+YIr3unryySexfPly/Pe//0VKSgpfcmO1WpGYmAiDwYBJkyZh+vTp6Nq1K7p27Yrp06cjKSkJo0eP5tOOHTsWU6ZMQVpaGlJTUzF16lT07NmT74XVvXt3DBs2DOPGjcO8efMAAOPHj8eIESMipseV7EM4xOPE7dFVkwvQbTMoznogPiFgMiXGTRGMjByoRKBgOfDDG8Doz4H0q6XTed98PcrWOcZBqhNFqCVKBgPw67hdKGWt/FfRyul1JagKUvoCEkz7DbkDBqqZ30ig/k3f79plDJ8QFKmxmzzPTRWPS3/XzKAmr23cDr+TXcXG8RrqeelmTPJaKVxBSItXlOIlOu+//z5sNhsGDRqEtm3b8j+fffYZn+bZZ5/FpEmT8MQTT6Bv3744e/Ys1q1bh5SUFD7NrFmzcO+992LUqFG45ZZbkJSUhDVr1sBobNq1y5YtQ8+ePTFkyBAMGTIEvXr1wpIlS5TeJO0pcqAodLTtWgK8ngHs/TzwGsUuikGfVE2XLv4mX34SWP8KUOXV6PzLPwEVp4D/PilcZeCM8r9yfoKpUK97SZUn8LH5bay1vORTCCOMuWT0uhJcmOUOGKjG7MQyk0VFY+Rm5FvGwHSq8p7Us5lzXUmVmhgEB7Z31ZVyW+wvuAtmPU1tdKT5uxaETxhKdEL8fpxhmEJGKYqX6Mg52AwGA6ZNm4Zp06ZJpklISMCcOXMwZ84cyTSpqalYunRpKNmMKLoaGXn1Uw3/fzEO6DXKb1KxEp1gcyFI33jhWTgcqDwDnN4KjP3W5zNORz3iPfPhs0zpnih+i79FMl/vdCNQ2VZC1Sn+d44xGD1yJJxJXcb35VlComGvENk9a6Ig0CmvdeBfG4/hycBJfel8m4OvGpGoUvUIppUY60ZQ8umxuIFxe7CRu17iM8FUXTW20fF3vuv7u1OK4r03w7x8OWiuKw2F3v9Bbpwvr32EUoNw+axdkV5XnqUtl5dXeXlcjiLx3hnFtjq/yzR43Xw9/xYb+0csL432nwtuLhp/1V9yLgiCkZEj4ELMqdkdPkzOVdjx1reHAycUo8A5ILnoy1eB85X1kseCT7uTZp7r3m3YxBojK7F9UuPbvGd+F3PjxR9+gzsffEt0vD8up6pa/2dgYJL7rfYSsHkWUHkuvBlSAQU6GpLfvVzkNRmfk9umxFbnDHl6BWnMZ3Cxy68GvRiezKJkwQCActYps5Qk1MDCs0mOv0XIarjLgg8c1IiHQgnSFQ/MIiDQE9tTSu6HT/JOot/07/D2OvFAzGdVQcWaYlVXwnOQf0iQWY0ql6Btnlc27jDuFu2yHtR+lTFqu5a9rniqzgR/mdR++2JcwzALn/xG9G3Z9y8d7EcKdCKBjBOY4xjmfHcUW441TSAnt+Gqw83w+U7lxhT6m2khfjBPRiJX4/tmkBd55tlQOMQeTv6qrphX93K/va5CLJHw297R83fP7ZMxYKDsfanUjdVjOd5diCX5abuhZH50S4FpUKQYwDDrv3l40vglvti4XTyRd3fwZrbXkurUIDwuleiE4P990Ye/EKquhM8W3kU6emijoz7J/XZsQ8P/F46ELzMqoUBHQ82puvK2Zu85vLP+CEZ/tK3pUx5XC58qGc+bFhi+2H1Wdm4CGWNaj05x5zHY4Ts7ebCXeC6Um2uQDIISHen2O/6CILn8lrLJqbqS255IDSF0FedCKIGSnx8t2yjJpHIwNjv+Pfw5/nMsN78mMzvNrLpyCx82mqaAUPa7CKWHY3CNkb1/ad7y1KPfxsi6Wb4MFOhEADlFfycv1CIZdYJuv8KbYqBHpJCzJylOZBTVoIMVz9KQEJ+wgqlp916HsDSm+Rfzwgs1WLL1lOiMzpxYIHEmv6HouGR/YyLPTzQ7P8HwNxP57qOn8M9/voGDp4q9PqNiY+SIaPOjbtXVQONeAA1zsYmvXfoBBwBaG6qCWp93qSp/PnucNz4DBga1hsufkWijI/tDAdNyPsv2ecTRwTg64aHuduohYKRAR0Oy6zhlnHAt6s/hQMJYLImfwb/m2e6m8WA7VlqNJ5ftwqHi4BrRhsIoWm/v5+Yk1mXdYxmi3dVl8J3rSnjzFZR8+Ql0xNocyVq/RwZGzNmMl7/cjw83icwTIyj+v/z/R78GTvwALLn38sue+0PeBUQsXSilY/7WV/nJH/B0+QycWjjW60PqjaMT6vEQVooEYxLVmDKuID4jGYst69xu2Tnh3OIDj/oLgkMhGvQHEFwbHb5IR+S1xnck9rvUes7slL9+mcIRIsjabwdWAYvvAarEA2q9o0AnSlxTuhYAcKvxAP+aoIfO5VPm4QXb8NW+Ytz/gXCGd6UajHmuU2wuJb/n1BfjGmYd9kzvGaypVVXjccP0LTL3U/3nsxypC2PT740lbttPXvJ50+/21ZQ1fN5zYWFuQ+Cv6q6xZOEu/Cz8jCC/yn5/unniZkz6wFbxaTaU3pKi+0xiyH7R5UtUXQl7MjZ8z0a4cbXhNEK5XftrjCwlqDY6jb2u/NYkBz6fBT66A7DJn6ldjnCMiyxrB//7EaDwR2Ddi0EvXu7gomqiQEdDSrbREUvieeI3lu6cs9UDAGodTTfJq+LOyDrYz1fWB0zDCW7qIVzkt38IlHk0flOgRMc7F75z8UjfjAV/BVq/jH0Ydzk3TaMjSz25SlxkueBvAKLLCaE3R2hVd77BtlJ0MaAb5wY+HAgs+V/x90W+pOBLtkK/3fkbM6pp8fJvA0yqRIfzLdF5O/4D5Fqexxiskb38l+KX4XXTAsQd+m/DZLnlpwJ/qHGtzSzR8f681PWGYwwWONDBIFK6cTFMM44rKKj9Vus9s3xkoEBHQ82J1uV8VqzqqunzTX+3M1zEzXWbAi6v3/TvAq+zOSU6APD9a8C/bvRI77GMEG9s/vaVAcwrIPRu0+Dxa8B2ToEDgcZAJ+5ypgyCJ1cZc115tsGSOzKyUuO2yGwYLujB5+cYbC4lGoc3W9lhoHgPcGKj6Hd2odr/mE5q81NA6UHqDBEJ0qR6PrKm1xuvLf9rbCjdG4dV/jPp5SHTd0j+79iGyXK/miL7gSmUkZEDjPcg+jLHgJXmafjR8gz6xnl16w9Hd3DFqVwySm10iCxipTVyXpG6icK3tGVo3VchZk5IEOiI3IiDLuUR3Px9l7fpSBn+tuYAHM0YjpzJ7BkUsARBVqDTkKbxcui5P0x7VwT8PBQemC0Yckt0nv3PXv53QdVVhAY6/o9Z/1WJlbUO308o1Iha3qjG3qUUIusO4ubs3euKf12sfVnj4mUvXUR9hezjJpQBA0NZHscYesSdBACkGqr9L6SZxygzGIDKYmD+HcAeGdeHUNah8nVEB3GO8lNAEOXJKvIXLSIP/4SKnqsR63XVVDcuc/B5j5uHWBuWMR83jB/SvnUSxvq8K5lLYY44zxIdYZ6Fk4r6v2gx5hbdJuE+aVhGXGO3XI+8GMsOeH5KIufBt1lSbhidwFVrPp+Bb5WGUvjtrzjdMIt8ahdFly9HZb0TLfn8uGAw6uyS6jNwk9h3IH4mih7LcgId7+85UEFogGuB3CrP0Oa6kg7EJUeblrua4j1gi0fCUF8hO1+i1r0EnN0JrFK+sTMAWQ9ochVdqkW6i4NFsSUqg0p0NCT7tAzxTiWcPsG76ir43LxuWhAwjWdWTSKBTmMC2e1IZVZdnSmvlbe8qhLEV3mMGcS8AgY/+zrQbOxSJQyer3q30ZGsApJ6XbCOMHcv9/jSZDcwFJQq+m5TKVqHnB+Oczc0jp3dE3i3N+CQeQwo6FK1XZgfL2pNryJ32WKHUY3dK1jxU6Lj851JVF15Dsvgmy//+Qx4eVOhRIc/lgUfkRfo+B8Ly+O9b55rfpADg08HDcUp0o4MyD91Cb96cyMW/nxSuKxQ86UgCnQ0JHV5+dljdGMAMk90sfp0eW105HrIFFwbHZNIVRMTSeeXv/YzoXinG/7nx4nCVQgCwsvr4NzAupeRUdLUdilQryu3WyIQE5ToNAY6DX8HX5UXfFWQYj3qIBIQ1tuAo+ulP+P5nYl8f3HNyBvHOMDdFGig9oJ0YrV4ZN/tEgkCxCa2DWNZvvc4OgwMH/7oPbSB+JWIMd8HJKkpIDg/DwuBjvFA53VIE8gGxPl8xCc889MYWRZjfOA0InyPD7WPF9/9L/UgWlEr3hgdAFYXSMyJpYO6Kwp0dOghj9GNAZmHuVg7ngBP054CXUzkXpwFgQ7ELvzMJ53f9XpeWP2U6IR+LjHBDZiv7tv7ObDlXXQu+sIjL5dXUrAc2Pq+z5Kk2vAIGvHyVVce65fKl+ir2k2S6Rk48wHKkvuAZb+T/kyA6q7mtN9gbi4sF1F/54ZnECn6/Wt9kfepueJQWmUXvihRomOAb2ADiV5Xwm0PbpsDPsDIXJzl57eAqhKZa2Ve/4ukkCrRkVscbU6RmZcGJy/U4I1vfkGpjN6tShLbTKltP+2n5Lxzm2SY4BIp7dU+0NFZhTIBgAeN3wMYjre+/QUA8Js2/g8Uu8uNHacuYoDXtynWGLmjoQQTTF/iY9ewoPLEMcAo8npN3scwJKQgqff9DevxeE+06qqxjY7ci0WAxsjNxgLMkC7IyuX1f/mnhv+vGub1fuA6faNXGx3J+nEZVVrhHnFUONDi5XyfDdBuIEB+mzPGBse51TkmgtK0TWIlOqLbp1QvuBAaI4MBRp/HW+nl+AQhUlNA+Al0AuUy8DAB8o6RhPx5qD7xEz7p8iaeCJC28Vz1+01ItdFxyQxEzMny0l32uw+24EK1A3tOXcCnjeuCQX57xlCJVV2FshhnHdaYX0L3uNPNX5jCqERHQ1Lf/xvxH6Gi1oF/bTyOf2087lun7vXhZT8fxUTTlz5JOJHGyAvj38TvjD/i3+a/ycxNA7fITbzu4mkkf/sMkv77R/5kYR4zh4sHOr5580vs5qooJiiibpU/109KTlj9UntJ8L5b4oLtua3eVVdB81i/QXZjZIV6+XgsR36XX89A1TcfzbmAc4yDw9l0btjqpIvVm+P/TN9Kvies9pQuwdSKb3UMgynO67IveTAyGPYJRytnTHwKCOZZbRtsbWzARv7yl9Wi/CCeyB8hZ62C/8TWI9kYua7Cz1I9PmNpISMfTS5UN/TQyz8lHKvmXIX0EAX/LTiLP3y0DeU1vr37ZBNtoxP8YjLKfvYNchqWFvzCFEaBjob8XeSdbs8LqFjE3fRauyNLRJchVqLTJa6haDfZ4FV8HeBYFCteLilpKiZu7Hbq+XQWb/DTGFluexvPC6taA8R53IBTjq+RbNTKOE7YGNPt8HpfKn++VT78gIGS+0Gq6srjOw1zY2ThBKtyg6xAJTqhXwQZx8HlavoORB8IVGbwCJJF2+iIbp8yF35ZjZF9rh1cU2mix5KkxK99SviCVK8rwfHgfygLn88GPK9VuFHycY50vkUDMHsVWr/fU3KxR897zB0WnxRS1gTnlsGASzV2ybRPryjA5mMXMHN96DOMiz10ymvX51VyZ6+USEWBDpEh0IFidUhM6Of5tBngWAv0ZO0WvcA1LdTlaniaDnTRatwW2aPaypwCItRqHCb2WanqEI4Tvsc5hTOfSzVG9thWf93LhXmQej34cXSUuswYZPa6+k3cZom1Kx3ouIW9fbSoxvL4zhVroxNqQO+sA1zeN0XfATBNRp/Z3+Svg5OquvIo7QuyMbLfEkfGVOm5JrZO369KZL1+Gt4DgNMtDFJC4T3Qqpztrwi2NPPicWDVnxoGvBRroxPC9CqcS6JUSet2aqBAR1P+vn6OMbwT/x7eiX8PbrfIhcDz4JE4oQRP082cF8gt0gjR8+LW+DQbcLTexicpsW0SX7PHZ5W/kRka+pcLX2Qczlf6PkUxJlKi47GPpaquIFZ1JfKeHN5zf/14pAwltgBtBhRrE+J5M5PO9z/N7/G/C0ojRauumlei43aFJ9D5g1H8Bse4pvNCbDA9seCHMQD5i4DVE3xL9HZ8BMxoD5zeGjBP3i03nNM7oG7G//j9vhkYjHFe1wsZJZFNaUMYRyeAwANxSi8v5OOncZkeH0+ylzWMzG47ezmJ7/Fa6wgioJAo/QrE6NnhIMAjaALsuNIQ/Pxa9YvvA/Ysh3PBXRBtAxVCdTeTCHS0D3Mo0NEtZ2UpfmvcjN8aN8NorxBJ4edi1lhvruDw+1yAYnm5JTr88uQ+tXoEROJPfgwtUNusk8knCHS7cOKCyIinPoGOU3BBkCpx8nw9zrvXlWTGpd5oWtaeonI8/PF2DHjjOxTb6rDthMQ8NN6Lsp3BdXXbpVYsiQUIWsQ/FOgYDP2b4xgHt8fFVWowOyW8Fr9Q8HfjDdZzSAFOpERPdJsZA9Y8Dez6BDj8Nf9yeY0D+GoK4KwFPh4K+GkLIiaeOZDoroLd3lT16nNscwxG7wejYG5qIY2j45/fh7CK03C4fPdrc2daaCpJbVr3tYULgR/fApaPuvyWb74Ol4hXz/A8rwHu0NrNBDPkwkrzNGywPItrqrcFTuwhofIkACC+/qJEGx2pPPgZc4lKdIgYv2107E0N0NxiN1A/B0/jU7SwMXKgi1mAxshiNxHPEYUbS3wCNiwMrupKUIcu8pl58bOwP+GPSKuTP/mf1wp8S6Ekn1rdXhcyYaAjuU0eaf7PlIufLROQ7jzr857wM4GrtA6crUAXwzkksHqMnPEFZsxfivxTl8Q/5+nb4Gcgblh18I2RITb2jofmlOhwHCcILqTbSKnHc5JLsRK9gG3RPAaUe3ud17xJ714fUp44j8BArDGyT4lO4/F/ZB1wKo9/OdNQLrZw0XUK9n3QjZH9fG81pThW5Ds+S7rrHDaan8EfjBuCW1nTShv+E8vr+f2Xk4gcr4GG6fCq2pbFXg3Ym9r2BHNOXBvXcN27qVK6wXxAotV4wbUdBKQDHTUHzZSLupfrlMMR6EnV8+ARXrjcbjeMxjgZT9PyiZXoeF6ggi3RkV2VJhiIzHfZQ40N3ZtvvLBK3vLE8iJz9FdwTPCerboKPvNkOWp8upV6pvmj6RsAwIjSeQBGBP+9eCyrh/sXvG1ZiZNcBjrFNbTTWrmnE/r4fkj4V92lkHo7eQbOAauJdi0Brn8o4Dg6cYyF3vWKcXB5lPiJtyNTl+e5KVZ1JVbKJ9WIvMx7fJs6kUDDg9QNxCW44fiEOkhxeZX8cW6g8hyw/H6/6wOkgxJhg9bg2ugEumb83vi9z2sPlX+AznHibRNlkXHeiX5PAR4YBVW6EmMOCXBuYEY7AEA8PoETJkHVVTNnCpNFtNAxhMFZmUQJlg4KdKhER69cHj1/RAMdGZNPckoGOiI3f87jwG4MhAI2Rr6cb7kBkecN1d/J15ynhuoLZ4UvcC6IT5LBCdoq1VRXCwIx0+mfgelZcHz7V2He/AYFUvkOXKJzJ/cTAPBBDgC0K98RcFGXHKE93whnLw/w/a1+Ctj7mddAzkqX6LjBufy3kYFT3cHXUo+t9Fi/WNVVoBtGgBvZ5llIhf+Ax5vb2bRPxEbZ7VTh1f6HcQ0TR8ohVUrhp+qquSMjtzD4fodmJt0TSQ7Rua4k0ngKOO6T5/VKLNDxXqZHSU4qGqrFPKuuDGABS5GaL9ReV0IGyRIs7SMdCnS0cvE4bqj5UfJtZ71noBNci/rGoETQGDnAwRboYiT2tOzZyt5U+H3DxU5uGx25DUcDjMPSKPSB5zjcevwdr5dcEG0rzXFwepRsGVx1gmqvxO8aqoTMef8UfCyp1iuQAuCMS2j4RUYVlfDlpteNItvc+cJG8eV5uOgQG/rRVx0zS+YpjnGBg+czO4THg8IXbMYx/21kCn8CXs8AfvL6fpVY9+UA5YqTazzyI9YYWf5xeW2tSLupDdNgFhth3CMP3jxLdHzHhgGY0WvKRcZ5lQJJM4ic326OebXf8g50/NOiylGsMbKnarsLX+/1rTILNKyC5/t7TpZKr7fpBZ8kcT5d3lUOFMTa6Eget8Jv8/8WbsfeMxUN70jcp7QPcyjQ0c6cG/y+7XYECHT89LriL/heJTrn/QwtHuhgFOs67fk03XrDZGDnx4GLPPmG0nIbs3pU1Wx/TjKZ3HFd5FixrRBbjvvOm8QYB7fHNhvcDmGDb7HvqfwUeh3xHYTQZWwMdILsdeVxERSbHT6jar/IZ4TfrtuYKGtdnPctyuN4qqm3o/+MwHOfCWeHVrbXFce5BSWNPiU6ayc1/P/dqyGvI6j8NEbHjfuJ42B0Vvmkk6q2va1yrSL58Cx1NNYKb7aMcTB4B2ScGyfLRBrfi/D+rNvN0HPat9h/1rPUSaREh3MDn44Gvvu7zzKb2yM0NI3Hovi6//HNL8IxcWTyDNrKbDViCYR/exyzjedCnFfvxqDOEcYapqgp2ec/jeefIsuX20Zn4+Ey3PfeFgBAHBMPdFqe+Eo6L2FCgY7KKmodgbv/inB79JwQbb3v5wbZ+JQrqLriGL7aK108HbB4WbREx+vA/noqEg9/6Xc5jbdOTm73co/ttNSXSbZbULLB28c/HZPMi8ujWsDAOZF9vqkxpFFsJOhC8VK7G8pzgR/e8FPK4fv6vl15gv0RJzNIStj4ClDVVL3lMpj9pG7i3fvDswTn+rjj+HvddL+f57w+c7ikEvVO4T5qzqSeYJyg7ZjYEAiepAYUdMke6sA/06UjwOdjgHm/amifsXwUrtr1mm9Cz2Chud2HRPBVV+WnkPHvkYL3DIz5Xk8YB7fchrMipVa1Djd2FXoGVCLf6YkfgMNfAT+97fMW8zOCulqaqq7EbS+8JH5NCXDOeZbqic/15/V5j/1uujzAqmdJbffSb9DSXeF3nQJHchumqPngVuk03mMBBdXrypfrcqAax4mXCqbv+qfo6+FEgY7Kvpiegz1vD4fNz+iWYjhHU6+rwI2RvT/ccMIIG8rKOHCLdgA14l2URauuRAKw1J/+6vOap8anh1BKdBoyItHgNNQSHZHdIjV1BcdxcHneTF0OtL3Y1N5BbLb2epGusUBDV2D8MAPlRQcl8uWbseqivYL6eu+BxaRY9q8AvhjH/+2WeQ3zvtB7j6A6xJjv9/PlR/IE23H0fBWmf33I7zqCwTFOUKIjOWAjgNkbjuDaV77FxsPCEo4lK7/Ah3/7I46fa/7M5+2/nwAc/LLhafrMDuCY+Ng78Xmzmv748k9AiW8pnBxS+47vcn/EtycOg2+pDJhbYvgIkXVKVDm/Ff+hRxqREh0/k22G0vC1h3130J/xZGjMop/rYrqhwvdzAR8IPUaGF61y9Pq8xzX07rht2GSehD5xR/nXWtvPoL0riB6l5wLvF+d54Tkoug9klLJZDC48bPy2qW2RVCcOHaBAR0WMMTxqysVQ406cO/hzUJ/lPKchEHvaEhyc3r2uXD5JAjWK7OY6AiwYDMzp7fumo1Y02JIcN8EfvuoqwFNc48XPO98SE+r5ey4WLWnxm16qy7cbbqfnjVUYvMYZfC8O+874b0iaDPF5bP6df8Zn7iZDYqogYJUb6AAQDEDn3ZZEKghu3KdvfPMLxi7aIWgPI0da5UHBQWiEG5/keV+0Qw90GMcJShobj/v8n9eh8MRhwbq//u57vGhairdWbREsI2ff/+GJuJU4sFKk5KU5/NxAzVvnCF/48nFFV+1T0uqJMRi8nrwZ5wbzGVFZcuEyEgm3Pd7gBv7bNM0mqy5FxeLfo/5QQyAm1ohbbfwDl8Tx19+5Da/Hf+zzeqAqcs/rmvgUOMLPe1Z3/yX+U3SMK8W7Zun59gS2fuD7mozvZ6/3NUl0Uk95bXRejV+MD80zAQBx/koFD6wKmC81UfdyFTmdTvCVBI0XF5cDOO7bXdIbczbdAMUaefk74Sy7PgKKt8FoHdi0PMi8pdTbhH+f2w324e1o0/EO3zwG2Ui6MR+AjMbIlWeA+CS0qSgQvi41c7Cf/WGGv4DMd680lOiI9LpiTNhGxx64Dj/U9rebDpdi1zeHMMPjNYuRg8tjOyUDMrF8oGmLDF4BKmPiNSiNT6/5P36FTMMl7O4yElmy19i4rqbj+OX4ZTjO2gHcsIbjLCm1WZ1nvQMdxrnwy56t6LP+cjfp1P/h38s1P484A0MXhw3AvT7Lamc/0YyciOZOftJLJ0Ncg/je4+qrgf8+Bdh8R8xtmJhWeDN0udxwy+ydpsTo00WfP4cOp78GCr8GJuzSpo1OgIDl/+o/EX2968E5oq838uxNaoHYA6pwvTV1dQhu6k8Pub5tFpnbHfCc8pwIFwCyi/7rm0jyO/F9vW9cwzxbRok2OgCAE5uAa/83QM7UQ4GOiux11Xyg0+rUOqDfMOCHGcDmmYE/7PRfolNe68BHP53AmfI6tDtrQ3+PbzI5r6Ee/Fr81LSIEC8mVWtfRAoYUk75Dszl98lRiszGyOw/Y2EoPYiuDq9GkhKBTmFZNW6UOJrFi5ClNZQAiRXnuvnxggAg4/DSgMsKVGX4K6N4tcVc8xw8cq4/fuGycXVcUcOyXPaQS3Scbo4/Fg1eJVENy/S9PBrAwBjDvy0NjXm/t3WXvT6eQxgMLjK/CdeSnQ299Po9Lv7UKxPHuQWlAZzbjZojTce8k2OIv/x7Y2nbNZzU5IfKtpX56392QG4TaFdyhqIX4tQ9HwAnvxF/k/l2A3Y4neDs8o4l72qv7LgyvGBaJkwTIIioPu8RVK57Ceyml2StW1GNJVhBXhYtdonRxy9jgkAncNtKt7MZs46LOFZqQ9cAabwDy4yyLb5pJHaM35Jzf4GOySL9XhhQ1ZWKHB6jG7c9uAAoPQQuf5GszzKPNjpiA0+dLa/Fa18dwqItJ+VlJsQ2LIUVfj7nDn0sC7vTf/BhOLMd8A5yAMlxUTrEiXTlvCxe7MmKJ1KiY/Dpb3Q5KRf0oHTNmbn30aoPBaU2nNMu+B6DKtHx7KTnVXUhNaaRAYxvaAgAybXBz6nD6nyHzDcVXi7R3CZS9B4MjvmU6Hi64D0AHyB5pQ6qGlCGV6unyU5bXKNsiUZ8pXSbDsaYTwnxkZIKuBziVajexEp0HjN596oJ0I4lLr7pD2ed/OlgFBTnbryOiOc12OruRp7Ho5wSHYejeeMBeYsvCdxGR86QB5ad80Rf9zf3lslfoGOQN6SFWijQUZHnNA4AgIvHUeuQOVCeZ8mFSIlOHBiSIL83F2MMLWuDnyYhzizdFZnJvDh6fQpA4EBHkkt8nf3jDom+DgDxQV60bo/bjT/Hf+7zOmPBl2I1Z+iYTHcxLB6P+oV7NwsWGOrN2bt3hL9Ap77e4xgLYWPanA1cTRsqxtyCG4t3g1pXEKWYvaulx7RSm50pW7Du9+bJGAxMuJ96H3gDZ8v8l1Q08mnILJYmwPsuQ1Ogc7beHFJj5OYyXC7RkTqkzSy0khZBiY7Bf9tKl5tDaXnwXdilnN39LTpVF4iuS5iFwPs7Kc+3d1wgFubnfqRC78JgUKCjIk6k7t0psytrW1tTZC52cRlr+gYHEx7FROMXspbHGEP2hZ8CJ7yszuHGyQs1fgMd2ANMcCeaj8sfdYZQ7QWvbvfSa2n4r+I0sCRAvbDIxcD3CfVyUs4t7HUlQ3PbNHh2Ib/f8SVaVjV1fQ+2jQ7/Oa/AWepGYwBgr2saCySU0bUzLvgWiyuFY5zgxuLdwN0oUmUZaDbooCg0AKLSpUlVNdIPIAwMcSLHcJeSXFnLNkp0IRauxP/2uA1Ngd0vRaV4Y+0eWetWUtefJ1/+Tfw79F8KLM3zGEwQqbpynT8Ih4tDz5fX4qtpw3Httw+EtB4xZ39eIfg77+g5HCsVGcepWWOOSR/zCX4CncAth9RFgY6Kslb9NuTPdqnayf8uPbQ28KDpe1lddO3FB2E8I3OGW8Ywal4eBr39A87VSB+gxjp5T4FeC2/IjyO0Ep2j5wKvsw13saHx2+yeARt+dysLYjI8xgkmTJTDEOIMxo28b4JJNaf5340ivbwk8+Hxu9ktDBY5zo2jZ8t8121gMHw8lP/bHUqbLBUxjgmqq7ynKQn1qVwupebWiucabhBKjQXlv9qFwSBSxdDO7Tt6t5gEd+CBBW+y5cJtkx6zy8w13RDvMO7G3ys1aKODywG+xC6P91cN40ffgzPAvm3YHrGqK9Oiu7B860n8H7cKvzEq+xDgvSlbF7+MGbM9hjJgDO79X/pOAaKQRD+BTsGZ4B+KlRTxgc57772Hzp07IyEhAX369MFPP8kvtQi7EMcZ+J9S8fE4ACDLcAm3xB0IuIybS1fgxlp5+4a57Kg8dxjD4rbjrE26GDy+PoRAhzWv6qpko3jdsScrqwQ+GRkwHQCk2uW3O2GMNc3SLhPnDL0O3gDmM7WFsd5/d3U5Et3CpzzGcaidN0Q0bVrtcf73ovO+wZCWOv44WVBdxdwuwdOqJcB8SG6ZY8eIMYDB6VBmHi0zF0oVsHRglMFJt1czMCbaDbi1Qd7IyEmuClnpHO/fJv1ejfAYbmPQ5iboWvdXdDr0vuh7oZboAIAhbw64i4XibXQAFH3zNh41STQWD5FYSeUz8SuxwPwO3xHlwvZ/w/ifMehQvVfRdTdK9NOUorRK2zF2IrrX1WeffYZJkybhvffewy233IJ58+bhrrvuwsGDB9GhQwets+fLKafaxVc6Lvl9v3vcab/vB+uNtXuwydJQtFvCWkumM4UQ6HD1lcDJn3HHdyNCytsgY/iLuRtlF7wT9DO3yV4R8vq6uo76vGZ0hHZTsBicQM0FILkNEjnhTc1da8N1cYG7V8fbCgFt2xQKJFafFgxxEGevgqGmaQRo0V4vHuz11UgKcd0mA4c6hwMJIX7eUwa7gL3v5QT9ObPEjdRfSR8Dk9XORkpn+y+y0iXWSwdbnQ0yJxBVWfzWObBKvCdW7RQMe8khJEr0KHw5fpno683RpXIbUiWC1aqaaljjGdp8M070/WD0qpceJNRfm1GTSdsylYgu0Zk5cybGjh2LP/7xj+jevTtmz56N7OxsvP++eJQeNm4Xzpf4TggHh8jcJzr0wp6mp/tMg3QJQopd+mIm5YrjXwCL7g4pX1qzlu5Aq1KR2cFFTPh0N0or63HjWfHxOEKVWScxPYUMjnd6wHnxJJKZ8Dhs8cH1sj7/W+PmkNetFlNdUynTDQdeR59TC/i/zSI3mixWitrL1abcoa+bte7DRcrdsHuVrsb1tcFVZSQh+NJCxoDqC/KqqdQidUOOJueOFoR1ff72afXFYmDzLMn3lVBWUoREP8ejyajtE5KBhdLCUAccDgeSkpLw73//G//7v00NTp9++mkUFBRg06ZNPp+x2+2w25u+jMrKSmRnZ8Nms6Fly5aK5e3YtrXo9HUOTIbw9ybQIzczYA/7H9wQF/pNOtJsdF+HTMMldL88Bg7Rj7MsDa0MdUhGaCWsRL/Ox7dDhlPbQE5vjib0QNf60KYZUcpPWWPxq/Eyxo8LQmVlJaxWq6z7d8SW6Fy4cAFutxsZGRmC1zMyMlBSIj6vyowZM2C1Wvmf7OxsdfJ24EcKcgCc4tLx9+6r8eeOn6P2FumZx6PR7cY9FOToVDvDRQpyAJQxqYob5blYHLaablJ9PWd7PBE4UYzROsgBgKQu/TRdf0S30QEAg1f/fMaYz2uNXnjhBUyePJn/u7FER2n9H30TO7feDeeBtUjscANQegBJ5/NRiRZIMnFIqjqJC6ZMwNoe9h6/Bzu0BmazBcxZB44BtW4jLpmuQIfqvYgDh+KWvXBF7+GIt51C/MVDcLs5JFzYj3qTFXXV5Ug2cqhP645WHa9D6Z5cWOPqUG1qjVpmQYLZCMuVg2A5uhasrhxcXSVccRa4U7KQ6K5BVbf7YLBXwXz0q4aJRBNbg9mrwEwJ4BJawVFXizYt4hFXX466xLZwO+rRwuiCofIM6owpqLO0AVpmwWA0w151EVV2Dm0sLnDdf4OKFv+Dl3q1hcFggNvNIa++AlxlMRISEsFdKkRdiw4w1V9C6oWdqOr6G3AVZ2E2m+GuKoW75hLaZ3dEXW0tyiwd4GjRDi7EIbXkZziSs5Aa70ClA3BxQHznASgr3I8MxylccWkX6s2tAAa4k9LRatCfcO7kUXAXjsLpdMBlTEai8xJaVheixmRFi5534/zZ00g6vRHuFm1htRhQGncFKlgLtI53gDPEI+HcVqTF1cDBjChPaAdjchqYKQlpPe+Abf96ZLOzOOVMRZm5Pc7UGNHLdApONweDJQWGi0dhvGowqktPIaGuBHFxRiSyOritHVGSci2Si7ehZdv/AastR3tTBc6U14GDATV19Uiv/gUMQNXV98MIwHV6B2x2Dld07A5DghWGwh9Q36YHEkr3IKW+GOfj2+MKx2m4LK1h4WphtcThRPL1sFafgM2SCXPdBdS37ITU2kKUZw+GqfB7OFu0gzGxJYxtroTDVow4twNJlw6i/YOzcLr0Emq3L4O57jxcMMJuaoH69rfCUHsB9eePotPNv4PrYiEcO5egwnotMqv2wm0w4YSxMxJbtIK5TWe0OvkNXGndkJTdC3G7l8BiNsFmN8CeeAU4gwlG5kbqLWNQXlmF+l2fIyHOhRY1p1Gd1gtx6d2AymLYXW60rD4OlpSO4to4tGrdCi273oqqgxtgdNUg/dJOuBLS4HQ64TLEw24wo7JlN7R2lSG9cj/Op96IippaZNcdgo21QIuUlriA1mhRXwx7YjpcCalw1dfA5K5HsqEeBgD1iRlwuoGUmkJYEpJQjha4gpXDcO1vUFmYj1okALYzYIlpiG/XCyjajoS6YthTOsJt7YgLjnhk1J8AV3Ue7oTWaF15GK74FnD8z1DEFe+Gq+NtiLvmHrS2n0XVnjWwG5NhvHgUlpozcKZkA4mt4XA44KytQJptPywGDuVd70PHWx/EyU+nIMF+EWevuBUpzovIrDuCc9n3IMF2HDCZgeQMXNHpWtRt+ifOtx+ChLN5iLtyMBJLtsMYF4cqJwBLS3S6ezJ+/OZfiKs8i8SUVnC7XGBJabiU0BFt0tJw4EQRrv7V75Bw8FO0q9yLczUMDpMVruQrYDTFw+2wA44qOBKugCEuDkZzMjKvSEPdlnm4aO0Jk4FDYvZ1cJQeh+HKO3DDjbdi49pFQKIVKa5yWNr1ROHhPUhzFgP2atSZU9Ghxy2o/ul9JKW2g9GcgCs6X4uLzIrSkwdhMJpgPpMHZ2ZvmJJTYSzciPLU69Hyht/Bsn0uWMebccOdD6OkTSsUH8qDqaIQ7qy+6DgwB2UlZ1B3MBcp7a5G2cEfYWQu1JtTwcXFo5XrIuIMDNWJWWjVcxjKCvcjvnQPjI4q1Ce3Q3JmVyRf0R6Ve79GtZ1DnLMGSL8aLdPaAvtXwnDjWLjO7YPRkoSEmrOornPAffEEjK2ykHDrk6g78A3YuQK0YeWochlQndoT5uqzSK86ABafhFpTKyTXnUWBuQ+yk5xIrilCbZe7EAc36gu3wmgADB1ugtNeD4MxHm069cDFwz+jxaWDqG+RDXecBW6DCSkVB+CKS0B9i2wYLclwVF2EwdoeJuYAxzFwtZdgcVbAbrKCtbkKxpbpiCsvRLuBj+KnHzcgtfIXZPYaDO7QarSqO41z7AowZx3M7a8HMyUg8dhauGFEfUonWNI6wF2yH1b3JdhSe8LudMNgNCO152BUHViPpNpzqLNeidrW3WFy12DAr+9X/D4bjJiquvIWTNEXIYQQQvQhJqquzGYz+vTpg/XrhV2v169fj5tvvlmjXBFCCCFETyK66mry5MnIyclB3759MWDAAHz44Yc4ffo0Hn/8ca2zRgghhBAdiOhA54EHHsDFixfx6quvori4GD169MDXX3+Njh07ap01QgghhOhAxLbRUQK10SGEEEIiT0y00SGEEEIICYQCHUIIIYRELQp0CCGEEBK1KNAhhBBCSNSiQIcQQgghUYsCHUIIIYRELQp0CCGEEBK1KNAhhBBCSNSiQIcQQgghUSuip4BorsZBoSsrKzXOCSGEEELkarxvy5ncIaYDnaqqKgBAdna2xjkhhBBCSLCqqqpgtVr9ponpua44jsO5c+eQkpICg8Gg6LIrKyuRnZ2NoqIimkfrMtonvmifiKP94ov2iTjaL75iYZ8wxlBVVYWsrCzExflvhRPTJTpxcXFo3769quto2bJl1B5ooaJ94ov2iTjaL75on4ij/eIr2vdJoJKcRtQYmRBCCCFRiwIdQgghhEQtCnRUYrFY8Morr8BisWidFd2gfeKL9ok42i++aJ+Io/3ii/aJUEw3RiaEEEJIdKMSHUIIIYRELQp0CCGEEBK1KNAhhBBCSNSiQIcQQgghUYsCHRW899576Ny5MxISEtCnTx/89NNPWmdJNTNmzMCNN96IlJQUpKen495778Xhw4cFaRhjmDZtGrKyspCYmIhBgwbhwIEDgjR2ux0TJkxAmzZtkJycjJEjR+LMmTPh3BTVzJgxAwaDAZMmTeJfi9V9cvbsWfzhD39AWloakpKScP311yM/P59/P9b2i8vlwksvvYTOnTsjMTERXbp0wauvvgqO4/g0sbBPfvzxR9xzzz3IysqCwWDAl19+KXhfqX1QXl6OnJwcWK1WWK1W5OTkoKKiQuWtC42/feJ0OvHcc8+hZ8+eSE5ORlZWFh5++GGcO3dOsIxo2ychY0RRK1asYPHx8Wz+/Pns4MGD7Omnn2bJycns1KlTWmdNFUOHDmULFy5k+/fvZwUFBWz48OGsQ4cOrLq6mk/zxhtvsJSUFLZy5Uq2b98+9sADD7C2bduyyspKPs3jjz/O2rVrx9avX8927drFbr/9dnbdddcxl8ulxWYpZvv27axTp06sV69e7Omnn+Zfj8V9cunSJdaxY0f2yCOPsG3btrHCwkK2YcMGduzYMT5NrO2X1157jaWlpbG1a9eywsJC9u9//5u1aNGCzZ49m08TC/vk66+/Zi+++CJbuXIlA8BWrVoleF+pfTBs2DDWo0cPtmXLFrZlyxbWo0cPNmLEiHBtZlD87ZOKigo2ePBg9tlnn7FffvmF5eXlsX79+rE+ffoIlhFt+yRUFOgo7KabbmKPP/644LWrr76aPf/88xrlKLxKS0sZALZp0ybGGGMcx7HMzEz2xhtv8Gnq6+uZ1WplH3zwAWOs4aSNj49nK1as4NOcPXuWxcXFsdzc3PBugIKqqqpY165d2fr169nAgQP5QCdW98lzzz3Hbr31Vsn3Y3G/DB8+nD366KOC1+677z72hz/8gTEWm/vE+6au1D44ePAgA8C2bt3Kp8nLy2MA2C+//KLyVjWPWPDnbfv27QwA/1Ad7fskGFR1pSCHw4H8/HwMGTJE8PqQIUOwZcsWjXIVXjabDQCQmpoKACgsLERJSYlgn1gsFgwcOJDfJ/n5+XA6nYI0WVlZ6NGjR0TvtyeffBLDhw/H4MGDBa/H6j5ZvXo1+vbti/vvvx/p6eno3bs35s+fz78fi/vl1ltvxXfffYcjR44AAPbs2YPNmzfj7rvvBhCb+8SbUvsgLy8PVqsV/fr149P0798fVqs1KvaTzWaDwWBAq1atANA+8RTTk3oq7cKFC3C73cjIyBC8npGRgZKSEo1yFT6MMUyePBm33norevToAQD8dovtk1OnTvFpzGYzWrdu7ZMmUvfbihUrsGvXLuzYscPnvVjdJydOnMD777+PyZMn4y9/+Qu2b9+OiRMnwmKx4OGHH47J/fLcc8/BZrPh6quvhtFohNvtxuuvv47f//73AGL3WPGk1D4oKSlBenq6z/LT09Mjfj/V19fj+eefx+jRo/lJPGN9n3iiQEcFBoNB8DdjzOe1aPTUU09h79692Lx5s897oeyTSN1vRUVFePrpp7Fu3TokJCRIpoulfQIAHMehb9++mD59OgCgd+/eOHDgAN5//308/PDDfLpY2i+fffYZli5diuXLl+Paa69FQUEBJk2ahKysLIwZM4ZPF0v7RIoS+0AsfaTvJ6fTiQcffBAcx+G9994LmD4W9ok3qrpSUJs2bWA0Gn0i4dLSUp+nkWgzYcIErF69Ghs3bkT79u351zMzMwHA7z7JzMyEw+FAeXm5ZJpIkp+fj9LSUvTp0wcmkwkmkwmbNm3Cu+++C5PJxG9TLO0TAGjbti2uueYawWvdu3fH6dOnAcTmsfLnP/8Zzz//PB588EH07NkTOTk5eOaZZzBjxgwAsblPvCm1DzIzM3H+/Hmf5ZeVlUXsfnI6nRg1ahQKCwuxfv16vjQHiN19IoYCHQWZzWb06dMH69evF7y+fv163HzzzRrlSl2MMTz11FP44osv8P3336Nz586C9zt37ozMzEzBPnE4HNi0aRO/T/r06YP4+HhBmuLiYuzfvz8i99sdd9yBffv2oaCggP/p27cvHnroIRQUFKBLly4xt08A4JZbbvEZeuDIkSPo2LEjgNg8VmpraxEXJ7wMG41Gvnt5LO4Tb0rtgwEDBsBms2H79u18mm3btsFms0XkfmoMco4ePYoNGzYgLS1N8H4s7hNJ4W//HN0au5cvWLCAHTx4kE2aNIklJyezkydPap01VfzpT39iVquV/fDDD6y4uJj/qa2t5dO88cYbzGq1si+++ILt27eP/f73vxftGtq+fXu2YcMGtmvXLvbrX/86orrHBuLZ64qx2Nwn27dvZyaTib3++uvs6NGjbNmyZSwpKYktXbqUTxNr+2XMmDGsXbt2fPfyL774grVp04Y9++yzfJpY2CdVVVVs9+7dbPfu3QwAmzlzJtu9ezffg0ipfTBs2DDWq1cvlpeXx/Ly8ljPnj1125Xa3z5xOp1s5MiRrH379qygoEBw7bXb7fwyom2fhIoCHRX861//Yh07dmRms5ndcMMNfFfraARA9GfhwoV8Go7j2CuvvMIyMzOZxWJht912G9u3b59gOXV1deypp55iqampLDExkY0YMYKdPn06zFujHu9AJ1b3yZo1a1iPHj2YxWJhV199Nfvwww8F78fafqmsrGRPP/0069ChA0tISGBdunRhL774ouBmFQv7ZOPGjaLXkTFjxjDGlNsHFy9eZA899BBLSUlhKSkp7KGHHmLl5eVh2srg+NsnhYWFktfejRs38suItn0SKgNjjIWv/IgQQgghJHyojQ4hhBBCohYFOoQQQgiJWhToEEIIISRqUaBDCCGEkKhFgQ4hhBBCohYFOoQQQgiJWhToEEIIISRqUaBDCCGEkKhFgQ4hhBBCohYFOoQQQgiJWhToEEIIISRqUaBDCCGEkKj1//JXlpgJ5n1yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    for batch_data, batch_labels in val_loader:\n",
    "        # Move the data and labels to the device\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        #batch_labels = torch.squeeze(-1)\n",
    "\n",
    "        batch_labels = torch.exp(batch_labels)-1\n",
    "        outputs = torch.exp(outputs)-1\n",
    "\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        plt.plot(outputs.numpy(), label = \"predicted\")\n",
    "        plt.plot(batch_labels.numpy(), label = \"expected\")\n",
    "        plt.legend()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab1dbd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.07407709956169128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evalutaion_val_dataset = val_loader.dataset\n",
    "    n_samples = len(evalutaion_val_dataset)\n",
    "    outputs = []\n",
    "    expections = []\n",
    "    for i in range(16):\n",
    "    # Get a random sample\n",
    "        random_index = int(np.random.random()*n_samples)\n",
    "        single_example = evalutaion_val_dataset[random_index]\n",
    "        output = model(single_example[0])\n",
    "        output = torch.exp(output)+1\n",
    "        outputs.append(output)\n",
    "        expections.append(np.exp(single_example[1])+1)\n",
    "        \n",
    "    loss = criterion(torch.FloatTensor(outputs).squeeze(-1), torch.FloatTensor(expections).squeeze(-1))\n",
    "    plt.plot(outputs, label = \"predicted\", linestyle=\"\",marker=\"x\")\n",
    "    plt.plot(expections, label = \"expected\", linestyle=\"\",marker=\"o\")\n",
    "    plt.legend()\n",
    "    print(f'loss = {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ce64981",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_weights_979.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights_979.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,val_loader)\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model_file, val_loader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model_file, val_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the neural network from file\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting model \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m model_file)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Get the name of the model\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/h8k65brxri7lixixd7d8lql3y3k3vq6d-python3-3.10.9-env/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/nix/store/h8k65brxri7lixixd7d8lql3y3k3vq6d-python3-3.10.9-env/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/nix/store/h8k65brxri7lixixd7d8lql3y3k3vq6d-python3-3.10.9-env/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_weights_979.pth'"
     ]
    }
   ],
   "source": [
    "evaluate(f'model_weights_979.pth',val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1be636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('weights/model_weights_979.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79198c12",
   "metadata": {},
   "source": [
    "Commiting tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a8496df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the test.csv file\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# read the oil.csv file\n",
    "oil_df = pd.read_csv('oil.csv')\n",
    "\n",
    "# fill missing values in dcoilwtico column with previous day's value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].fillna(method='ffill')\n",
    "\n",
    "# merge the two dataframes based on the 'date' column using left join\n",
    "test_merged_df = pd.merge(test_df, oil_df[['date', 'dcoilwtico']], on='date', how='left')\n",
    "\n",
    "# fill remaining missing values in dcoilwtico column with previous day's value\n",
    "test_merged_df['dcoilwtico'] = test_merged_df['dcoilwtico'].fillna(method='ffill')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d6b8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file using pandas\n",
    "test_train_df = pd.read_csv('test.csv')\n",
    "test_oil_df = pd.read_csv('oil.csv')\n",
    "test_stores_df = pd.read_csv('stores.csv')\n",
    "# fill missing values in dcoilwtico column with previous day's value\n",
    "test_oil_df['dcoilwtico'] = test_oil_df['dcoilwtico'].fillna(method='ffill')\n",
    "\n",
    "# merge the two dataframes based on the 'date' column using left join\n",
    "test_merged_df = pd.merge(test_train_df, test_oil_df[['date', 'dcoilwtico']], on='date', how='left')\n",
    "\n",
    "# fill remaining missing values in dcoilwtico column with previous day's value\n",
    "test_merged_df['dcoilwtico'] = test_merged_df['dcoilwtico'].fillna(method='ffill')\n",
    "test_merged_df = pd.merge(test_merged_df, test_stores_df, on='store_nbr').sort_values(by='id')\n",
    "\n",
    "test_df = test_merged_df\n",
    "\n",
    "# Extract the label column and convert to a PyTorch tensor\n",
    "test_ids = torch.tensor(test_df['id'].values, dtype=torch.float)\n",
    "#date = torch.tensor(df['date'].values)\n",
    "test_store_nbr = torch.tensor(test_df['store_nbr'].values)\n",
    "#test_train_sales = torch.tensor(test_df['sales'].values, dtype=torch.float)\n",
    "test_onpromotion = torch.tensor(test_df['onpromotion'].values)\n",
    "test_dcoilwtico = torch.tensor(test_df['dcoilwtico'].values, dtype=torch.float)\n",
    "\n",
    "test_df['event_type'] = 'regular day'\n",
    "test_df['description'] = '0'\n",
    "for index, row in test_df.iterrows():\n",
    "    if (row['date'] in data_dict):\n",
    "        if (row['city'] in data_dict[row['date']]):\n",
    "            test_df.at[index, 'description'] = data_dict[row['date']][row['city']]['description']\n",
    "            test_df.at[index, 'event_type'] =  data_dict[row['date']][row['city']]['type']\n",
    "        if (row['state'] in data_dict[row['date']]):\n",
    "            test_df.at[index, 'description'] = data_dict[row['date']][row['state']]['description']\n",
    "            test_df.at[index, 'event_type']  = data_dict[row['date']][row['state']]['type']\n",
    "        if ('Ecuador' in data_dict[row['date']]):\n",
    "                test_df.at[index, 'description'] = data_dict[row['date']]['Ecuador']['description']\n",
    "                test_df.at[index, 'event_type'] = data_dict[row['date']]['Ecuador']['type']\n",
    "    else:\n",
    "        test_df.at[index, 'event_type'] = \"regular day\"\n",
    "\n",
    "# Convert string dates to datetime objects\n",
    "test_dates = pd.to_datetime(test_df['date'], format='%Y-%m-%d')\n",
    "test_month = []\n",
    "test_day_of_week = []\n",
    "test_day_of_month = []\n",
    "test_day_since_paycheck = []\n",
    "for i in test_dates:\n",
    "    test_month.append(i.month)\n",
    "    test_day_of_week.append(i.day_of_week + 1)\n",
    "    num_days_in_month = monthrange(i.year, i.month)[1]\n",
    "    test_day_of_month.append(i.day)\n",
    "    if(num_days_in_month == i.day):\n",
    "        test_day_since_paycheck.append(0)\n",
    "    else:\n",
    "        if (i.day>=15):\n",
    "            test_day_since_paycheck.append(i.day-15)\n",
    "        else:\n",
    "            test_day_since_paycheck.append(i.day)\n",
    "\n",
    "test_month = torch.FloatTensor(test_month)\n",
    "test_day_of_week = torch.FloatTensor(test_day_of_week)\n",
    "test_day_since_paycheck = torch.FloatTensor(test_day_since_paycheck)\n",
    "test_day_of_month = torch.FloatTensor(test_day_of_month)\n",
    "\n",
    "#family to tensor\n",
    "test_family = []\n",
    "test_family_raw = test_df['family'].values\n",
    "test_families = sorted(list(set(test_family_raw)))\n",
    "test_family_stoi = {s:i+1 for i,s in enumerate(test_families)}\n",
    "for i in test_family_raw:\n",
    "    test_family.append(family_stoi[i])\n",
    "test_family = torch.FloatTensor(test_family)\n",
    "\n",
    "#city to tensor\n",
    "test_city = []\n",
    "test_city_raw = test_df['city'].values\n",
    "test_cities = sorted(list(set(city_raw)))\n",
    "test_cities_stoi = {s:i+1 for i,s in enumerate(cities)}\n",
    "#cities_itos = {i:s for s,i in cities_stoi.items()}\n",
    "for i in test_city_raw:\n",
    "    test_city.append(test_cities_stoi[i])\n",
    "test_city = torch.FloatTensor(test_city)\n",
    "\n",
    "#state to tensor\n",
    "#test_state_raw = test_df['state'].values\n",
    "#test_state = []\n",
    "#test_states = sorted(list(set(test_state_raw)))\n",
    "#test\n",
    "\n",
    "#state to tensor\n",
    "test_state_raw = test_df['state'].values\n",
    "test_state = []\n",
    "#states = sorted(list(set(state_raw)))\n",
    "#states_stoi = {s:i+1 for i,s in enumerate(states)}\n",
    "for i in test_state_raw:\n",
    "    test_state.append(states_stoi[i])\n",
    "test_state = torch.FloatTensor(test_state)\n",
    "\n",
    "#store type to tensor\n",
    "test_store_type_raw = test_df['type'].values\n",
    "test_store_type = []\n",
    "#store_types = sorted(list(set(store_type_raw)))\n",
    "#store_types_stoi = {s:i+1 for i,s in enumerate(store_types)}\n",
    "for i in test_store_type_raw:\n",
    "    test_store_type.append(store_types_stoi[i])\n",
    "test_store_type = torch.FloatTensor(test_store_type)\n",
    "\n",
    "test_event_description_raw = test_df['description']\n",
    "test_event_description = []\n",
    "#event_descriptions = sorted(list(set(test_event_description_raw)))\n",
    "#event_descriptions_stoi = {s:i+1 for i,s in enumerate(event_descriptions)}\n",
    "for i in test_event_description_raw:\n",
    "    test_event_description.append(event_descriptions_stoi[i])\n",
    "test_event_description = torch.FloatTensor(test_event_description)\n",
    "\n",
    "\n",
    "test_event_type_raw = test_df['event_type']\n",
    "test_event_type = []\n",
    "#event_types = sorted(list(set(test_event_type_raw)))\n",
    "#event_types_stoi = {s:i+1 for i,s in enumerate(event_types)}\n",
    "for i in test_event_type_raw:\n",
    "    test_event_type.append(event_types_stoi[i])\n",
    "test_event_type = torch.FloatTensor(test_event_type)\n",
    "\n",
    "\n",
    "test_cluster = torch.tensor(test_df['cluster'].values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47bc880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28512]) torch.int64\n",
      "torch.Size([28512]) torch.int64\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n",
      "torch.Size([28512]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "#print(train_sales.shape, train_sales.dtype)\n",
    "print(test_store_nbr.shape, test_store_nbr.dtype)\n",
    "print(test_onpromotion.shape, test_onpromotion.dtype)\n",
    "print(test_family.shape, test_family.dtype)\n",
    "print(test_day_of_week.shape, day_of_week.dtype)\n",
    "print(test_month.shape, test_month.dtype)\n",
    "print(test_day_since_paycheck.shape, test_day_since_paycheck.dtype)\n",
    "print(test_dcoilwtico.shape, dcoilwtico.dtype)\n",
    "print(test_city.shape, test_city.dtype)\n",
    "print(test_state.shape, test_state.dtype)\n",
    "print(test_store_type.shape, test_store_type.dtype)\n",
    "print(test_cluster.shape, test_cluster.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45d43e95",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2375917821.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [38]\u001b[0;36m\u001b[0m\n\u001b[0;31m    test_city.unsqueeze(1), test_state.unsqueeze(1), test_store_type.unsqueeze(1), test_cluster.unsqueeze(1)\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "test_data = torch.cat((test_month.unsqueeze(1), test_day_of_week.unsqueeze(1),test_day_since_paycheck.unsqueeze(1),\n",
    "                        #test_store_nbr.unsqueeze(1),\n",
    "                       test_family.unsqueeze(1),  test_onpromotion.unsqueeze(1),\n",
    "                        test_dcoilwtico.unsqueeze(1),\n",
    "                       test_city.unsqueeze(1), test_state.unsqueeze(1), test_store_type.unsqueeze(1), test_cluster.unsqueeze(1)\n",
    "                       test_event_type.unsqueeze(1), test_event_description.unsqueeze(1)\n",
    "                           ), dim=1)\n",
    "\n",
    "print(test_data.dtype)\n",
    "print(test_data.shape, test_data.dtype)\n",
    "print(test_data.shape, test_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8c269f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "submission_loader = DataLoader(test_data, batch_size=1, shuffle=False,num_workers=8)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs) in enumerate(submission_loader):\n",
    "        outputs = model(inputs)\n",
    "        output = torch.exp(outputs)+1\n",
    "        #_,predicted = torch.max(outputs.data, 1)\n",
    "        all_predictions.append(output.item())\n",
    "        #all_predictions.extend(predicted.numpy())\n",
    "# Save the predictions to a new CSV file\n",
    "startId = 3000888\n",
    "#endId = \n",
    "results = [i for i in range(startId,3000888+len(all_predictions))]\n",
    "df = pd.DataFrame({'id': results, 'sales': all_predictions})\n",
    "df.to_csv('My_model_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed9741b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.857950210571289,\n",
       " 2.0,\n",
       " 8.28862190246582,\n",
       " 2978.365234375,\n",
       " 2.0,\n",
       " 533.490234375,\n",
       " 17.83911895751953,\n",
       " 860.1469116210938,\n",
       " 630.85546875,\n",
       " 282.5483093261719,\n",
       " 157.57640075683594,\n",
       " 137.74520874023438,\n",
       " 4420.60888671875,\n",
       " 22.235414505004883,\n",
       " 3.1352550983428955,\n",
       " 25.550722122192383,\n",
       " 36.089805603027344,\n",
       " 2.0,\n",
       " 225.013427734375,\n",
       " 21.495405197143555,\n",
       " 62.506683349609375,\n",
       " 13.136899948120117,\n",
       " 95.19330596923828,\n",
       " 7.150758743286133,\n",
       " 338.64813232421875,\n",
       " 362.2543029785156,\n",
       " 9.042611122131348,\n",
       " 9.9443998336792,\n",
       " 443.81243896484375,\n",
       " 111.09378051757812,\n",
       " 6632.443359375,\n",
       " 79.55860137939453,\n",
       " 22.332046508789062,\n",
       " 4.524602890014648,\n",
       " 2.0,\n",
       " 4.597993850708008,\n",
       " 1147.9459228515625,\n",
       " 2.0,\n",
       " 112.02134704589844,\n",
       " 6.927706718444824,\n",
       " 602.2344360351562,\n",
       " 351.5782165527344,\n",
       " 176.87417602539062,\n",
       " 46.131202697753906,\n",
       " 27.95133399963379,\n",
       " 2484.265869140625,\n",
       " 4.052448749542236,\n",
       " 2.0,\n",
       " 10.96297550201416,\n",
       " 21.330751419067383,\n",
       " 2.0,\n",
       " 136.9022979736328,\n",
       " 4.779414176940918,\n",
       " 35.9719352722168,\n",
       " 5.1050496101379395,\n",
       " 49.697872161865234,\n",
       " 2.0,\n",
       " 136.17225646972656,\n",
       " 187.09669494628906,\n",
       " 2.325284957885742,\n",
       " 4.563907146453857,\n",
       " 129.65345764160156,\n",
       " 17.43269157409668,\n",
       " 4710.7802734375,\n",
       " 18.712919235229492,\n",
       " 3.160533905029297,\n",
       " 7.790188312530518,\n",
       " 2.0669360160827637,\n",
       " 9.734598159790039,\n",
       " 3872.267578125,\n",
       " 2.0,\n",
       " 828.1788330078125,\n",
       " 25.382949829101562,\n",
       " 2258.783447265625,\n",
       " 921.5621948242188,\n",
       " 417.505615234375,\n",
       " 148.2179718017578,\n",
       " 118.95427703857422,\n",
       " 6120.8779296875,\n",
       " 15.434693336486816,\n",
       " 2.6288673877716064,\n",
       " 30.72011947631836,\n",
       " 35.1878776550293,\n",
       " 2.0,\n",
       " 549.9279174804688,\n",
       " 12.125218391418457,\n",
       " 28.241743087768555,\n",
       " 10.86463737487793,\n",
       " 56.79911804199219,\n",
       " 4.264845371246338,\n",
       " 473.1886901855469,\n",
       " 490.4779052734375,\n",
       " 3.2245633602142334,\n",
       " 11.93876838684082,\n",
       " 461.6692810058594,\n",
       " 62.496097564697266,\n",
       " 2613.10546875,\n",
       " 60.175819396972656,\n",
       " 7.157416343688965,\n",
       " 7.183769226074219,\n",
       " 2.0,\n",
       " 4.3422746658325195,\n",
       " 1438.73388671875,\n",
       " 2.0,\n",
       " 169.46717834472656,\n",
       " 11.080163955688477,\n",
       " 954.71142578125,\n",
       " 381.82025146484375,\n",
       " 209.96084594726562,\n",
       " 45.41148376464844,\n",
       " 37.75126647949219,\n",
       " 2595.298828125,\n",
       " 6.102906703948975,\n",
       " 2.385651111602783,\n",
       " 16.046161651611328,\n",
       " 23.696441650390625,\n",
       " 2.0,\n",
       " 215.53646850585938,\n",
       " 3.7217941284179688,\n",
       " 27.7359619140625,\n",
       " 10.272541046142578,\n",
       " 54.846458435058594,\n",
       " 2.6105287075042725,\n",
       " 149.66177368164062,\n",
       " 217.429931640625,\n",
       " 2.2364935874938965,\n",
       " 5.186211109161377,\n",
       " 132.20530700683594,\n",
       " 22.49947738647461,\n",
       " 2507.9599609375,\n",
       " 23.944047927856445,\n",
       " 2.7876157760620117,\n",
       " 7.183769226074219,\n",
       " 2.0,\n",
       " 4.3422746658325195,\n",
       " 1490.257080078125,\n",
       " 2.0,\n",
       " 170.97584533691406,\n",
       " 11.080163955688477,\n",
       " 954.71142578125,\n",
       " 425.92462158203125,\n",
       " 209.96084594726562,\n",
       " 45.41148376464844,\n",
       " 37.75126647949219,\n",
       " 2621.467529296875,\n",
       " 6.102906703948975,\n",
       " 2.385651111602783,\n",
       " 16.046161651611328,\n",
       " 23.696441650390625,\n",
       " 2.0,\n",
       " 199.60906982421875,\n",
       " 3.7217941284179688,\n",
       " 27.7359619140625,\n",
       " 8.363691329956055,\n",
       " 61.23434829711914,\n",
       " 2.6105287075042725,\n",
       " 149.66177368164062,\n",
       " 227.30929565429688,\n",
       " 2.2364935874938965,\n",
       " 5.186211109161377,\n",
       " 102.32482147216797,\n",
       " 22.49947738647461,\n",
       " 3040.291259765625,\n",
       " 23.944047927856445,\n",
       " 2.7876157760620117,\n",
       " 4.852867126464844,\n",
       " 2.0,\n",
       " 4.06871223449707,\n",
       " 1289.3253173828125,\n",
       " 2.0,\n",
       " 193.63818359375,\n",
       " 9.739053726196289,\n",
       " 1266.0936279296875,\n",
       " 679.2921142578125,\n",
       " 223.90122985839844,\n",
       " 37.08428955078125,\n",
       " 49.086151123046875,\n",
       " 2452.582763671875,\n",
       " 6.361307621002197,\n",
       " 2.187471866607666,\n",
       " 14.229178428649902,\n",
       " 22.420331954956055,\n",
       " 2.0,\n",
       " 202.8341827392578,\n",
       " 2.0,\n",
       " 64.75827026367188,\n",
       " 12.208235740661621,\n",
       " 39.67075729370117,\n",
       " 3.2719874382019043,\n",
       " 225.05914306640625,\n",
       " 296.64385986328125,\n",
       " 2.48996639251709,\n",
       " 4.624576091766357,\n",
       " 67.40508270263672,\n",
       " 49.89684295654297,\n",
       " 3527.120361328125,\n",
       " 15.203144073486328,\n",
       " 4.171868324279785,\n",
       " 4.938647270202637,\n",
       " 3.148831605911255,\n",
       " 7.873968124389648,\n",
       " 1742.3594970703125,\n",
       " 2.0,\n",
       " 197.99639892578125,\n",
       " 6.723859786987305,\n",
       " 984.8052978515625,\n",
       " 350.5753173828125,\n",
       " 273.4579772949219,\n",
       " 71.40174865722656,\n",
       " 67.83826446533203,\n",
       " 2740.409912109375,\n",
       " 7.379183292388916,\n",
       " 2.5566015243530273,\n",
       " 20.590999603271484,\n",
       " 33.745155334472656,\n",
       " 2.0,\n",
       " 220.1829833984375,\n",
       " 8.477275848388672,\n",
       " 45.25770568847656,\n",
       " 14.909541130065918,\n",
       " 34.63205337524414,\n",
       " 2.7547035217285156,\n",
       " 124.76300048828125,\n",
       " 230.22593688964844,\n",
       " 2.5548934936523438,\n",
       " 4.92294454574585,\n",
       " 113.50376892089844,\n",
       " 25.89468765258789,\n",
       " 2609.637451171875,\n",
       " 46.38605499267578,\n",
       " 5.061914920806885,\n",
       " 6.126456260681152,\n",
       " 2.0,\n",
       " 5.038641929626465,\n",
       " 1625.22265625,\n",
       " 2.0,\n",
       " 147.2207489013672,\n",
       " 7.9399566650390625,\n",
       " 1067.0809326171875,\n",
       " 325.1568603515625,\n",
       " 203.84686279296875,\n",
       " 114.79502868652344,\n",
       " 43.18182373046875,\n",
       " 2691.665771484375,\n",
       " 4.3005690574646,\n",
       " 2.0,\n",
       " 11.786690711975098,\n",
       " 15.834989547729492,\n",
       " 2.0,\n",
       " 131.11569213867188,\n",
       " 2.0,\n",
       " 19.465389251708984,\n",
       " 10.888788223266602,\n",
       " 42.1511344909668,\n",
       " 2.489041805267334,\n",
       " 62.653358459472656,\n",
       " 179.03414916992188,\n",
       " 2.1141152381896973,\n",
       " 4.9082489013671875,\n",
       " 62.834835052490234,\n",
       " 40.37869644165039,\n",
       " 4116.142578125,\n",
       " 60.513126373291016,\n",
       " 2.6211862564086914,\n",
       " 7.75686502456665,\n",
       " 2.0,\n",
       " 5.120918273925781,\n",
       " 3088.88330078125,\n",
       " 2.0,\n",
       " 256.510986328125,\n",
       " 9.890849113464355,\n",
       " 1187.4088134765625,\n",
       " 994.3612670898438,\n",
       " 469.8993835449219,\n",
       " 175.469970703125,\n",
       " 92.10767364501953,\n",
       " 5049.06884765625,\n",
       " 8.702150344848633,\n",
       " 2.5287699699401855,\n",
       " 28.95273780822754,\n",
       " 34.257049560546875,\n",
       " 2.046557903289795,\n",
       " 252.46629333496094,\n",
       " 3.4318151473999023,\n",
       " 40.63294982910156,\n",
       " 9.490859031677246,\n",
       " 51.814300537109375,\n",
       " 3.575845718383789,\n",
       " 231.02041625976562,\n",
       " 302.0040588378906,\n",
       " 3.0637259483337402,\n",
       " 6.55986213684082,\n",
       " 345.2432861328125,\n",
       " 69.48380279541016,\n",
       " 3694.60546875,\n",
       " 63.95515823364258,\n",
       " 9.487600326538086,\n",
       " 3.1284797191619873,\n",
       " 2.0,\n",
       " 6.087435722351074,\n",
       " 2964.163818359375,\n",
       " 2.0,\n",
       " 583.0440673828125,\n",
       " 2.0,\n",
       " 845.2869873046875,\n",
       " 758.49169921875,\n",
       " 221.0820770263672,\n",
       " 109.0705337524414,\n",
       " 42.83821487426758,\n",
       " 3005.84228515625,\n",
       " 5.4040117263793945,\n",
       " 2.0,\n",
       " 19.507497787475586,\n",
       " 26.749622344970703,\n",
       " 2.0,\n",
       " 210.29380798339844,\n",
       " 2.2912981510162354,\n",
       " 27.79364776611328,\n",
       " 10.111449241638184,\n",
       " 62.67382049560547,\n",
       " 2.0,\n",
       " 7.701939105987549,\n",
       " 211.3196563720703,\n",
       " 2.0,\n",
       " 2.247072219848633,\n",
       " 218.09878540039062,\n",
       " 51.58678436279297,\n",
       " 3150.723388671875,\n",
       " 40.82785415649414,\n",
       " 5.381106376647949,\n",
       " 9.00054931640625,\n",
       " 2.1552574634552,\n",
       " 4.998072624206543,\n",
       " 1969.1641845703125,\n",
       " 2.0,\n",
       " 177.03744506835938,\n",
       " 9.238977432250977,\n",
       " 880.0614624023438,\n",
       " 616.656982421875,\n",
       " 292.958984375,\n",
       " 60.23942565917969,\n",
       " 48.61735534667969,\n",
       " 2801.091796875,\n",
       " 6.790037631988525,\n",
       " 2.816823720932007,\n",
       " 15.562602996826172,\n",
       " 18.71668243408203,\n",
       " 2.0,\n",
       " 183.6317596435547,\n",
       " 9.443479537963867,\n",
       " 23.59685516357422,\n",
       " 12.214357376098633,\n",
       " 116.32130432128906,\n",
       " 2.8765482902526855,\n",
       " 136.4993133544922,\n",
       " 224.69000244140625,\n",
       " 2.555598497390747,\n",
       " 5.977693557739258,\n",
       " 96.97523498535156,\n",
       " 22.690746307373047,\n",
       " 2667.16845703125,\n",
       " 16.163419723510742,\n",
       " 4.9783477783203125,\n",
       " 5.857950210571289,\n",
       " 2.0,\n",
       " 8.28862190246582,\n",
       " 3062.598388671875,\n",
       " 2.0,\n",
       " 533.490234375,\n",
       " 17.83911895751953,\n",
       " 894.6492309570312,\n",
       " 853.7012939453125,\n",
       " 282.5483093261719,\n",
       " 157.57640075683594,\n",
       " 137.74520874023438,\n",
       " 4471.439453125,\n",
       " 22.235414505004883,\n",
       " 3.1352550983428955,\n",
       " 25.550722122192383,\n",
       " 36.089805603027344,\n",
       " 2.0,\n",
       " 228.17739868164062,\n",
       " 21.495405197143555,\n",
       " 62.506683349609375,\n",
       " 16.267488479614258,\n",
       " 100.09281158447266,\n",
       " 7.150758743286133,\n",
       " 325.58905029296875,\n",
       " 349.93963623046875,\n",
       " 9.042611122131348,\n",
       " 9.9443998336792,\n",
       " 443.81243896484375,\n",
       " 111.09378051757812,\n",
       " 6544.45458984375,\n",
       " 79.55860137939453,\n",
       " 22.332046508789062,\n",
       " 9.677678108215332,\n",
       " 2.0700249671936035,\n",
       " 9.119404792785645,\n",
       " 2908.788818359375,\n",
       " 2.0,\n",
       " 503.74029541015625,\n",
       " 15.496047973632812,\n",
       " 1566.341552734375,\n",
       " 967.3951416015625,\n",
       " 530.3265380859375,\n",
       " 115.35115814208984,\n",
       " 72.6733169555664,\n",
       " 6255.171875,\n",
       " 10.421854972839355,\n",
       " 3.0601956844329834,\n",
       " 34.86240768432617,\n",
       " 31.588760375976562,\n",
       " 2.0,\n",
       " 343.26300048828125,\n",
       " 8.616775512695312,\n",
       " 19.24980354309082,\n",
       " 7.10013484954834,\n",
       " 58.00396728515625,\n",
       " 3.68355131149292,\n",
       " 238.0371551513672,\n",
       " 440.82928466796875,\n",
       " 5.899841785430908,\n",
       " 6.591579914093018,\n",
       " 390.66009521484375,\n",
       " 76.79711151123047,\n",
       " 4820.38232421875,\n",
       " 67.4548110961914,\n",
       " 12.767192840576172,\n",
       " 9.908761978149414,\n",
       " 2.0,\n",
       " 7.632305145263672,\n",
       " 2108.74755859375,\n",
       " 2.0,\n",
       " 385.1100769042969,\n",
       " 9.493367195129395,\n",
       " 1248.90380859375,\n",
       " 614.3441772460938,\n",
       " 490.66607666015625,\n",
       " 138.3116455078125,\n",
       " 67.36500549316406,\n",
       " 3843.07177734375,\n",
       " 9.590926170349121,\n",
       " 2.3346376419067383,\n",
       " 21.124372482299805,\n",
       " 34.075889587402344,\n",
       " 2.2425308227539062,\n",
       " 249.5692138671875,\n",
       " 5.508024215698242,\n",
       " 32.22954177856445,\n",
       " 12.166025161743164,\n",
       " 72.51795196533203,\n",
       " 3.8689472675323486,\n",
       " 187.51663208007812,\n",
       " 254.75381469726562,\n",
       " 2.541077136993408,\n",
       " 47.88214874267578,\n",
       " 137.5953826904297,\n",
       " 82.43002319335938,\n",
       " 2671.41943359375,\n",
       " 125.31092071533203,\n",
       " 5.572783470153809,\n",
       " 4.653246879577637,\n",
       " 2.0,\n",
       " 3.888566017150879,\n",
       " 1397.0201416015625,\n",
       " 2.0,\n",
       " 117.95935821533203,\n",
       " 5.044131278991699,\n",
       " 722.9940795898438,\n",
       " 610.7442626953125,\n",
       " 175.9861297607422,\n",
       " 42.602783203125,\n",
       " 38.41590118408203,\n",
       " 2105.540771484375,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 31.449541091918945,\n",
       " 29.107372283935547,\n",
       " 2.0,\n",
       " 153.94973754882812,\n",
       " 2.0,\n",
       " 27.362640380859375,\n",
       " 8.323953628540039,\n",
       " 38.74360275268555,\n",
       " 2.1243624687194824,\n",
       " 24.25479507446289,\n",
       " 194.29525756835938,\n",
       " 2.0,\n",
       " 3.6805033683776855,\n",
       " 22.925373077392578,\n",
       " 37.80082321166992,\n",
       " 6876.03076171875,\n",
       " 10.840555191040039,\n",
       " 2.2758851051330566,\n",
       " 3.895826816558838,\n",
       " 2.0,\n",
       " 7.257423400878906,\n",
       " 1447.1807861328125,\n",
       " 2.0,\n",
       " 269.8427734375,\n",
       " 24.284053802490234,\n",
       " 643.1983032226562,\n",
       " 581.9011840820312,\n",
       " 160.28042602539062,\n",
       " 57.505043029785156,\n",
       " 65.19273376464844,\n",
       " 2629.708740234375,\n",
       " 22.145681381225586,\n",
       " 2.1132588386535645,\n",
       " 14.843756675720215,\n",
       " 26.16219139099121,\n",
       " 2.0,\n",
       " 181.73880004882812,\n",
       " 13.889118194580078,\n",
       " 23.03445816040039,\n",
       " 12.089576721191406,\n",
       " 94.18145751953125,\n",
       " 5.138891696929932,\n",
       " 519.3936157226562,\n",
       " 247.04269409179688,\n",
       " 4.923081874847412,\n",
       " 5.061736583709717,\n",
       " 219.95462036132812,\n",
       " 32.20542907714844,\n",
       " 2844.982177734375,\n",
       " 41.18784713745117,\n",
       " 11.985326766967773,\n",
       " 3.977435350418091,\n",
       " 2.0,\n",
       " 8.428742408752441,\n",
       " 3750.421142578125,\n",
       " 2.0,\n",
       " 768.8513793945312,\n",
       " 24.919723510742188,\n",
       " 1483.9990234375,\n",
       " 1514.05712890625,\n",
       " 375.3629150390625,\n",
       " 238.0721893310547,\n",
       " 248.95233154296875,\n",
       " 4098.86767578125,\n",
       " 18.909198760986328,\n",
       " 2.923074245452881,\n",
       " 28.1053409576416,\n",
       " 49.9211311340332,\n",
       " 2.0,\n",
       " 259.9481201171875,\n",
       " 11.082427978515625,\n",
       " 115.69503021240234,\n",
       " 22.27320098876953,\n",
       " 120.07530212402344,\n",
       " 7.895941734313965,\n",
       " 281.83514404296875,\n",
       " 325.9236755371094,\n",
       " 13.447771072387695,\n",
       " 10.707110404968262,\n",
       " 366.2861328125,\n",
       " 86.30924987792969,\n",
       " 8671.380859375,\n",
       " 131.2852325439453,\n",
       " 22.92594337463379,\n",
       " 3.1678802967071533,\n",
       " 2.0,\n",
       " 6.474270820617676,\n",
       " 1636.33251953125,\n",
       " 2.0,\n",
       " 454.45849609375,\n",
       " 5.465526580810547,\n",
       " 621.2841796875,\n",
       " 595.5823974609375,\n",
       " 151.25112915039062,\n",
       " 95.3070068359375,\n",
       " 129.97003173828125,\n",
       " 2916.7001953125,\n",
       " 5.502876281738281,\n",
       " 2.0,\n",
       " 22.54979705810547,\n",
       " 29.295663833618164,\n",
       " 2.0,\n",
       " 127.48258209228516,\n",
       " 2.0,\n",
       " 96.85381317138672,\n",
       " 22.096538543701172,\n",
       " 155.84597778320312,\n",
       " 2.9811043739318848,\n",
       " 62.01433181762695,\n",
       " 137.92007446289062,\n",
       " 4.334508895874023,\n",
       " 8.908964157104492,\n",
       " 81.91789245605469,\n",
       " 32.737648010253906,\n",
       " 10860.630859375,\n",
       " 11.939253807067871,\n",
       " 3.9926347732543945,\n",
       " 5.57036018371582,\n",
       " 2.0411734580993652,\n",
       " 4.421885013580322,\n",
       " 796.1116333007812,\n",
       " 2.0,\n",
       " 220.2129669189453,\n",
       " 9.643723487854004,\n",
       " 476.07318115234375,\n",
       " 356.94659423828125,\n",
       " 97.83924865722656,\n",
       " 35.85220718383789,\n",
       " 37.54209899902344,\n",
       " 1636.323974609375,\n",
       " 4.227208137512207,\n",
       " 2.2842226028442383,\n",
       " 15.752519607543945,\n",
       " 16.10400390625,\n",
       " 2.0,\n",
       " 143.0110626220703,\n",
       " 3.4303503036499023,\n",
       " 24.365890502929688,\n",
       " 6.456539154052734,\n",
       " 67.0916519165039,\n",
       " 2.4461464881896973,\n",
       " 230.2498779296875,\n",
       " 242.1256561279297,\n",
       " 2.864654541015625,\n",
       " 3.203227996826172,\n",
       " 145.22671508789062,\n",
       " 16.82402992248535,\n",
       " 5881.9462890625,\n",
       " 42.30464172363281,\n",
       " 3.123286247253418,\n",
       " 5.64799165725708,\n",
       " 2.0,\n",
       " 7.231149196624756,\n",
       " 3505.08935546875,\n",
       " 2.0,\n",
       " 665.7301025390625,\n",
       " 20.0377254486084,\n",
       " 1056.1363525390625,\n",
       " 719.22998046875,\n",
       " 317.7581787109375,\n",
       " 191.17919921875,\n",
       " 140.86959838867188,\n",
       " 4099.08251953125,\n",
       " 18.355119705200195,\n",
       " 3.372143507003784,\n",
       " 24.337753295898438,\n",
       " 42.985084533691406,\n",
       " 2.0,\n",
       " 243.61146545410156,\n",
       " 6.33367919921875,\n",
       " 79.55552673339844,\n",
       " 26.47075653076172,\n",
       " 254.9048614501953,\n",
       " 4.027327537536621,\n",
       " 194.2809600830078,\n",
       " 173.2219696044922,\n",
       " 9.017589569091797,\n",
       " 8.338133811950684,\n",
       " 305.34649658203125,\n",
       " 71.86988830566406,\n",
       " 6842.7255859375,\n",
       " 179.14199829101562,\n",
       " 17.404170989990234,\n",
       " 7.351943492889404,\n",
       " 2.0,\n",
       " 5.900308132171631,\n",
       " 2405.167236328125,\n",
       " 2.0,\n",
       " 571.3980712890625,\n",
       " 14.766523361206055,\n",
       " 1093.0,\n",
       " 1067.5599365234375,\n",
       " 430.2587585449219,\n",
       " 181.42425537109375,\n",
       " 71.65596008300781,\n",
       " 4202.86474609375,\n",
       " 9.65157413482666,\n",
       " 2.9059345722198486,\n",
       " 23.585872650146484,\n",
       " 26.839092254638672,\n",
       " 2.0,\n",
       " 295.6466064453125,\n",
       " 2.0,\n",
       " 29.09285545349121,\n",
       " 14.027119636535645,\n",
       " 120.70282745361328,\n",
       " 3.1089043617248535,\n",
       " 153.83026123046875,\n",
       " 411.20416259765625,\n",
       " 6.198760986328125,\n",
       " 5.824122905731201,\n",
       " 178.9130401611328,\n",
       " 52.44109344482422,\n",
       " 2594.55810546875,\n",
       " 83.83301544189453,\n",
       " 4.654244422912598,\n",
       " 7.351943492889404,\n",
       " 2.0,\n",
       " 5.900308132171631,\n",
       " 2405.167236328125,\n",
       " 2.0,\n",
       " 571.3980712890625,\n",
       " 14.766523361206055,\n",
       " 1038.513671875,\n",
       " 1075.5611572265625,\n",
       " 430.2587585449219,\n",
       " 181.42425537109375,\n",
       " 71.65596008300781,\n",
       " 4375.572265625,\n",
       " 9.65157413482666,\n",
       " 2.9059345722198486,\n",
       " 23.585872650146484,\n",
       " 26.839092254638672,\n",
       " 2.0,\n",
       " 275.85845947265625,\n",
       " 2.0,\n",
       " 34.153507232666016,\n",
       " 16.736068725585938,\n",
       " 115.12525939941406,\n",
       " 3.1089043617248535,\n",
       " 153.83026123046875,\n",
       " 360.1006164550781,\n",
       " 6.198760986328125,\n",
       " 5.824122905731201,\n",
       " 178.9130401611328,\n",
       " 53.052066802978516,\n",
       " 2406.0419921875,\n",
       " 96.95217895507812,\n",
       " 4.654244422912598,\n",
       " 7.04403829574585,\n",
       " 2.0,\n",
       " 10.658305168151855,\n",
       " 5034.80078125,\n",
       " 2.0,\n",
       " 1083.4097900390625,\n",
       " 32.75000762939453,\n",
       " 1465.560546875,\n",
       " 1336.3160400390625,\n",
       " 343.9072570800781,\n",
       " 314.42510986328125,\n",
       " 311.6854553222656,\n",
       " 5603.23779296875,\n",
       " 45.56303787231445,\n",
       " 4.838051795959473,\n",
       " 37.930152893066406,\n",
       " 41.95906066894531,\n",
       " 2.6323626041412354,\n",
       " 311.30419921875,\n",
       " 21.809690475463867,\n",
       " 61.55484390258789,\n",
       " 31.428590774536133,\n",
       " 191.2943115234375,\n",
       " 13.972260475158691,\n",
       " 535.6423950195312,\n",
       " 591.0299072265625,\n",
       " 13.175804138183594,\n",
       " 15.812247276306152,\n",
       " 831.0394287109375,\n",
       " 222.07676696777344,\n",
       " 10707.796875,\n",
       " 61.99367904663086,\n",
       " 47.59666061401367,\n",
       " 3.7684550285339355,\n",
       " 2.0,\n",
       " 4.256739616394043,\n",
       " 1132.5950927734375,\n",
       " 2.0,\n",
       " 161.19161987304688,\n",
       " 7.2967658042907715,\n",
       " 527.0878295898438,\n",
       " 518.9730834960938,\n",
       " 188.4302978515625,\n",
       " 159.9683380126953,\n",
       " 49.350894927978516,\n",
       " 1858.37744140625,\n",
       " 3.708160400390625,\n",
       " 2.452512264251709,\n",
       " 14.733242988586426,\n",
       " 24.996505737304688,\n",
       " 2.0,\n",
       " 122.7174072265625,\n",
       " 2.0,\n",
       " 21.438650131225586,\n",
       " 8.758622169494629,\n",
       " 84.85359191894531,\n",
       " 2.3055500984191895,\n",
       " 53.56549835205078,\n",
       " 124.56410217285156,\n",
       " 2.6357131004333496,\n",
       " 3.670358657836914,\n",
       " 77.4209976196289,\n",
       " 14.91160774230957,\n",
       " 5951.14404296875,\n",
       " 68.49063873291016,\n",
       " 2.6997804641723633,\n",
       " 9.107522010803223,\n",
       " 2.5424957275390625,\n",
       " 6.765185356140137,\n",
       " 2388.8544921875,\n",
       " 2.0,\n",
       " 434.4280700683594,\n",
       " 14.435626983642578,\n",
       " 1480.9332275390625,\n",
       " 1063.7169189453125,\n",
       " 308.1093444824219,\n",
       " 249.36045837402344,\n",
       " 81.36441040039062,\n",
       " 5275.01953125,\n",
       " 9.50694751739502,\n",
       " 2.219895362854004,\n",
       " 21.394840240478516,\n",
       " 28.253273010253906,\n",
       " 2.0,\n",
       " 292.83984375,\n",
       " 3.661273956298828,\n",
       " 28.927257537841797,\n",
       " 10.442069053649902,\n",
       " 63.59165573120117,\n",
       " 3.239109992980957,\n",
       " 303.2727966308594,\n",
       " 441.0205993652344,\n",
       " 3.9387264251708984,\n",
       " 6.705484390258789,\n",
       " 126.79065704345703,\n",
       " 54.21579360961914,\n",
       " 3911.7646484375,\n",
       " 66.69957733154297,\n",
       " 5.076301574707031,\n",
       " 3.7684550285339355,\n",
       " 2.0,\n",
       " 4.256739616394043,\n",
       " 973.7855834960938,\n",
       " 2.0,\n",
       " 162.03106689453125,\n",
       " 7.2967658042907715,\n",
       " 517.8534545898438,\n",
       " 392.588134765625,\n",
       " 188.4302978515625,\n",
       " 159.9683380126953,\n",
       " 49.350894927978516,\n",
       " 1859.6939697265625,\n",
       " 3.708160400390625,\n",
       " 2.452512264251709,\n",
       " 14.733242988586426,\n",
       " 24.996505737304688,\n",
       " 2.0,\n",
       " 130.01425170898438,\n",
       " 2.0,\n",
       " 21.438650131225586,\n",
       " 10.003535270690918,\n",
       " 95.96730041503906,\n",
       " 2.3055500984191895,\n",
       " 53.56549835205078,\n",
       " 102.70088195800781,\n",
       " 2.6357131004333496,\n",
       " 3.670358657836914,\n",
       " 77.4209976196289,\n",
       " 14.91160774230957,\n",
       " 7338.62255859375,\n",
       " 68.49063873291016,\n",
       " 2.6997804641723633,\n",
       " 8.363214492797852,\n",
       " 2.0,\n",
       " 5.104569911956787,\n",
       " 1707.315185546875,\n",
       " 2.0,\n",
       " 312.36810302734375,\n",
       " 11.272631645202637,\n",
       " 1168.3826904296875,\n",
       " 932.45703125,\n",
       " 263.6994323730469,\n",
       " 149.0541534423828,\n",
       " 53.74956130981445,\n",
       " 2442.91552734375,\n",
       " 3.479621648788452,\n",
       " 2.3701672554016113,\n",
       " 33.72116470336914,\n",
       " 19.453399658203125,\n",
       " 2.0,\n",
       " 187.71328735351562,\n",
       " 2.0,\n",
       " 29.536415100097656,\n",
       " 10.76218318939209,\n",
       " 55.17375564575195,\n",
       " 2.7177767753601074,\n",
       " 194.58673095703125,\n",
       " 325.95281982421875,\n",
       " 2.9599812030792236,\n",
       " 5.318147659301758,\n",
       " 191.4033203125,\n",
       " 40.75896453857422,\n",
       " 4791.80126953125,\n",
       " 32.14045715332031,\n",
       " 2.1356091499328613,\n",
       " 5.138916969299316,\n",
       " 2.0,\n",
       " 6.61184549331665,\n",
       " 2311.55615234375,\n",
       " 2.0,\n",
       " 567.3946533203125,\n",
       " 15.439746856689453,\n",
       " 1311.83056640625,\n",
       " 654.8189697265625,\n",
       " 203.00238037109375,\n",
       " 105.72842407226562,\n",
       " 79.31639099121094,\n",
       " 3805.505615234375,\n",
       " 5.276004791259766,\n",
       " 3.292313814163208,\n",
       " 38.68937683105469,\n",
       " 65.02375030517578,\n",
       " 2.0,\n",
       " 284.0542297363281,\n",
       " 4.9817609786987305,\n",
       " 28.868141174316406,\n",
       " 14.984488487243652,\n",
       " 101.24664306640625,\n",
       " 3.8538591861724854,\n",
       " 177.97520446777344,\n",
       " 278.1545104980469,\n",
       " 4.137228965759277,\n",
       " 6.457620620727539,\n",
       " 114.91490173339844,\n",
       " 42.800537109375,\n",
       " 6783.08984375,\n",
       " 43.43146514892578,\n",
       " 3.3401496410369873,\n",
       " 5.4295525550842285,\n",
       " 2.0,\n",
       " 3.957037925720215,\n",
       " 1427.43798828125,\n",
       " 2.0,\n",
       " 162.76441955566406,\n",
       " 5.697052478790283,\n",
       " 673.90576171875,\n",
       " 517.3565673828125,\n",
       " 139.3658905029297,\n",
       " 160.41119384765625,\n",
       " 48.96388244628906,\n",
       " 2237.0810546875,\n",
       " 3.909601926803589,\n",
       " 2.1218185424804688,\n",
       " 11.171942710876465,\n",
       " 14.937984466552734,\n",
       " 2.0,\n",
       " 112.6145248413086,\n",
       " 2.0,\n",
       " 30.391313552856445,\n",
       " 5.668853759765625,\n",
       " 33.36667251586914,\n",
       " 2.262254238128662,\n",
       " 172.76211547851562,\n",
       " 104.43138122558594,\n",
       " 2.132504940032959,\n",
       " 2.5086472034454346,\n",
       " 36.293968200683594,\n",
       " 13.750875473022461,\n",
       " 5427.84130859375,\n",
       " 58.55659484863281,\n",
       " 2.0,\n",
       " 6.2007737159729,\n",
       " 2.0,\n",
       " 5.608245372772217,\n",
       " 2291.467529296875,\n",
       " 2.0,\n",
       " 528.6854248046875,\n",
       " 9.999942779541016,\n",
       " 1062.2620849609375,\n",
       " 892.5509033203125,\n",
       " 315.5495300292969,\n",
       " 123.64116668701172,\n",
       " 103.6734619140625,\n",
       " 4894.93212890625,\n",
       " 6.735473155975342,\n",
       " 2.2424492835998535,\n",
       " 26.28021812438965,\n",
       " 28.649635314941406,\n",
       " 2.0,\n",
       " 346.4685363769531,\n",
       " 2.0,\n",
       " 37.362491607666016,\n",
       " 19.111072540283203,\n",
       " 151.5900421142578,\n",
       " 2.6777005195617676,\n",
       " 225.761962890625,\n",
       " 374.6257019042969,\n",
       " 3.74125075340271,\n",
       " 5.667999267578125,\n",
       " 92.63839721679688,\n",
       " 39.93171691894531,\n",
       " 2959.11279296875,\n",
       " 147.10992431640625,\n",
       " 2.9554083347320557,\n",
       " 4.235501289367676,\n",
       " 2.0,\n",
       " 7.81580924987793,\n",
       " 2484.92431640625,\n",
       " 2.0,\n",
       " 644.90869140625,\n",
       " 11.561488151550293,\n",
       " 960.0827026367188,\n",
       " 808.0072631835938,\n",
       " 195.5870819091797,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132acab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
